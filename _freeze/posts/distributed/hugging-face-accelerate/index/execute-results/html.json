{
  "hash": "b1e438c019ffdd298595a5fdbd10a5be",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Hugging Face Accelerate Code Guide\"\nauthor: \"Krishnatheja Vanka\"\ndate: \"2025-06-03\"\ncategories: [code, tutorial, beginner]\nformat:\n  html:\n    code-fold: false\nexecute:\n  echo: true\n  timing: true\njupyter: python3\n---\n\n# Hugging Face Accelerate Code Guide\n![](accelerate.png)\nI've created a comprehensive code guide for Hugging Face Accelerate that covers everything from basic setup to advanced features like DeepSpeed integration.\n\n## Installation and Setup\n\n### Installation\n```bash\npip install accelerate\n```\n\n### Configuration\nRun the configuration wizard to set up your training environment:\n```bash\naccelerate config\n```\n\nOr create a config file programmatically:\n```python\nfrom accelerate import Accelerator\nfrom accelerate.utils import write_basic_config\n\nwrite_basic_config(mixed_precision=\"fp16\")  # or \"bf16\", \"no\"\n```\n\n## Basic Concepts\n\n### The Accelerator Object\nThe `Accelerator` is the main class that handles device placement, gradient synchronization, and other distributed training concerns.\n\n```python\nfrom accelerate import Accelerator\n\n# Initialize accelerator\naccelerator = Accelerator()\n\n# Key properties\ndevice = accelerator.device\nis_main_process = accelerator.is_main_process\nnum_processes = accelerator.num_processes\n```\n\n### Device Placement\nAccelerate automatically handles device placement:\n\n```python\n# Manual device placement (old way)\nmodel = model.to(device)\nbatch = {k: v.to(device) for k, v in batch.items()}\n\n# Accelerate way (automatic)\nmodel, optimizer, dataloader = accelerator.prepare(model, optimizer, dataloader)\n# No need to move batch to device - accelerate handles it\n```\n\n## Simple Training Loop\n\n### Basic Example\n```python\nimport torch\nfrom torch.utils.data import DataLoader\nfrom accelerate import Accelerator\nfrom transformers import AutoModel, AutoTokenizer, AdamW\n\ndef train_model():\n    # Initialize accelerator\n    accelerator = Accelerator()\n    \n    # Load model and tokenizer\n    model = AutoModel.from_pretrained(\"bert-base-uncased\")\n    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n    \n    # Create optimizer\n    optimizer = AdamW(model.parameters(), lr=5e-5)\n    \n    # Create dataloader (your dataset here)\n    train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n    \n    # Prepare everything with accelerator\n    model, optimizer, train_dataloader = accelerator.prepare(\n        model, optimizer, train_dataloader\n    )\n    \n    # Training loop\n    model.train()\n    for epoch in range(3):\n        for batch in train_dataloader:\n            # Forward pass\n            outputs = model(**batch)\n            loss = outputs.loss\n            \n            # Backward pass\n            accelerator.backward(loss)\n            optimizer.step()\n            optimizer.zero_grad()\n            \n            # Print loss (only on main process)\n            if accelerator.is_main_process:\n                print(f\"Loss: {loss.item():.4f}\")\n\nif __name__ == \"__main__\":\n    train_model()\n```\n\n### Running the Training\n```bash\n# Single GPU\npython train.py\n\n# Multiple GPUs\naccelerate launch --num_processes=2 train.py\n\n# With config file\naccelerate launch --config_file config.yaml train.py\n```\n\n## Advanced Features\n\n### Logging and Tracking\n```python\nfrom accelerate import Accelerator\nfrom accelerate.logging import get_logger\n\n# Initialize with logging\naccelerator = Accelerator(log_with=\"tensorboard\", project_dir=\"./logs\")\n\n# Get logger\nlogger = get_logger(__name__)\n\n# Start tracking\naccelerator.init_trackers(\"my_experiment\")\n\n# Log metrics\naccelerator.log({\"train_loss\": loss.item(), \"epoch\": epoch})\n\n# End tracking\naccelerator.end_training()\n```\n\n### Saving and Loading Models\n```python\n# Save model\naccelerator.save_model(model, \"path/to/save\")\n\n# Or save state dict\naccelerator.save(model.state_dict(), \"model.pt\")\n\n# Load model\naccelerator.load_state(\"model.pt\")\n\n# Save complete training state\naccelerator.save_state(\"checkpoint_dir\")\n\n# Load complete training state\naccelerator.load_state(\"checkpoint_dir\")\n```\n\n### Evaluation Loop\n```python\ndef evaluate_model(model, eval_dataloader, accelerator):\n    model.eval()\n    total_loss = 0\n    total_samples = 0\n    \n    with torch.no_grad():\n        for batch in eval_dataloader:\n            outputs = model(**batch)\n            loss = outputs.loss\n            \n            # Gather losses from all processes\n            gathered_loss = accelerator.gather(loss)\n            total_loss += gathered_loss.sum().item()\n            total_samples += gathered_loss.shape[0]\n    \n    avg_loss = total_loss / total_samples\n    return avg_loss\n```\n\n## Multi-GPU Training\n\n### Data Parallel Training\n```python\nfrom accelerate import Accelerator\n\ndef train_multi_gpu():\n    accelerator = Accelerator()\n    \n    # Model will be replicated across GPUs\n    model = MyModel()\n    optimizer = torch.optim.Adam(model.parameters())\n    \n    # Prepare for multi-GPU\n    model, optimizer, train_dataloader = accelerator.prepare(\n        model, optimizer, train_dataloader\n    )\n    \n    # Training loop remains the same\n    for batch in train_dataloader:\n        outputs = model(**batch)\n        loss = outputs.loss\n        \n        # Accelerate handles gradient synchronization\n        accelerator.backward(loss)\n        optimizer.step()\n        optimizer.zero_grad()\n```\n\n### Launch Commands\n```bash\n# Launch on 4 GPUs\naccelerate launch --num_processes=4 --multi_gpu train.py\n\n# Launch with specific GPUs\nCUDA_VISIBLE_DEVICES=0,1,3 accelerate launch --num_processes=3 train.py\n\n# Launch on multiple nodes\naccelerate launch --num_processes=8 --num_machines=2 --main_process_ip=192.168.1.1 train.py\n```\n\n## Mixed Precision Training\n\n### Automatic Mixed Precision\n```python\n# Enable mixed precision in config or during initialization\naccelerator = Accelerator(mixed_precision=\"fp16\")  # or \"bf16\"\n\n# Training loop remains exactly the same\nfor batch in train_dataloader:\n    outputs = model(**batch)\n    loss = outputs.loss\n    \n    # Accelerate handles scaling automatically\n    accelerator.backward(loss)\n    optimizer.step()\n    optimizer.zero_grad()\n```\n\n### Manual Mixed Precision Control\n```python\n# Access the scaler if needed\nif accelerator.mixed_precision == \"fp16\":\n    scaler = accelerator.scaler\n    \n    # Manual scaling (usually not needed)\n    scaled_loss = scaler.scale(loss)\n    scaled_loss.backward()\n    scaler.step(optimizer)\n    scaler.update()\n```\n\n## Gradient Accumulation\n\n### Basic Gradient Accumulation\n```python\naccelerator = Accelerator(gradient_accumulation_steps=4)\n\nfor batch in train_dataloader:\n    # Use accumulate context manager\n    with accelerator.accumulate(model):\n        outputs = model(**batch)\n        loss = outputs.loss\n        \n        accelerator.backward(loss)\n        optimizer.step()\n        optimizer.zero_grad()\n```\n\n### Dynamic Gradient Accumulation\n```python\ndef train_with_dynamic_accumulation():\n    accumulation_steps = 2\n    \n    for i, batch in enumerate(train_dataloader):\n        outputs = model(**batch)\n        loss = outputs.loss / accumulation_steps  # Scale loss\n        \n        accelerator.backward(loss)\n        \n        if (i + 1) % accumulation_steps == 0:\n            optimizer.step()\n            optimizer.zero_grad()\n```\n\n## DeepSpeed Integration\n\n### DeepSpeed Configuration\nCreate a DeepSpeed config file (`ds_config.json`):\n```json\n{\n    \"train_batch_size\": 32,\n    \"gradient_accumulation_steps\": 1,\n    \"optimizer\": {\n        \"type\": \"Adam\",\n        \"params\": {\n            \"lr\": 5e-5\n        }\n    },\n    \"fp16\": {\n        \"enabled\": true\n    },\n    \"zero_optimization\": {\n        \"stage\": 2\n    }\n}\n```\n\n### Using DeepSpeed\n```python\nfrom accelerate import Accelerator\n\n# Initialize with DeepSpeed\naccelerator = Accelerator(deepspeed_plugin=\"ds_config.json\")\n\n# Or programmatically\nfrom accelerate import DeepSpeedPlugin\n\nds_plugin = DeepSpeedPlugin(\n    gradient_accumulation_steps=4,\n    zero_stage=2,\n    offload_optimizer_device=\"cpu\"\n)\naccelerator = Accelerator(deepspeed_plugin=ds_plugin)\n\n# Training code remains the same\nmodel, optimizer = accelerator.prepare(model, optimizer)\n```\n\n### Launch with DeepSpeed\n```bash\naccelerate launch --config_file ds_config.yaml train.py\n```\n\n## Troubleshooting\n\n### Common Issues and Solutions\n\n#### Memory Issues\n```python\n# Clear cache regularly\nif accelerator.is_main_process:\n    torch.cuda.empty_cache()\n\n# Use gradient checkpointing\nmodel.gradient_checkpointing_enable()\n\n# Reduce batch size or increase gradient accumulation\n```\n\n#### Synchronization Issues\n```python\n# Wait for all processes\naccelerator.wait_for_everyone()\n\n# Gather data from all processes\nall_losses = accelerator.gather(loss)\n\n# Reduce across processes\navg_loss = accelerator.reduce(loss, reduction=\"mean\")\n```\n\n#### Debugging\n```python\n# Enable debug mode\naccelerator = Accelerator(debug=True)\n\n# Check if running in distributed mode\nif accelerator.distributed_type != \"NO\":\n    print(f\"Running on {accelerator.num_processes} processes\")\n\n# Print only on main process\naccelerator.print(\"This will only print once\")\n```\n\n### Performance Tips\n\n1. **Use appropriate batch sizes**: Larger batch sizes generally improve GPU utilization\n2. **Enable mixed precision**: Use fp16 or bf16 for faster training\n3. **Gradient accumulation**: Simulate larger batch sizes without memory issues\n4. **DataLoader optimization**: Use `num_workers` and `pin_memory=True`\n5. **Compile models**: Use `torch.compile()` for PyTorch 2.0+\n\n```python\n# Optimized setup\naccelerator = Accelerator(\n    mixed_precision=\"bf16\",\n    gradient_accumulation_steps=4\n)\n\n# Compile model (PyTorch 2.0+)\nmodel = torch.compile(model)\n\n# Optimized DataLoader\ntrain_dataloader = DataLoader(\n    dataset,\n    batch_size=32,\n    num_workers=4,\n    pin_memory=True,\n    shuffle=True\n)\n```\n\n## Complete Example: BERT Fine-tuning\n\n```python\nimport torch\nfrom torch.utils.data import DataLoader\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\nfrom accelerate import Accelerator\nfrom datasets import load_dataset\n\ndef main():\n    # Initialize\n    accelerator = Accelerator(mixed_precision=\"fp16\")\n    \n    # Load data\n    dataset = load_dataset(\"imdb\")\n    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n    \n    def tokenize_function(examples):\n        return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\")\n    \n    tokenized_datasets = dataset.map(tokenize_function, batched=True)\n    train_dataset = tokenized_datasets[\"train\"].with_format(\"torch\")\n    \n    # Model and optimizer\n    model = AutoModelForSequenceClassification.from_pretrained(\n        \"bert-base-uncased\", num_labels=2\n    )\n    optimizer = AdamW(model.parameters(), lr=5e-5)\n    \n    # DataLoader\n    train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n    \n    # Prepare everything\n    model, optimizer, train_dataloader = accelerator.prepare(\n        model, optimizer, train_dataloader\n    )\n    \n    # Training loop\n    num_epochs = 3\n    model.train()\n    \n    for epoch in range(num_epochs):\n        total_loss = 0\n        for step, batch in enumerate(train_dataloader):\n            outputs = model(**batch)\n            loss = outputs.loss\n            \n            accelerator.backward(loss)\n            optimizer.step()\n            optimizer.zero_grad()\n            \n            total_loss += loss.item()\n            \n            if step % 100 == 0 and accelerator.is_main_process:\n                print(f\"Epoch {epoch}, Step {step}, Loss: {loss.item():.4f}\")\n        \n        if accelerator.is_main_process:\n            avg_loss = total_loss / len(train_dataloader)\n            print(f\"Epoch {epoch} completed. Average loss: {avg_loss:.4f}\")\n    \n    # Save model\n    accelerator.wait_for_everyone()\n    unwrapped_model = accelerator.unwrap_model(model)\n    unwrapped_model.save_pretrained(\"./fine_tuned_bert\")\n    \n    if accelerator.is_main_process:\n        tokenizer.save_pretrained(\"./fine_tuned_bert\")\n\nif __name__ == \"__main__\":\n    main()\n```\n\nThis guide covers the essential aspects of using Hugging Face Accelerate for distributed training. The library abstracts away much of the complexity while providing fine-grained control when needed.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}