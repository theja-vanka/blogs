{
  "hash": "16edf18eb1f07a973b1b6bc2427c0653",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"MLflow for PyTorch - Complete Guide\"\nauthor: \"Krishnatheja Vanka\"\ndate: \"2025-05-30\"\ncategories: [code, mlops, beginner]\nformat:\n  html:\n    code-fold: false\nexecute:\n  echo: true\n  timing: true\njupyter: python3\n---\n\n# MLflow for PyTorch - Complete Guide\n![](mlflow.jpg)\n\nMLflow is an open-source platform for managing the machine learning lifecycle, including experimentation, reproducibility, deployment, and model registry. This guide covers how to integrate MLflow with PyTorch for comprehensive ML workflow management.\n## Installation and Setup\n\n### Install MLflow\n```bash\npip install mlflow\npip install torch torchvision\n```\n\n### Start MLflow UI\n```bash\nmlflow ui\n```\nThis starts the MLflow UI at `http://localhost:5000`\n\n### Basic Configuration\n```python\nimport mlflow\nimport mlflow.pytorch\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\n\n# Set tracking URI (optional - defaults to local)\nmlflow.set_tracking_uri(\"http://localhost:5000\")\n\n# Set experiment name\nmlflow.set_experiment(\"pytorch_experiments\")\n```\n\n## Basic MLflow Concepts\n\n- **Experiment**: A collection of runs for a particular task\n- **Run**: A single execution of your ML code\n- **Artifact**: Files generated during a run (models, plots, data)\n- **Metric**: Numerical values tracked over time\n- **Parameter**: Input configurations for your run\n\n## Experiment Tracking\n\n### Basic Run Structure\n```python\nimport mlflow\n\nwith mlflow.start_run():\n    # Your training code here\n    mlflow.log_param(\"learning_rate\", 0.001)\n    mlflow.log_metric(\"accuracy\", 0.95)\n    mlflow.log_artifact(\"model.pth\")\n```\n\n### Complete Training Example\n```python\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport mlflow\nimport mlflow.pytorch\nfrom sklearn.metrics import accuracy_score\nimport numpy as np\n\nclass SimpleNet(nn.Module):\n    def __init__(self, input_size, hidden_size, num_classes):\n        super(SimpleNet, self).__init__()\n        self.fc1 = nn.Linear(input_size, hidden_size)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(hidden_size, num_classes)\n    \n    def forward(self, x):\n        out = self.fc1(x)\n        out = self.relu(out)\n        out = self.fc2(out)\n        return out\n\ndef train_model():\n    # Hyperparameters\n    input_size = 784\n    hidden_size = 128\n    num_classes = 10\n    learning_rate = 0.001\n    batch_size = 64\n    num_epochs = 10\n    \n    # Start MLflow run\n    with mlflow.start_run():\n        # Log hyperparameters\n        mlflow.log_param(\"input_size\", input_size)\n        mlflow.log_param(\"hidden_size\", hidden_size)\n        mlflow.log_param(\"num_classes\", num_classes)\n        mlflow.log_param(\"learning_rate\", learning_rate)\n        mlflow.log_param(\"batch_size\", batch_size)\n        mlflow.log_param(\"num_epochs\", num_epochs)\n        \n        # Initialize model\n        model = SimpleNet(input_size, hidden_size, num_classes)\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n        \n        # Training loop\n        for epoch in range(num_epochs):\n            running_loss = 0.0\n            correct = 0\n            total = 0\n            \n            # Simulate training data\n            for i in range(100):  # 100 batches\n                # Generate dummy data\n                inputs = torch.randn(batch_size, input_size)\n                labels = torch.randint(0, num_classes, (batch_size,))\n                \n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n                \n                running_loss += loss.item()\n                _, predicted = torch.max(outputs.data, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n            \n            # Calculate metrics\n            epoch_loss = running_loss / 100\n            epoch_acc = 100 * correct / total\n            \n            # Log metrics\n            mlflow.log_metric(\"loss\", epoch_loss, step=epoch)\n            mlflow.log_metric(\"accuracy\", epoch_acc, step=epoch)\n            \n            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n        \n        # Log model\n        mlflow.pytorch.log_model(model, \"model\")\n        \n        # Log additional artifacts\n        torch.save(model.state_dict(), \"model_state_dict.pth\")\n        mlflow.log_artifact(\"model_state_dict.pth\")\n\n# Run training\ntrain_model()\n```\n\n## Model Logging\n\n### Different Ways to Log PyTorch Models\n\n#### 1. Log Complete Model\n```python\n# Log the entire model\nmlflow.pytorch.log_model(model, \"complete_model\")\n```\n\n#### 2. Log Model State Dict\n```python\n# Save and log state dict\ntorch.save(model.state_dict(), \"model_state_dict.pth\")\nmlflow.log_artifact(\"model_state_dict.pth\")\n```\n\n#### 3. Log with Custom Code\n```python\n# Log model with custom code for loading\nmlflow.pytorch.log_model(\n    model, \n    \"model\",\n    code_paths=[\"model_definition.py\"]  # Include custom model definition\n)\n```\n\n#### 4. Log with Conda Environment\n```python\nimport mlflow.pytorch\n\n# Create conda environment specification\nconda_env = {\n    'channels': ['defaults', 'pytorch'],\n    'dependencies': [\n        'python=3.8',\n        'pytorch',\n        'torchvision',\n        {'pip': ['mlflow']}\n    ],\n    'name': 'pytorch_env'\n}\n\nmlflow.pytorch.log_model(\n    model,\n    \"model\",\n    conda_env=conda_env\n)\n```\n\n## Model Registry\n\n### Register Model\n```python\n# Register model during logging\nmlflow.pytorch.log_model(\n    model, \n    \"model\",\n    registered_model_name=\"MyPyTorchModel\"\n)\n\n# Or register existing run\nmodel_uri = \"runs:/your_run_id/model\"\nmlflow.register_model(model_uri, \"MyPyTorchModel\")\n```\n\n### Model Versioning and Stages\n```python\nfrom mlflow.tracking import MlflowClient\n\nclient = MlflowClient()\n\n# Transition model to different stages\nclient.transition_model_version_stage(\n    name=\"MyPyTorchModel\",\n    version=1,\n    stage=\"Production\"\n)\n\n# Get model by stage\nmodel_version = client.get_latest_versions(\n    \"MyPyTorchModel\", \n    stages=[\"Production\"]\n)[0]\n```\n\n### Load Registered Model\n```python\n# Load model from registry\nmodel = mlflow.pytorch.load_model(\n    model_uri=f\"models:/MyPyTorchModel/Production\"\n)\n\n# Or load specific version\nmodel = mlflow.pytorch.load_model(\n    model_uri=f\"models:/MyPyTorchModel/1\"\n)\n```\n\n## Model Deployment\n\n### Local Serving\n```python\n# Serve model locally\n# Run in terminal:\n# mlflow models serve -m models:/MyPyTorchModel/Production -p 1234\n```\n\n### Prediction with Served Model\n```python\nimport requests\nimport json\n\n# Prepare data\ndata = {\n    \"inputs\": [[1.0, 2.0, 3.0, 4.0]]  # Your input features\n}\n\n# Make prediction request\nresponse = requests.post(\n    \"http://localhost:1234/invocations\",\n    headers={\"Content-Type\": \"application/json\"},\n    data=json.dumps(data)\n)\n\npredictions = response.json()\nprint(predictions)\n```\n\n### Docker Deployment\n```bash\n# Build Docker image\nmlflow models build-docker -m models:/MyPyTorchModel/Production -n my-pytorch-model\n\n# Run Docker container\ndocker run -p 8080:8080 my-pytorch-model\n```\n\n## Advanced Features\n\n### Custom MLflow Model\n```python\nimport mlflow.pyfunc\n\nclass PyTorchModelWrapper(mlflow.pyfunc.PythonModel):\n    def __init__(self, model):\n        self.model = model\n    \n    def predict(self, context, model_input):\n        # Custom prediction logic\n        with torch.no_grad():\n            tensor_input = torch.FloatTensor(model_input.values)\n            predictions = self.model(tensor_input)\n            return predictions.numpy()\n\n# Log custom model\nwrapped_model = PyTorchModelWrapper(model)\nmlflow.pyfunc.log_model(\n    \"custom_model\", \n    python_model=wrapped_model\n)\n```\n\n### Automatic Logging\n```python\n# Enable automatic logging\nmlflow.pytorch.autolog()\n\n# Your training code - metrics and models are logged automatically\nwith mlflow.start_run():\n    # Training happens here\n    pass\n```\n\n### Logging Hyperparameter Sweeps\n```python\nimport itertools\n\n# Define hyperparameter grid\nparam_grid = {\n    'learning_rate': [0.001, 0.01, 0.1],\n    'hidden_size': [64, 128, 256],\n    'batch_size': [32, 64, 128]\n}\n\n# Run experiments\nfor params in [dict(zip(param_grid.keys(), v)) \n               for v in itertools.product(*param_grid.values())]:\n    with mlflow.start_run():\n        # Log parameters\n        for key, value in params.items():\n            mlflow.log_param(key, value)\n        \n        # Train model with these parameters\n        model = train_with_params(params)\n        \n        # Log results\n        mlflow.log_metric(\"final_accuracy\", accuracy)\n        mlflow.pytorch.log_model(model, \"model\")\n```\n\n### Logging Artifacts and Plots\n```python\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create and log plots\ndef log_training_plots(train_losses, val_losses):\n    plt.figure(figsize=(10, 6))\n    plt.plot(train_losses, label='Training Loss')\n    plt.plot(val_losses, label='Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.title('Training and Validation Loss')\n    plt.savefig('loss_plot.png')\n    mlflow.log_artifact('loss_plot.png')\n    plt.close()\n\n# Log confusion matrix\ndef log_confusion_matrix(y_true, y_pred, class_names):\n    from sklearn.metrics import confusion_matrix\n    import seaborn as sns\n    \n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                xticklabels=class_names, yticklabels=class_names)\n    plt.title('Confusion Matrix')\n    plt.savefig('confusion_matrix.png')\n    mlflow.log_artifact('confusion_matrix.png')\n    plt.close()\n```\n\n## Best Practices\n\n### 1. Organize Experiments\n```python\n# Use descriptive experiment names\nmlflow.set_experiment(\"image_classification_resnet\")\n\n# Use run names for specific configurations\nwith mlflow.start_run(run_name=\"resnet50_adam_lr001\"):\n    pass\n```\n\n### 2. Comprehensive Logging\n```python\ndef comprehensive_logging(model, optimizer, criterion, config):\n    # Log hyperparameters\n    mlflow.log_params(config)\n    \n    # Log model architecture info\n    total_params = sum(p.numel() for p in model.parameters())\n    mlflow.log_param(\"total_parameters\", total_params)\n    mlflow.log_param(\"model_architecture\", str(model))\n    \n    # Log optimizer info\n    mlflow.log_param(\"optimizer\", type(optimizer).__name__)\n    mlflow.log_param(\"criterion\", type(criterion).__name__)\n    \n    # Log system info\n    mlflow.log_param(\"cuda_available\", torch.cuda.is_available())\n    if torch.cuda.is_available():\n        mlflow.log_param(\"gpu_name\", torch.cuda.get_device_name(0))\n```\n\n### 3. Error Handling\n```python\ndef safe_mlflow_run(training_function, **kwargs):\n    try:\n        with mlflow.start_run():\n            result = training_function(**kwargs)\n            mlflow.log_param(\"status\", \"success\")\n            return result\n    except Exception as e:\n        mlflow.log_param(\"status\", \"failed\")\n        mlflow.log_param(\"error\", str(e))\n        raise e\n```\n\n### 4. Model Comparison\n```python\ndef compare_models():\n    # Get experiment\n    experiment = mlflow.get_experiment_by_name(\"pytorch_experiments\")\n    runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n    \n    # Sort by accuracy\n    best_runs = runs.sort_values(\"metrics.accuracy\", ascending=False)\n    \n    print(\"Top 5 models by accuracy:\")\n    print(best_runs[[\"run_id\", \"metrics.accuracy\", \"params.learning_rate\"]].head())\n```\n\n### 5. Model Loading Best Practices\n```python\ndef load_model_safely(model_uri):\n    try:\n        model = mlflow.pytorch.load_model(model_uri)\n        model.eval()  # Set to evaluation mode\n        return model\n    except Exception as e:\n        print(f\"Error loading model: {e}\")\n        return None\n\n# Usage\nmodel = load_model_safely(\"models:/MyPyTorchModel/Production\")\nif model:\n    # Use model for inference\n    pass\n```\n\n## Summary\n\nMLflow provides a comprehensive solution for managing PyTorch ML workflows:\n\n- **Experiment Tracking**: Log parameters, metrics, and artifacts\n- **Model Management**: Version and organize your models\n- **Model Registry**: Centralized model store with lifecycle management  \n- **Deployment**: Easy model serving and deployment options\n- **Reproducibility**: Track everything needed to reproduce experiments\n\nStart with basic experiment tracking, then gradually adopt more advanced features like the model registry and deployment capabilities as your ML workflow matures.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}