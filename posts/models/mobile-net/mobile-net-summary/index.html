<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Krishnatheja Vanka">
<meta name="dcterms.date" content="2025-07-19">

<title>MobileNet: Efficient Neural Networks for Mobile Vision Applications – Krishnatheja Vanka’s Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<link href="../../../../favicon.ico" rel="icon">
<script src="../../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-dark-2fef5ea3f8957b3e4ecc936fc74692ca.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-62c28fcd870f55f61984f019219cbd7c.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../../site_libs/bootstrap/bootstrap-dark-5a86c4bd0c1f9981a70f893fdae069f2.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../../../site_libs/bootstrap/bootstrap-62c28fcd870f55f61984f019219cbd7c.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../../styles/styles.css">
</head>

<body class="floating nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../../index.html">
    <span class="navbar-title">Krishnatheja Vanka’s Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../about.html"> 
<span class="menu-text">About me</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/theja-vanka"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-page-right">
      <h1 class="title">MobileNet: Efficient Neural Networks for Mobile Vision Applications</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">research</div>
                <div class="quarto-category">intermediate</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta column-page-right">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Krishnatheja Vanka </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">July 19, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#mobilenet-efficient-neural-networks-for-mobile-vision-applications" id="toc-mobilenet-efficient-neural-networks-for-mobile-vision-applications" class="nav-link active" data-scroll-target="#mobilenet-efficient-neural-networks-for-mobile-vision-applications">MobileNet: Efficient Neural Networks for Mobile Vision Applications</a>
  <ul class="collapse">
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#core-innovation-depthwise-separable-convolutions" id="toc-core-innovation-depthwise-separable-convolutions" class="nav-link" data-scroll-target="#core-innovation-depthwise-separable-convolutions">Core Innovation: Depthwise Separable Convolutions</a>
  <ul class="collapse">
  <li><a href="#understanding-standard-convolutions" id="toc-understanding-standard-convolutions" class="nav-link" data-scroll-target="#understanding-standard-convolutions">Understanding Standard Convolutions</a></li>
  <li><a href="#depthwise-separable-convolutions" id="toc-depthwise-separable-convolutions" class="nav-link" data-scroll-target="#depthwise-separable-convolutions">Depthwise Separable Convolutions</a></li>
  <li><a href="#efficiency-gains" id="toc-efficiency-gains" class="nav-link" data-scroll-target="#efficiency-gains">Efficiency Gains</a></li>
  </ul></li>
  <li><a href="#mobilenet-architecture" id="toc-mobilenet-architecture" class="nav-link" data-scroll-target="#mobilenet-architecture">MobileNet Architecture</a>
  <ul class="collapse">
  <li><a href="#overall-structure" id="toc-overall-structure" class="nav-link" data-scroll-target="#overall-structure">Overall Structure</a></li>
  <li><a href="#width-and-resolution-multipliers" id="toc-width-and-resolution-multipliers" class="nav-link" data-scroll-target="#width-and-resolution-multipliers">Width and Resolution Multipliers</a></li>
  </ul></li>
  <li><a href="#training-and-implementation-details" id="toc-training-and-implementation-details" class="nav-link" data-scroll-target="#training-and-implementation-details">Training and Implementation Details</a>
  <ul class="collapse">
  <li><a href="#training-procedure" id="toc-training-procedure" class="nav-link" data-scroll-target="#training-procedure">Training Procedure</a></li>
  <li><a href="#batch-normalization-and-activation" id="toc-batch-normalization-and-activation" class="nav-link" data-scroll-target="#batch-normalization-and-activation">Batch Normalization and Activation</a></li>
  <li><a href="#dropout-and-regularization" id="toc-dropout-and-regularization" class="nav-link" data-scroll-target="#dropout-and-regularization">Dropout and Regularization</a></li>
  </ul></li>
  <li><a href="#performance-analysis" id="toc-performance-analysis" class="nav-link" data-scroll-target="#performance-analysis">Performance Analysis</a>
  <ul class="collapse">
  <li><a href="#accuracy-vs.-efficiency-trade-offs" id="toc-accuracy-vs.-efficiency-trade-offs" class="nav-link" data-scroll-target="#accuracy-vs.-efficiency-trade-offs">Accuracy vs.&nbsp;Efficiency Trade-offs</a></li>
  <li><a href="#comparison-with-other-architectures" id="toc-comparison-with-other-architectures" class="nav-link" data-scroll-target="#comparison-with-other-architectures">Comparison with Other Architectures</a></li>
  <li><a href="#ablation-studies" id="toc-ablation-studies" class="nav-link" data-scroll-target="#ablation-studies">Ablation Studies</a></li>
  </ul></li>
  <li><a href="#evolution-mobilenetv2-and-beyond" id="toc-evolution-mobilenetv2-and-beyond" class="nav-link" data-scroll-target="#evolution-mobilenetv2-and-beyond">Evolution: MobileNetV2 and Beyond</a>
  <ul class="collapse">
  <li><a href="#mobilenetv2-improvements" id="toc-mobilenetv2-improvements" class="nav-link" data-scroll-target="#mobilenetv2-improvements">MobileNetV2 Improvements</a></li>
  <li><a href="#mobilenetv3" id="toc-mobilenetv3" class="nav-link" data-scroll-target="#mobilenetv3">MobileNetV3</a></li>
  </ul></li>
  <li><a href="#applications-and-use-cases" id="toc-applications-and-use-cases" class="nav-link" data-scroll-target="#applications-and-use-cases">Applications and Use Cases</a>
  <ul class="collapse">
  <li><a href="#image-classification" id="toc-image-classification" class="nav-link" data-scroll-target="#image-classification">Image Classification</a></li>
  <li><a href="#object-detection" id="toc-object-detection" class="nav-link" data-scroll-target="#object-detection">Object Detection</a></li>
  <li><a href="#semantic-segmentation" id="toc-semantic-segmentation" class="nav-link" data-scroll-target="#semantic-segmentation">Semantic Segmentation</a></li>
  <li><a href="#transfer-learning" id="toc-transfer-learning" class="nav-link" data-scroll-target="#transfer-learning">Transfer Learning</a></li>
  </ul></li>
  <li><a href="#deployment-considerations" id="toc-deployment-considerations" class="nav-link" data-scroll-target="#deployment-considerations">Deployment Considerations</a>
  <ul class="collapse">
  <li><a href="#quantization" id="toc-quantization" class="nav-link" data-scroll-target="#quantization">Quantization</a></li>
  <li><a href="#hardware-optimization" id="toc-hardware-optimization" class="nav-link" data-scroll-target="#hardware-optimization">Hardware Optimization</a></li>
  <li><a href="#framework-support" id="toc-framework-support" class="nav-link" data-scroll-target="#framework-support">Framework Support</a></li>
  </ul></li>
  <li><a href="#limitations-and-considerations" id="toc-limitations-and-considerations" class="nav-link" data-scroll-target="#limitations-and-considerations">Limitations and Considerations</a>
  <ul class="collapse">
  <li><a href="#accuracy-trade-offs" id="toc-accuracy-trade-offs" class="nav-link" data-scroll-target="#accuracy-trade-offs">Accuracy Trade-offs</a></li>
  <li><a href="#architecture-constraints" id="toc-architecture-constraints" class="nav-link" data-scroll-target="#architecture-constraints">Architecture Constraints</a></li>
  <li><a href="#training-considerations" id="toc-training-considerations" class="nav-link" data-scroll-target="#training-considerations">Training Considerations</a></li>
  </ul></li>
  <li><a href="#future-directions-and-research" id="toc-future-directions-and-research" class="nav-link" data-scroll-target="#future-directions-and-research">Future Directions and Research</a>
  <ul class="collapse">
  <li><a href="#architectural-innovations" id="toc-architectural-innovations" class="nav-link" data-scroll-target="#architectural-innovations">Architectural Innovations</a></li>
  <li><a href="#hardware-software-co-design" id="toc-hardware-software-co-design" class="nav-link" data-scroll-target="#hardware-software-co-design">Hardware-Software Co-design</a></li>
  <li><a href="#automated-architecture-design" id="toc-automated-architecture-design" class="nav-link" data-scroll-target="#automated-architecture-design">Automated Architecture Design</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block column-page-right" id="quarto-document-content">






<section id="mobilenet-efficient-neural-networks-for-mobile-vision-applications" class="level1">
<h1>MobileNet: Efficient Neural Networks for Mobile Vision Applications</h1>
<p><img src="mobnet.png" class="img-fluid" width="600"></p>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>MobileNet represents a revolutionary approach to deep learning architecture design, specifically optimized for mobile and embedded vision applications. Introduced by Google researchers in 2017, MobileNet addresses one of the most pressing challenges in deploying deep neural networks: achieving high accuracy while maintaining computational efficiency on resource-constrained devices.</p>
<p>The traditional approach to neural network design focused primarily on accuracy, often at the expense of computational complexity. Networks like VGGNet, ResNet, and Inception achieved remarkable performance on image classification tasks but required substantial computational resources, making them impractical for mobile deployment. MobileNet fundamentally changed this paradigm by introducing depthwise separable convolutions, a technique that dramatically reduces the number of parameters and computational operations while preserving much of the representational power of traditional convolutional neural networks.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Key Innovation
</div>
</div>
<div class="callout-body-container callout-body">
<p>MobileNet’s primary contribution is the introduction of <strong>depthwise separable convolutions</strong>, which provide an 8-9x reduction in computational cost compared to standard convolutions with minimal accuracy loss.</p>
</div>
</div>
</section>
<section id="core-innovation-depthwise-separable-convolutions" class="level2">
<h2 class="anchored" data-anchor-id="core-innovation-depthwise-separable-convolutions">Core Innovation: Depthwise Separable Convolutions</h2>
<section id="understanding-standard-convolutions" class="level3">
<h3 class="anchored" data-anchor-id="understanding-standard-convolutions">Understanding Standard Convolutions</h3>
<p>To appreciate MobileNet’s innovation, it’s essential to understand how standard convolutions work. A standard convolutional layer applies a set of filters across the input feature map. For an input feature map of size <span class="math inline">\(D_F \times D_F \times M\)</span> (height, width, channels) and <span class="math inline">\(N\)</span> output channels with kernel size <span class="math inline">\(D_K \times D_K\)</span>, a standard convolution requires:</p>
<ul>
<li><strong>Parameters</strong>: <span class="math inline">\(D_K \times D_K \times M \times N\)</span></li>
<li><strong>Computational cost</strong>: <span class="math inline">\(D_K \times D_K \times M \times N \times D_F \times D_F\)</span></li>
</ul>
<p>This computational cost grows rapidly with the number of input and output channels, making standard convolutions expensive for mobile applications.</p>
</section>
<section id="depthwise-separable-convolutions" class="level3">
<h3 class="anchored" data-anchor-id="depthwise-separable-convolutions">Depthwise Separable Convolutions</h3>
<p>MobileNet’s key innovation lies in factorizing standard convolutions into two separate operations:</p>
<ol type="1">
<li><strong>Depthwise Convolution</strong>: Applies a single filter to each input channel separately</li>
<li><strong>Pointwise Convolution</strong>: Uses 1×1 convolutions to combine the outputs of the depthwise convolution</li>
</ol>
<section id="depthwise-convolution" class="level4">
<h4 class="anchored" data-anchor-id="depthwise-convolution">Depthwise Convolution</h4>
<p>The depthwise convolution applies a single convolutional filter to each input channel. For <span class="math inline">\(M\)</span> input channels, this requires <span class="math inline">\(M\)</span> filters of size <span class="math inline">\(D_K \times D_K \times 1\)</span>. The computational cost is:</p>
<ul>
<li><strong>Parameters</strong>: <span class="math inline">\(D_K \times D_K \times M\)</span></li>
<li><strong>Computational cost</strong>: <span class="math inline">\(D_K \times D_K \times M \times D_F \times D_F\)</span></li>
</ul>
</section>
<section id="pointwise-convolution" class="level4">
<h4 class="anchored" data-anchor-id="pointwise-convolution">Pointwise Convolution</h4>
<p>The pointwise convolution uses 1×1 convolutions to create new features by computing linear combinations of the input channels. This step requires:</p>
<ul>
<li><strong>Parameters</strong>: <span class="math inline">\(M \times N\)</span></li>
<li><strong>Computational cost</strong>: <span class="math inline">\(M \times N \times D_F \times D_F\)</span></li>
</ul>
</section>
</section>
<section id="efficiency-gains" class="level3">
<h3 class="anchored" data-anchor-id="efficiency-gains">Efficiency Gains</h3>
<p>The total cost of depthwise separable convolution is the sum of depthwise and pointwise convolutions:</p>
<ul>
<li><strong>Total parameters</strong>: <span class="math inline">\(D_K \times D_K \times M + M \times N\)</span></li>
<li><strong>Total computational cost</strong>: <span class="math inline">\((D_K \times D_K \times M \times D_F \times D_F) + (M \times N \times D_F \times D_F)\)</span></li>
</ul>
<p>Compared to standard convolution, the reduction in computational cost is:</p>
<p><span class="math display">\[
\text{Reduction} = \frac{D_K^2 \times M \times D_F^2 + M \times N \times D_F^2}{D_K^2 \times M \times N \times D_F^2} = \frac{1}{N} + \frac{1}{D_K^2}
\]</span></p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Efficiency Example
</div>
</div>
<div class="callout-body-container callout-body">
<p>For typical values (<span class="math inline">\(D_K = 3\)</span>, <span class="math inline">\(N = 256\)</span>), this represents approximately an <strong>8-9x reduction</strong> in computational cost with minimal accuracy loss.</p>
</div>
</div>
</section>
</section>
<section id="mobilenet-architecture" class="level2">
<h2 class="anchored" data-anchor-id="mobilenet-architecture">MobileNet Architecture</h2>
<section id="overall-structure" class="level3">
<h3 class="anchored" data-anchor-id="overall-structure">Overall Structure</h3>
<p>MobileNet follows a straightforward architecture based on depthwise separable convolutions. The network begins with a standard 3×3 convolution followed by 13 depthwise separable convolution layers. Each depthwise separable convolution is followed by batch normalization and ReLU activation.</p>
<p>The architecture progressively reduces spatial resolution while increasing the number of channels, following the general pattern established by successful CNN architectures. The network concludes with global average pooling, a fully connected layer, and softmax activation for classification.</p>
</section>
<section id="width-and-resolution-multipliers" class="level3">
<h3 class="anchored" data-anchor-id="width-and-resolution-multipliers">Width and Resolution Multipliers</h3>
<p>MobileNet introduces two hyperparameters to provide additional control over the trade-off between accuracy and efficiency:</p>
<section id="width-multiplier-α" class="level4">
<h4 class="anchored" data-anchor-id="width-multiplier-α">Width Multiplier (α)</h4>
<p>The width multiplier <span class="math inline">\(\alpha \in (0,1]\)</span> uniformly reduces the number of channels in each layer. With width multiplier <span class="math inline">\(\alpha\)</span>, the number of input channels <span class="math inline">\(M\)</span> becomes <span class="math inline">\(\alpha M\)</span> and the number of output channels <span class="math inline">\(N\)</span> becomes <span class="math inline">\(\alpha N\)</span>. This reduces computational cost by approximately <span class="math inline">\(\alpha^2\)</span>.</p>
<p>Common values for <span class="math inline">\(\alpha\)</span> include:</p>
<ul>
<li>1.0 (full model)</li>
<li>0.75</li>
<li>0.5</li>
<li>0.25</li>
</ul>
</section>
<section id="resolution-multiplier-ρ" class="level4">
<h4 class="anchored" data-anchor-id="resolution-multiplier-ρ">Resolution Multiplier (ρ)</h4>
<p>The resolution multiplier <span class="math inline">\(\rho \in (0,1]\)</span> reduces the input image resolution. The input image size becomes <span class="math inline">\(\rho D_F \times \rho D_F\)</span>, which reduces computational cost by approximately <span class="math inline">\(\rho^2\)</span>.</p>
<p>Typical values for <span class="math inline">\(\rho\)</span> correspond to common input resolutions: 224, 192, 160, and 128 pixels.</p>
</section>
</section>
</section>
<section id="training-and-implementation-details" class="level2">
<h2 class="anchored" data-anchor-id="training-and-implementation-details">Training and Implementation Details</h2>
<section id="training-procedure" class="level3">
<h3 class="anchored" data-anchor-id="training-procedure">Training Procedure</h3>
<p>MobileNet models are typically trained using standard techniques for image classification:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 57%">
<col style="width: 42%">
</colgroup>
<thead>
<tr class="header">
<th>Parameter</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Optimizer</strong></td>
<td>RMSprop with decay 0.9 and momentum 0.9</td>
</tr>
<tr class="even">
<td><strong>Learning Rate</strong></td>
<td>Initial rate of 0.045 with exponential decay every two epochs</td>
</tr>
<tr class="odd">
<td><strong>Weight Decay</strong></td>
<td>L2 regularization with weight decay of 4e-5</td>
</tr>
<tr class="even">
<td><strong>Batch Size</strong></td>
<td>Typically 96-128 depending on available memory</td>
</tr>
<tr class="odd">
<td><strong>Data Augmentation</strong></td>
<td>Random crops, horizontal flips, and color jittering</td>
</tr>
</tbody>
</table>
</section>
<section id="batch-normalization-and-activation" class="level3">
<h3 class="anchored" data-anchor-id="batch-normalization-and-activation">Batch Normalization and Activation</h3>
<p>Each convolutional layer in MobileNet is followed by batch normalization and ReLU6 activation. ReLU6 is preferred over standard ReLU because it is more robust when used with low-precision arithmetic, making it suitable for mobile deployment where quantization is often employed.</p>
</section>
<section id="dropout-and-regularization" class="level3">
<h3 class="anchored" data-anchor-id="dropout-and-regularization">Dropout and Regularization</h3>
<p>MobileNet employs several regularization techniques:</p>
<ul>
<li>Batch normalization after each convolutional layer</li>
<li>Dropout with rate 0.001 before the final classification layer</li>
<li>L2 weight decay as mentioned above</li>
</ul>
</section>
</section>
<section id="performance-analysis" class="level2">
<h2 class="anchored" data-anchor-id="performance-analysis">Performance Analysis</h2>
<section id="accuracy-vs.-efficiency-trade-offs" class="level3">
<h3 class="anchored" data-anchor-id="accuracy-vs.-efficiency-trade-offs">Accuracy vs.&nbsp;Efficiency Trade-offs</h3>
<p>MobileNet achieves remarkable efficiency gains while maintaining competitive accuracy. On ImageNet classification:</p>
<ul>
<li><strong>MobileNet-224</strong> (α=1.0): 70.6% top-1 accuracy with 569M multiply-adds</li>
<li><strong>VGG-16</strong>: 71.5% top-1 accuracy with 15.3B multiply-adds</li>
</ul>
<p>This represents a <strong>27x reduction</strong> in computational cost for only 0.9% accuracy loss.</p>
</section>
<section id="comparison-with-other-architectures" class="level3">
<h3 class="anchored" data-anchor-id="comparison-with-other-architectures">Comparison with Other Architectures</h3>
<p>MobileNet’s efficiency becomes particularly apparent when compared to other popular architectures:</p>
<div id="tbl-performance" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-performance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Model Performance Comparison
</figcaption>
<div aria-describedby="tbl-performance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th>Model</th>
<th>Top-1 Accuracy</th>
<th>Million Parameters</th>
<th>Million Multiply-Adds</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>MobileNet</td>
<td>70.6%</td>
<td>4.2</td>
<td>569</td>
</tr>
<tr class="even">
<td>GoogleNet</td>
<td>69.8%</td>
<td>6.8</td>
<td>1550</td>
</tr>
<tr class="odd">
<td>VGG-16</td>
<td>71.5%</td>
<td>138</td>
<td>15300</td>
</tr>
<tr class="even">
<td>Inception V3</td>
<td>78.0%</td>
<td>23.8</td>
<td>5720</td>
</tr>
<tr class="odd">
<td>ResNet-50</td>
<td>76.0%</td>
<td>25.5</td>
<td>3800</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>MobileNet achieves the best accuracy-to-computation ratio among these models, making it ideal for mobile deployment.</p>
</section>
<section id="ablation-studies" class="level3">
<h3 class="anchored" data-anchor-id="ablation-studies">Ablation Studies</h3>
<p>Research has shown that various design choices in MobileNet contribute to its effectiveness:</p>
<ol type="1">
<li><strong>Depthwise vs.&nbsp;Standard Convolution</strong>: Depthwise separable convolutions provide 8-9x computational savings with minimal accuracy loss</li>
<li><strong>Width Multiplier Impact</strong>: Reducing width multiplier from 1.0 to 0.75 saves 40% computation with only 2.4% accuracy drop</li>
<li><strong>Resolution Multiplier Impact</strong>: Reducing input resolution from 224 to 192 saves 30% computation with 1.3% accuracy drop</li>
</ol>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Key Finding
</div>
</div>
<div class="callout-body-container callout-body">
<p>The ablation studies demonstrate that MobileNet’s design choices are well-justified, with each component contributing meaningfully to the overall efficiency-accuracy trade-off.</p>
</div>
</div>
</section>
</section>
<section id="evolution-mobilenetv2-and-beyond" class="level2">
<h2 class="anchored" data-anchor-id="evolution-mobilenetv2-and-beyond">Evolution: MobileNetV2 and Beyond</h2>
<section id="mobilenetv2-improvements" class="level3">
<h3 class="anchored" data-anchor-id="mobilenetv2-improvements">MobileNetV2 Improvements</h3>
<p>MobileNetV2, introduced in 2018, built upon the original MobileNet with several key improvements:</p>
<section id="inverted-residuals" class="level4">
<h4 class="anchored" data-anchor-id="inverted-residuals">Inverted Residuals</h4>
<p>MobileNetV2 introduces inverted residual blocks, which expand the number of channels before the depthwise convolution and then project back to a lower-dimensional space. This design maintains representational capacity while reducing memory usage.</p>
</section>
<section id="linear-bottlenecks" class="level4">
<h4 class="anchored" data-anchor-id="linear-bottlenecks">Linear Bottlenecks</h4>
<p>The final layer of each inverted residual block uses linear activation instead of ReLU. This prevents the loss of information that can occur when ReLU is applied to low-dimensional representations.</p>
</section>
<section id="improved-performance" class="level4">
<h4 class="anchored" data-anchor-id="improved-performance">Improved Performance</h4>
<p>MobileNetV2 achieves better accuracy than the original MobileNet while maintaining similar computational efficiency. On ImageNet, MobileNetV2 achieves 72.0% top-1 accuracy with similar computational cost to the original MobileNet.</p>
</section>
</section>
<section id="mobilenetv3" class="level3">
<h3 class="anchored" data-anchor-id="mobilenetv3">MobileNetV3</h3>
<p>MobileNetV3, released in 2019, incorporates several advanced techniques:</p>
<ul>
<li><strong>Neural Architecture Search (NAS)</strong>: Automated architecture design for optimal efficiency</li>
<li><strong>SE (Squeeze-and-Excitation) blocks</strong>: Attention mechanisms for better feature representation</li>
<li><strong>h-swish activation</strong>: More efficient than ReLU for mobile deployment</li>
<li><strong>Platform-aware NAS</strong>: Optimization specifically for mobile hardware</li>
</ul>
</section>
</section>
<section id="applications-and-use-cases" class="level2">
<h2 class="anchored" data-anchor-id="applications-and-use-cases">Applications and Use Cases</h2>
<section id="image-classification" class="level3">
<h3 class="anchored" data-anchor-id="image-classification">Image Classification</h3>
<p>MobileNet excels at image classification tasks on mobile devices. Its efficiency makes it suitable for real-time classification in mobile apps, enabling features like:</p>
<ul>
<li>Real-time object recognition in camera applications</li>
<li>Automatic photo tagging and organization</li>
<li>Visual search capabilities</li>
<li>Augmented reality applications</li>
</ul>
</section>
<section id="object-detection" class="level3">
<h3 class="anchored" data-anchor-id="object-detection">Object Detection</h3>
<p>MobileNet serves as an excellent backbone for mobile object detection systems:</p>
<ul>
<li><strong>MobileNet-SSD</strong>: Combines MobileNet with Single Shot Detector for efficient object detection</li>
<li><strong>MobileNetV2-SSDLite</strong>: Further optimized for mobile deployment</li>
<li>Applications in autonomous vehicles, robotics, and surveillance systems</li>
</ul>
</section>
<section id="semantic-segmentation" class="level3">
<h3 class="anchored" data-anchor-id="semantic-segmentation">Semantic Segmentation</h3>
<p>MobileNet has been adapted for semantic segmentation tasks:</p>
<ul>
<li><strong>DeepLabV3+</strong>: Uses MobileNet as encoder for efficient semantic segmentation</li>
<li>Applications in image editing, medical imaging, and autonomous navigation</li>
</ul>
</section>
<section id="transfer-learning" class="level3">
<h3 class="anchored" data-anchor-id="transfer-learning">Transfer Learning</h3>
<p>MobileNet’s pre-trained weights serve as excellent starting points for transfer learning:</p>
<ul>
<li>Fine-tuning for specialized classification tasks</li>
<li>Feature extraction for custom applications</li>
<li>Domain adaptation for specific use cases</li>
</ul>
</section>
</section>
<section id="deployment-considerations" class="level2">
<h2 class="anchored" data-anchor-id="deployment-considerations">Deployment Considerations</h2>
<section id="quantization" class="level3">
<h3 class="anchored" data-anchor-id="quantization">Quantization</h3>
<p>MobileNet’s design makes it particularly amenable to quantization, a technique that reduces the precision of weights and activations to decrease memory usage and increase inference speed:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true">8-bit Quantization</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">16-bit Quantization</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-3" role="tab" aria-controls="tabset-1-3" aria-selected="false">Dynamic Quantization</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<p>Reduces model size by 4x with minimal accuracy loss</p>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<p>Balanced approach between compression and accuracy</p>
</div>
<div id="tabset-1-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-3-tab">
<p>Runtime optimization for different deployment scenarios</p>
</div>
</div>
</div>
</section>
<section id="hardware-optimization" class="level3">
<h3 class="anchored" data-anchor-id="hardware-optimization">Hardware Optimization</h3>
<p>MobileNet’s architecture aligns well with mobile hardware capabilities:</p>
<ul>
<li><strong>ARM processors</strong>: Efficient execution on mobile CPUs</li>
<li><strong>Neural processing units (NPUs)</strong>: Dedicated hardware acceleration</li>
<li><strong>GPU acceleration</strong>: Optimized implementations for mobile GPUs</li>
</ul>
</section>
<section id="framework-support" class="level3">
<h3 class="anchored" data-anchor-id="framework-support">Framework Support</h3>
<p>MobileNet enjoys broad support across major deep learning frameworks:</p>
<ul>
<li><strong>TensorFlow Lite</strong>: Optimized for mobile deployment</li>
<li><strong>Core ML</strong>: Apple’s framework for iOS deployment</li>
<li><strong>ONNX</strong>: Cross-platform model representation</li>
<li><strong>PyTorch Mobile</strong>: Facebook’s mobile deployment solution</li>
</ul>
</section>
</section>
<section id="limitations-and-considerations" class="level2">
<h2 class="anchored" data-anchor-id="limitations-and-considerations">Limitations and Considerations</h2>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Trade-offs to Consider
</div>
</div>
<div class="callout-body-container callout-body">
<p>While MobileNet achieves impressive efficiency, practitioners should be aware of inherent trade-offs and limitations.</p>
</div>
</div>
<section id="accuracy-trade-offs" class="level3">
<h3 class="anchored" data-anchor-id="accuracy-trade-offs">Accuracy Trade-offs</h3>
<p>While MobileNet achieves impressive efficiency, there are inherent trade-offs:</p>
<ul>
<li>Lower accuracy compared to larger models on complex tasks</li>
<li>Reduced representational capacity may limit performance on fine-grained classification</li>
<li>Potential degradation in transfer learning performance for significantly different domains</li>
</ul>
</section>
<section id="architecture-constraints" class="level3">
<h3 class="anchored" data-anchor-id="architecture-constraints">Architecture Constraints</h3>
<p>MobileNet’s design imposes certain limitations:</p>
<ul>
<li>Fixed architecture pattern may not be optimal for all tasks</li>
<li>Limited flexibility compared to more modular architectures</li>
<li>Potential bottlenecks in very deep variants</li>
</ul>
</section>
<section id="training-considerations" class="level3">
<h3 class="anchored" data-anchor-id="training-considerations">Training Considerations</h3>
<p>Training MobileNet requires careful attention to:</p>
<ul>
<li>Regularization to prevent overfitting with fewer parameters</li>
<li>Learning rate scheduling for stable convergence</li>
<li>Data augmentation strategies to improve generalization</li>
</ul>
</section>
</section>
<section id="future-directions-and-research" class="level2">
<h2 class="anchored" data-anchor-id="future-directions-and-research">Future Directions and Research</h2>
<section id="architectural-innovations" class="level3">
<h3 class="anchored" data-anchor-id="architectural-innovations">Architectural Innovations</h3>
<p>Ongoing research continues to improve upon MobileNet’s design:</p>
<ul>
<li><strong>Attention mechanisms</strong>: Integration of self-attention for better feature representation</li>
<li><strong>Dynamic networks</strong>: Adaptive computation based on input complexity</li>
<li><strong>Multi-scale processing</strong>: Handling objects at different scales more effectively</li>
</ul>
</section>
<section id="hardware-software-co-design" class="level3">
<h3 class="anchored" data-anchor-id="hardware-software-co-design">Hardware-Software Co-design</h3>
<p>Future developments focus on closer integration between architecture and hardware:</p>
<ul>
<li><strong>Custom silicon</strong>: Processors designed specifically for efficient neural networks</li>
<li><strong>Edge computing</strong>: Distributed processing across multiple devices</li>
<li><strong>Federated learning</strong>: Training updates without centralized data collection</li>
</ul>
</section>
<section id="automated-architecture-design" class="level3">
<h3 class="anchored" data-anchor-id="automated-architecture-design">Automated Architecture Design</h3>
<p>Neural Architecture Search continues to evolve:</p>
<ul>
<li><strong>Differentiable NAS</strong>: More efficient architecture search methods</li>
<li><strong>Progressive search</strong>: Incremental architecture refinement</li>
<li><strong>Multi-objective optimization</strong>: Balancing multiple performance metrics</li>
</ul>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>MobileNet represents a paradigm shift in neural network design, demonstrating that significant efficiency gains are possible without sacrificing too much accuracy. By introducing depthwise separable convolutions and providing tunable parameters for accuracy-efficiency trade-offs, MobileNet has enabled the deployment of sophisticated computer vision capabilities on resource-constrained devices.</p>
<p>The impact of MobileNet extends beyond its immediate applications. It has influenced a generation of efficient neural network architectures and sparked renewed interest in the optimization of deep learning models for practical deployment. As mobile devices become increasingly powerful and AI capabilities more ubiquitous, MobileNet’s principles continue to guide the development of efficient, deployable neural networks.</p>
<p>The evolution from MobileNet to MobileNetV2 and V3 demonstrates the ongoing refinement of these principles, incorporating advances in neural architecture search, attention mechanisms, and hardware-aware optimization. As we look to the future, MobileNet’s legacy lies not just in its specific architectural contributions, but in its demonstration that efficiency and accuracy need not be mutually exclusive in deep learning system design.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
For Practitioners
</div>
</div>
<div class="callout-body-container callout-body">
<p>For practitioners and researchers working on mobile AI applications, MobileNet provides both a practical solution and a blueprint for designing efficient neural networks. Its success underscores the importance of considering deployment constraints from the earliest stages of model design.</p>
</div>
</div>
<p>For practitioners and researchers working on mobile AI applications, MobileNet provides both a practical solution and a blueprint for designing efficient neural networks. Its success underscores the importance of considering deployment constraints from the earliest stages of model design, rather than treating optimization as an afterthought. As the field continues to evolve, the principles pioneered by MobileNet will undoubtedly continue to influence the development of efficient, practical AI systems.</p>



</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/theja-vanka\.github\.io\/blogs\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>© 2025 Krishnatheja Vanka</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>