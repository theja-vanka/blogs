<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Krishnatheja Vanka">
<meta name="dcterms.date" content="2025-07-19">

<title>DenseNet: A Code Guide – Krishnatheja Vanka’s Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<link href="../../../../favicon.ico" rel="icon">
<script src="../../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-dark-b758ccaa5987ceb1b75504551e579abf.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-db7551fb198f90e53e140817f36f545d.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../../site_libs/bootstrap/bootstrap-dark-941aa739f4f6ead0e06d988344f7e38f.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../../../site_libs/bootstrap/bootstrap-db7551fb198f90e53e140817f36f545d.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../../styles/styles.css">
</head>

<body class="floating nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../../index.html">
    <span class="navbar-title">Krishnatheja Vanka’s Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../about.html"> 
<span class="menu-text">About me</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/theja-vanka"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-page-right">
      <h1 class="title">DenseNet: A Code Guide</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">code</div>
                <div class="quarto-category">tutorial</div>
                <div class="quarto-category">intermediate</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta column-page-right">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Krishnatheja Vanka </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">July 19, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#densenet-a-code-guide" id="toc-densenet-a-code-guide" class="nav-link active" data-scroll-target="#densenet-a-code-guide">DenseNet: A Code Guide</a>
  <ul class="collapse">
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#theoretical-foundation" id="toc-theoretical-foundation" class="nav-link" data-scroll-target="#theoretical-foundation">Theoretical Foundation</a>
  <ul class="collapse">
  <li><a href="#the-dense-connectivity-pattern" id="toc-the-dense-connectivity-pattern" class="nav-link" data-scroll-target="#the-dense-connectivity-pattern">The Dense Connectivity Pattern</a></li>
  <li><a href="#growth-rate-and-feature-map-management" id="toc-growth-rate-and-feature-map-management" class="nav-link" data-scroll-target="#growth-rate-and-feature-map-management">Growth Rate and Feature Map Management</a></li>
  </ul></li>
  <li><a href="#architecture-components" id="toc-architecture-components" class="nav-link" data-scroll-target="#architecture-components">Architecture Components</a>
  <ul class="collapse">
  <li><a href="#dense-blocks" id="toc-dense-blocks" class="nav-link" data-scroll-target="#dense-blocks">Dense Blocks</a></li>
  <li><a href="#transition-layers" id="toc-transition-layers" class="nav-link" data-scroll-target="#transition-layers">Transition Layers</a></li>
  <li><a href="#composite-functions" id="toc-composite-functions" class="nav-link" data-scroll-target="#composite-functions">Composite Functions</a></li>
  </ul></li>
  <li><a href="#implementation-deep-dive" id="toc-implementation-deep-dive" class="nav-link" data-scroll-target="#implementation-deep-dive">Implementation Deep Dive</a>
  <ul class="collapse">
  <li><a href="#memory-efficiency-considerations" id="toc-memory-efficiency-considerations" class="nav-link" data-scroll-target="#memory-efficiency-considerations">Memory Efficiency Considerations</a></li>
  <li><a href="#implementation-variants" id="toc-implementation-variants" class="nav-link" data-scroll-target="#implementation-variants">Implementation Variants</a></li>
  </ul></li>
  <li><a href="#code-implementation" id="toc-code-implementation" class="nav-link" data-scroll-target="#code-implementation">Code Implementation</a></li>
  <li><a href="#performance-analysis-and-benchmarks" id="toc-performance-analysis-and-benchmarks" class="nav-link" data-scroll-target="#performance-analysis-and-benchmarks">Performance Analysis and Benchmarks</a>
  <ul class="collapse">
  <li><a href="#computational-complexity" id="toc-computational-complexity" class="nav-link" data-scroll-target="#computational-complexity">Computational Complexity</a></li>
  <li><a href="#benchmark-results" id="toc-benchmark-results" class="nav-link" data-scroll-target="#benchmark-results">Benchmark Results</a></li>
  <li><a href="#memory-optimization-strategies" id="toc-memory-optimization-strategies" class="nav-link" data-scroll-target="#memory-optimization-strategies">Memory Optimization Strategies</a></li>
  </ul></li>
  <li><a href="#training-considerations" id="toc-training-considerations" class="nav-link" data-scroll-target="#training-considerations">Training Considerations</a>
  <ul class="collapse">
  <li><a href="#hyperparameter-selection" id="toc-hyperparameter-selection" class="nav-link" data-scroll-target="#hyperparameter-selection">Hyperparameter Selection</a></li>
  <li><a href="#regularization-techniques" id="toc-regularization-techniques" class="nav-link" data-scroll-target="#regularization-techniques">Regularization Techniques</a></li>
  </ul></li>
  <li><a href="#applications-and-use-cases" id="toc-applications-and-use-cases" class="nav-link" data-scroll-target="#applications-and-use-cases">Applications and Use Cases</a>
  <ul class="collapse">
  <li><a href="#computer-vision-tasks" id="toc-computer-vision-tasks" class="nav-link" data-scroll-target="#computer-vision-tasks">Computer Vision Tasks</a></li>
  <li><a href="#transfer-learning" id="toc-transfer-learning" class="nav-link" data-scroll-target="#transfer-learning">Transfer Learning</a></li>
  </ul></li>
  <li><a href="#comparison-with-other-architectures" id="toc-comparison-with-other-architectures" class="nav-link" data-scroll-target="#comparison-with-other-architectures">Comparison with Other Architectures</a>
  <ul class="collapse">
  <li><a href="#densenet-vs-resnet" id="toc-densenet-vs-resnet" class="nav-link" data-scroll-target="#densenet-vs-resnet">DenseNet vs ResNet</a></li>
  <li><a href="#densenet-vs-inception" id="toc-densenet-vs-inception" class="nav-link" data-scroll-target="#densenet-vs-inception">DenseNet vs Inception</a></li>
  </ul></li>
  <li><a href="#recent-developments-and-variants" id="toc-recent-developments-and-variants" class="nav-link" data-scroll-target="#recent-developments-and-variants">Recent Developments and Variants</a>
  <ul class="collapse">
  <li><a href="#densenet-extensions" id="toc-densenet-extensions" class="nav-link" data-scroll-target="#densenet-extensions">DenseNet Extensions</a></li>
  <li><a href="#integration-with-modern-techniques" id="toc-integration-with-modern-techniques" class="nav-link" data-scroll-target="#integration-with-modern-techniques">Integration with Modern Techniques</a></li>
  </ul></li>
  <li><a href="#best-practices-and-recommendations" id="toc-best-practices-and-recommendations" class="nav-link" data-scroll-target="#best-practices-and-recommendations">Best Practices and Recommendations</a>
  <ul class="collapse">
  <li><a href="#architecture-design" id="toc-architecture-design" class="nav-link" data-scroll-target="#architecture-design">Architecture Design</a></li>
  <li><a href="#implementation-guidelines" id="toc-implementation-guidelines" class="nav-link" data-scroll-target="#implementation-guidelines">Implementation Guidelines</a></li>
  <li><a href="#training-optimization" id="toc-training-optimization" class="nav-link" data-scroll-target="#training-optimization">Training Optimization</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block column-page-right" id="quarto-document-content">






<section id="densenet-a-code-guide" class="level1">
<h1>DenseNet: A Code Guide</h1>
<p><img src="dncode.png" class="img-fluid" width="600"></p>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>DenseNet (Densely Connected Convolutional Networks) represents a paradigm shift in deep learning architecture design, introducing unprecedented connectivity patterns that revolutionize how information flows through neural networks. Proposed by Gao Huang, Zhuang Liu, Laurens van der Maaten, and Kilian Weinberger in 2017, DenseNet challenges the traditional sequential nature of convolutional neural networks by creating direct connections between every layer and all subsequent layers.</p>
<p>The fundamental insight behind DenseNet stems from addressing the vanishing gradient problem that plagued very deep networks. While ResNet introduced skip connections to enable training of deeper networks, DenseNet takes this concept to its logical extreme, creating a densely connected topology that maximizes information flow and gradient propagation throughout the entire network.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Key Innovation
</div>
</div>
<div class="callout-body-container callout-body">
<p>DenseNet’s core innovation lies in connecting each layer to every subsequent layer in the network, creating maximum information flow and feature reuse.</p>
</div>
</div>
</section>
<section id="theoretical-foundation" class="level2">
<h2 class="anchored" data-anchor-id="theoretical-foundation">Theoretical Foundation</h2>
<section id="the-dense-connectivity-pattern" class="level3">
<h3 class="anchored" data-anchor-id="the-dense-connectivity-pattern">The Dense Connectivity Pattern</h3>
<p>The core innovation of DenseNet lies in its connectivity pattern. In traditional CNNs, each layer receives input only from the previous layer. ResNet improved upon this by adding skip connections, allowing layers to receive input from both the previous layer and earlier layers through residual connections. DenseNet generalizes this concept by connecting each layer to every subsequent layer in the network.</p>
<p>Mathematically, if we consider a network with L layers, the lth layer receives feature maps from all preceding layers:</p>
<p><span class="math display">\[
x_l = H_l([x_0, x_1, ..., x_{l-1}])
\]</span></p>
<p>Where <span class="math inline">\([x_0, x_1, ..., x_{l-1}]\)</span> represents the concatenation of feature maps produced by layers 0 through l-1, and <span class="math inline">\(H_l\)</span> denotes the composite function performed by the lth layer.</p>
<p>This dense connectivity pattern creates several theoretical advantages:</p>
<ol type="1">
<li><p><strong>Maximum Information Flow</strong>: Every layer has direct access to the gradients from the loss function and the original input signal, ensuring efficient gradient flow during backpropagation.</p></li>
<li><p><strong>Feature Reuse</strong>: Lower-level features are directly accessible to higher-level layers, promoting feature reuse and reducing the need for redundant feature learning.</p></li>
<li><p><strong>Implicit Deep Supervision</strong>: Each layer receives supervision signals from all subsequent layers, creating an implicit form of deep supervision that improves learning efficiency.</p></li>
</ol>
</section>
<section id="growth-rate-and-feature-map-management" class="level3">
<h3 class="anchored" data-anchor-id="growth-rate-and-feature-map-management">Growth Rate and Feature Map Management</h3>
<p>A critical design parameter in DenseNet is the growth rate (k), which determines how many new feature maps each layer contributes to the global feature pool. If each layer produces k feature maps, then the lth layer receives <span class="math inline">\(k \times l\)</span> input feature maps from all preceding layers.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Growth Rate Guidelines
</div>
</div>
<div class="callout-body-container callout-body">
<p>Typical values for k range from 12 to 32, which is significantly smaller than the hundreds of feature maps common in traditional architectures like VGG or ResNet.</p>
</div>
</div>
<p>This growth pattern means that while each individual layer remains narrow (small k), the collective input to each layer grows linearly with depth. The growth rate serves as a global hyperparameter that controls the information flow throughout the network. A smaller growth rate forces the network to learn more efficient representations, while a larger growth rate provides more representational capacity at the cost of computational efficiency.</p>
</section>
</section>
<section id="architecture-components" class="level2">
<h2 class="anchored" data-anchor-id="architecture-components">Architecture Components</h2>
<section id="dense-blocks" class="level3">
<h3 class="anchored" data-anchor-id="dense-blocks">Dense Blocks</h3>
<p>Dense blocks form the fundamental building units of DenseNet. Within each dense block, every layer is connected to every subsequent layer through concatenation operations. The internal structure of a dense block implements the dense connectivity pattern while maintaining computational efficiency.</p>
<p>Each layer within a dense block typically consists of:</p>
<ul>
<li>Batch normalization</li>
<li>ReLU activation<br>
</li>
<li>3×3 convolution</li>
</ul>
<p>Some variants also include a 1×1 convolution (bottleneck layer) before the 3×3 convolution to reduce computational complexity, creating the DenseNet-BC (Bottleneck-Compression) variant.</p>
</section>
<section id="transition-layers" class="level3">
<h3 class="anchored" data-anchor-id="transition-layers">Transition Layers</h3>
<p>Between dense blocks, transition layers serve multiple critical functions:</p>
<ol type="1">
<li><p><strong>Dimensionality Reduction</strong>: As feature maps accumulate through concatenation within dense blocks, transition layers reduce the number of feature maps to control model complexity and computational requirements.</p></li>
<li><p><strong>Spatial Downsampling</strong>: Transition layers typically include average pooling operations to reduce spatial dimensions, enabling the network to learn hierarchical representations at different scales.</p></li>
<li><p><strong>Compression</strong>: The compression factor (θ) in transition layers, typically set to 0.5, determines how many feature maps are retained. This compression helps maintain computational efficiency while preserving essential information.</p></li>
</ol>
<p>A typical transition layer consists of:</p>
<ul>
<li>Batch normalization</li>
<li>1×1 convolution (for compression)</li>
<li>2×2 average pooling</li>
</ul>
</section>
<section id="composite-functions" class="level3">
<h3 class="anchored" data-anchor-id="composite-functions">Composite Functions</h3>
<p>The composite function <span class="math inline">\(H_l\)</span> in DenseNet typically follows the pre-activation design pattern:</p>
<p><strong>Batch Normalization → ReLU → Convolution</strong></p>
<p>This ordering, borrowed from ResNet improvements, ensures optimal gradient flow and training stability. The pre-activation design places the normalization and activation functions before the convolution operation, which has been shown to improve training dynamics in very deep networks.</p>
</section>
</section>
<section id="implementation-deep-dive" class="level2">
<h2 class="anchored" data-anchor-id="implementation-deep-dive">Implementation Deep Dive</h2>
<section id="memory-efficiency-considerations" class="level3">
<h3 class="anchored" data-anchor-id="memory-efficiency-considerations">Memory Efficiency Considerations</h3>
<p>One of the primary challenges in implementing DenseNet stems from its memory requirements. The concatenation operations required for dense connectivity can lead to significant memory consumption, especially during the backward pass when gradients must be stored for all connections.</p>
<p>Several optimization strategies address these memory concerns:</p>
<ol type="1">
<li><p><strong>Shared Memory Allocation</strong>: Implementing efficient memory sharing for concatenation operations reduces the memory footprint by avoiding unnecessary copying of feature maps.</p></li>
<li><p><strong>Gradient Checkpointing</strong>: For very deep DenseNet models, gradient checkpointing can trade computation for memory by recomputing intermediate activations during the backward pass instead of storing them.</p></li>
<li><p><strong>Efficient Concatenation</strong>: Using in-place operations where possible and optimizing the order of concatenation operations can significantly reduce memory usage.</p></li>
</ol>
</section>
<section id="implementation-variants" class="level3">
<h3 class="anchored" data-anchor-id="implementation-variants">Implementation Variants</h3>
<section id="densenet-bc-bottleneck-compression" class="level4">
<h4 class="anchored" data-anchor-id="densenet-bc-bottleneck-compression">DenseNet-BC (Bottleneck-Compression)</h4>
<p>The BC variant introduces bottleneck layers that use 1×1 convolutions to reduce the number of input feature maps before applying the 3×3 convolution. This modification significantly reduces computational complexity while maintaining representational capacity.</p>
<p>The bottleneck design modifies the composite function to: <strong>BN → ReLU → 1×1 Conv → BN → ReLU → 3×3 Conv</strong></p>
</section>
<section id="densenet-c-compression-only" class="level4">
<h4 class="anchored" data-anchor-id="densenet-c-compression-only">DenseNet-C (Compression Only)</h4>
<p>This variant applies compression in transition layers without using bottleneck layers within dense blocks, providing a middle ground between computational efficiency and architectural simplicity.</p>
</section>
</section>
</section>
<section id="code-implementation" class="level2">
<h2 class="anchored" data-anchor-id="code-implementation">Code Implementation</h2>
<p>Here’s a comprehensive PyTorch implementation of DenseNet:</p>
<div id="densenet-implementation" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> OrderedDict</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DenseLayer(nn.Module):</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_channels, growth_rate, bottleneck_size<span class="op">=</span><span class="dv">4</span>, dropout_rate<span class="op">=</span><span class="fl">0.0</span>):</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(DenseLayer, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Bottleneck layer (1x1 conv)</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bottleneck <span class="op">=</span> nn.Sequential(</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm2d(in_channels),</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(in_channels, bottleneck_size <span class="op">*</span> growth_rate, </span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>                     kernel_size<span class="op">=</span><span class="dv">1</span>, stride<span class="op">=</span><span class="dv">1</span>, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Main convolution layer (3x3 conv)</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.main_conv <span class="op">=</span> nn.Sequential(</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm2d(bottleneck_size <span class="op">*</span> growth_rate),</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(bottleneck_size <span class="op">*</span> growth_rate, growth_rate,</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>                     kernel_size<span class="op">=</span><span class="dv">3</span>, stride<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">1</span>, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout <span class="op">=</span> nn.Dropout(dropout_rate) <span class="cf">if</span> dropout_rate <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="va">None</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># x can be a tensor or a list of tensors (from concatenation)</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(x, torch.Tensor):</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>            concatenated_features <span class="op">=</span> x</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>            concatenated_features <span class="op">=</span> torch.cat(x, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply bottleneck</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>        bottleneck_output <span class="op">=</span> <span class="va">self</span>.bottleneck(concatenated_features)</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply main convolution</span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>        new_features <span class="op">=</span> <span class="va">self</span>.main_conv(bottleneck_output)</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply dropout if specified</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.dropout <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>            new_features <span class="op">=</span> <span class="va">self</span>.dropout(new_features)</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> new_features</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DenseBlock(nn.Module):</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_layers, in_channels, growth_rate, </span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>                 bottleneck_size<span class="op">=</span><span class="dv">4</span>, dropout_rate<span class="op">=</span><span class="fl">0.0</span>):</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(DenseBlock, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layers <span class="op">=</span> nn.ModuleList()</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_layers):</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>            current_in_channels <span class="op">=</span> in_channels <span class="op">+</span> i <span class="op">*</span> growth_rate</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>            layer <span class="op">=</span> DenseLayer(</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>                current_in_channels, </span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>                growth_rate, </span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>                bottleneck_size, </span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>                dropout_rate</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.layers.append(layer)</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>        features <span class="op">=</span> [x]</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> layer <span class="kw">in</span> <span class="va">self</span>.layers:</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>            new_features <span class="op">=</span> layer(features)</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>            features.append(new_features)</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.cat(features[<span class="dv">1</span>:], dim<span class="op">=</span><span class="dv">1</span>)  <span class="co"># Exclude original input</span></span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TransitionLayer(nn.Module):</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_channels, compression_factor<span class="op">=</span><span class="fl">0.5</span>):</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(TransitionLayer, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>        out_channels <span class="op">=</span> <span class="bu">int</span>(in_channels <span class="op">*</span> compression_factor)</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.transition <span class="op">=</span> nn.Sequential(</span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm2d(in_channels),</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(in_channels, out_channels, kernel_size<span class="op">=</span><span class="dv">1</span>, bias<span class="op">=</span><span class="va">False</span>),</span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>            nn.AvgPool2d(kernel_size<span class="op">=</span><span class="dv">2</span>, stride<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out_channels <span class="op">=</span> out_channels</span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.transition(x)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="densenet-main-class" class="cell" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DenseNet(nn.Module):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, growth_rate<span class="op">=</span><span class="dv">32</span>, block_config<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">12</span>, <span class="dv">24</span>, <span class="dv">16</span>),</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>                 num_init_features<span class="op">=</span><span class="dv">64</span>, bottleneck_size<span class="op">=</span><span class="dv">4</span>, </span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>                 compression_factor<span class="op">=</span><span class="fl">0.5</span>, dropout_rate<span class="op">=</span><span class="fl">0.0</span>, </span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>                 num_classes<span class="op">=</span><span class="dv">1000</span>):</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(DenseNet, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initial convolution and pooling</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.features <span class="op">=</span> nn.Sequential(OrderedDict([</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>            (<span class="st">'conv0'</span>, nn.Conv2d(<span class="dv">3</span>, num_init_features, </span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>                               kernel_size<span class="op">=</span><span class="dv">7</span>, stride<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="dv">3</span>, bias<span class="op">=</span><span class="va">False</span>)),</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>            (<span class="st">'norm0'</span>, nn.BatchNorm2d(num_init_features)),</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>            (<span class="st">'relu0'</span>, nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>)),</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>            (<span class="st">'pool0'</span>, nn.MaxPool2d(kernel_size<span class="op">=</span><span class="dv">3</span>, stride<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>        ]))</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Dense blocks and transition layers</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>        num_features <span class="op">=</span> num_init_features</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, num_layers <span class="kw">in</span> <span class="bu">enumerate</span>(block_config):</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Add dense block</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>            block <span class="op">=</span> DenseBlock(</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>                num_layers<span class="op">=</span>num_layers,</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>                in_channels<span class="op">=</span>num_features,</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>                growth_rate<span class="op">=</span>growth_rate,</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>                bottleneck_size<span class="op">=</span>bottleneck_size,</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>                dropout_rate<span class="op">=</span>dropout_rate</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.features.add_module(<span class="ss">f'denseblock</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span>, block)</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>            num_features <span class="op">+=</span> num_layers <span class="op">*</span> growth_rate</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Add transition layer (except after the last dense block)</span></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> i <span class="op">!=</span> <span class="bu">len</span>(block_config) <span class="op">-</span> <span class="dv">1</span>:</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>                transition <span class="op">=</span> TransitionLayer(num_features, compression_factor)</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.features.add_module(<span class="ss">f'transition</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span>, transition)</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>                num_features <span class="op">=</span> transition.out_channels</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Final batch normalization</span></span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.features.add_module(<span class="st">'norm_final'</span>, nn.BatchNorm2d(num_features))</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Classifier</span></span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.classifier <span class="op">=</span> nn.Linear(num_features, num_classes)</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Weight initialization</span></span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._initialize_weights()</span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _initialize_weights(<span class="va">self</span>):</span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> m <span class="kw">in</span> <span class="va">self</span>.modules():</span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(m, nn.Conv2d):</span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a>                nn.init.kaiming_normal_(m.weight, mode<span class="op">=</span><span class="st">'fan_out'</span>, </span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a>                                      nonlinearity<span class="op">=</span><span class="st">'relu'</span>)</span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> <span class="bu">isinstance</span>(m, nn.BatchNorm2d):</span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a>                nn.init.constant_(m.weight, <span class="dv">1</span>)</span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a>                nn.init.constant_(m.bias, <span class="dv">0</span>)</span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> <span class="bu">isinstance</span>(m, nn.Linear):</span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a>                nn.init.normal_(m.weight, <span class="dv">0</span>, <span class="fl">0.01</span>)</span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a>                nn.init.constant_(m.bias, <span class="dv">0</span>)</span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb2-60"><a href="#cb2-60" aria-hidden="true" tabindex="-1"></a>        features <span class="op">=</span> <span class="va">self</span>.features(x)</span>
<span id="cb2-61"><a href="#cb2-61" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> F.relu(features, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-62"><a href="#cb2-62" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> F.adaptive_avg_pool2d(out, (<span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb2-63"><a href="#cb2-63" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> torch.flatten(out, <span class="dv">1</span>)</span>
<span id="cb2-64"><a href="#cb2-64" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.classifier(out)</span>
<span id="cb2-65"><a href="#cb2-65" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="densenet-variants" class="cell" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Factory functions for common DenseNet variants</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> densenet121(num_classes<span class="op">=</span><span class="dv">1000</span>, <span class="op">**</span>kwargs):</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> DenseNet(growth_rate<span class="op">=</span><span class="dv">32</span>, block_config<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">12</span>, <span class="dv">24</span>, <span class="dv">16</span>), </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>                   num_classes<span class="op">=</span>num_classes, <span class="op">**</span>kwargs)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> densenet169(num_classes<span class="op">=</span><span class="dv">1000</span>, <span class="op">**</span>kwargs):</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> DenseNet(growth_rate<span class="op">=</span><span class="dv">32</span>, block_config<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">12</span>, <span class="dv">32</span>, <span class="dv">32</span>), </span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>                   num_classes<span class="op">=</span>num_classes, <span class="op">**</span>kwargs)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> densenet201(num_classes<span class="op">=</span><span class="dv">1000</span>, <span class="op">**</span>kwargs):</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> DenseNet(growth_rate<span class="op">=</span><span class="dv">32</span>, block_config<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">12</span>, <span class="dv">48</span>, <span class="dv">32</span>), </span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>                   num_classes<span class="op">=</span>num_classes, <span class="op">**</span>kwargs)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> densenet161(num_classes<span class="op">=</span><span class="dv">1000</span>, <span class="op">**</span>kwargs):</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> DenseNet(growth_rate<span class="op">=</span><span class="dv">48</span>, block_config<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">12</span>, <span class="dv">36</span>, <span class="dv">24</span>), </span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>                   num_init_features<span class="op">=</span><span class="dv">96</span>, num_classes<span class="op">=</span>num_classes, <span class="op">**</span>kwargs)</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Create a DenseNet-121 model</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> densenet121(num_classes<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Model created with </span><span class="sc">{</span><span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> model.parameters())<span class="sc">}</span><span class="ss"> parameters"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="performance-analysis-and-benchmarks" class="level2">
<h2 class="anchored" data-anchor-id="performance-analysis-and-benchmarks">Performance Analysis and Benchmarks</h2>
<section id="computational-complexity" class="level3">
<h3 class="anchored" data-anchor-id="computational-complexity">Computational Complexity</h3>
<p>DenseNet’s computational complexity differs significantly from traditional architectures due to its unique connectivity pattern. While the number of parameters can be substantially lower than comparable ResNet models, the memory requirements during training are generally higher due to the concatenation operations.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Key Complexity Characteristics
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li><p><strong>Parameter Efficiency</strong>: DenseNet typically requires fewer parameters than ResNet for comparable performance due to feature reuse and the narrow layer design.</p></li>
<li><p><strong>Memory Complexity</strong>: Memory usage grows quadratically with the number of layers within dense blocks due to concatenation operations.</p></li>
<li><p><strong>Computational Complexity</strong>: While individual layers are computationally lighter, the overall complexity can be higher due to the increased connectivity.</p></li>
</ol>
</div>
</div>
</section>
<section id="benchmark-results" class="level3">
<h3 class="anchored" data-anchor-id="benchmark-results">Benchmark Results</h3>
<p>DenseNet has demonstrated strong performance across various computer vision tasks:</p>
<div id="tbl-imagenet-performance" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-imagenet-performance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: DenseNet Performance on ImageNet
</figcaption>
<div aria-describedby="tbl-imagenet-performance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th>Model</th>
<th>ImageNet Top-1 Error</th>
<th>Parameters</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>DenseNet-121</td>
<td>25.35%</td>
<td>8.0M</td>
</tr>
<tr class="even">
<td>DenseNet-169</td>
<td>24.00%</td>
<td>14.1M</td>
</tr>
<tr class="odd">
<td>DenseNet-201</td>
<td>22.80%</td>
<td>20.0M</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p><strong>CIFAR Datasets</strong>:</p>
<ul>
<li>CIFAR-10: Error rates as low as 3.46% with appropriate regularization</li>
<li>CIFAR-100: Competitive performance with significantly fewer parameters than ResNet</li>
</ul>
</section>
<section id="memory-optimization-strategies" class="level3">
<h3 class="anchored" data-anchor-id="memory-optimization-strategies">Memory Optimization Strategies</h3>
<p>Several strategies can be employed to optimize DenseNet’s memory usage:</p>
<div id="memory-optimization-example" class="cell" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example of memory-efficient DenseNet implementation considerations</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MemoryEfficientDenseLayer(nn.Module):</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Memory-efficient implementation using gradient checkpointing</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_channels, growth_rate):</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Implementation with memory optimizations</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Use gradient checkpointing for memory efficiency</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.utils.checkpoint.checkpoint(<span class="va">self</span>._forward_impl, x)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _forward_impl(<span class="va">self</span>, x):</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Actual forward implementation</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<ol type="1">
<li><p><strong>Memory-Efficient Implementation</strong>: Using shared memory allocation and efficient concatenation operations.</p></li>
<li><p><strong>Mixed Precision Training</strong>: Utilizing half-precision floating-point arithmetic where appropriate.</p></li>
<li><p><strong>Gradient Checkpointing</strong>: Trading computation for memory by recomputing intermediate activations.</p></li>
</ol>
</section>
</section>
<section id="training-considerations" class="level2">
<h2 class="anchored" data-anchor-id="training-considerations">Training Considerations</h2>
<section id="hyperparameter-selection" class="level3">
<h3 class="anchored" data-anchor-id="hyperparameter-selection">Hyperparameter Selection</h3>
<p>Training DenseNet effectively requires careful attention to several hyperparameters:</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Critical Hyperparameters
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Growth Rate (k)</strong>: Typically ranges from 12 to 48. Smaller values promote parameter efficiency but may limit representational capacity.</li>
<li><strong>Compression Factor (θ)</strong>: Usually set to 0.5, balancing computational efficiency with information preservation.</li>
<li><strong>Dropout Rate</strong>: Often beneficial for regularization, particularly in deeper variants.</li>
<li><strong>Learning Rate Schedule</strong>: Due to the efficient gradient flow, DenseNet often benefits from different learning rate schedules compared to ResNet.</li>
</ul>
</div>
</div>
</section>
<section id="regularization-techniques" class="level3">
<h3 class="anchored" data-anchor-id="regularization-techniques">Regularization Techniques</h3>
<p>DenseNet’s dense connectivity can sometimes lead to overfitting, making regularization crucial:</p>
<div id="training-example" class="cell" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.optim.lr_scheduler <span class="im">import</span> StepLR</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Example training setup for DenseNet</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> densenet121(num_classes<span class="op">=</span><span class="dv">10</span>)  <span class="co"># For CIFAR-10</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.SGD(model.parameters(), lr<span class="op">=</span><span class="fl">0.1</span>, momentum<span class="op">=</span><span class="fl">0.9</span>, weight_decay<span class="op">=</span><span class="fl">1e-4</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>scheduler <span class="op">=</span> StepLR(optimizer, step_size<span class="op">=</span><span class="dv">30</span>, gamma<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Training loop with proper regularization</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch_idx, (data, target) <span class="kw">in</span> <span class="bu">enumerate</span>(train_loader):</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> model(data)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> F.cross_entropy(output, target)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>    scheduler.step()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<ol type="1">
<li><strong>Dropout</strong>: Applied within dense layers, particularly effective for preventing overfitting.</li>
<li><strong>Data Augmentation</strong>: Standard augmentation techniques remain highly effective.</li>
<li><strong>Weight Decay</strong>: Careful tuning of weight decay is important due to the parameter sharing characteristics.</li>
</ol>
</section>
</section>
<section id="applications-and-use-cases" class="level2">
<h2 class="anchored" data-anchor-id="applications-and-use-cases">Applications and Use Cases</h2>
<section id="computer-vision-tasks" class="level3">
<h3 class="anchored" data-anchor-id="computer-vision-tasks">Computer Vision Tasks</h3>
<p>DenseNet excels in various computer vision applications:</p>
<ul>
<li><strong>Image Classification</strong>: Strong performance on standard benchmarks with parameter efficiency</li>
<li><strong>Object Detection</strong>: When used as a backbone in detection frameworks like Faster R-CNN or YOLO</li>
<li><strong>Semantic Segmentation</strong>: The feature reuse properties make DenseNet particularly suitable for dense prediction tasks</li>
<li><strong>Medical Imaging</strong>: The parameter efficiency and strong representation learning make it popular for medical image analysis where data is often limited</li>
</ul>
</section>
<section id="transfer-learning" class="level3">
<h3 class="anchored" data-anchor-id="transfer-learning">Transfer Learning</h3>
<p>DenseNet’s feature reuse properties make it particularly effective for transfer learning scenarios:</p>
<div id="transfer-learning-example" class="cell" data-execution_count="6">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Transfer learning with pre-trained DenseNet</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.models <span class="im">as</span> models</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load pre-trained DenseNet-121</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> models.densenet121(pretrained<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Freeze feature extraction layers</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> param <span class="kw">in</span> model.features.parameters():</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    param.requires_grad <span class="op">=</span> <span class="va">False</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Replace classifier for new task</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>num_features <span class="op">=</span> model.classifier.in_features</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>model.classifier <span class="op">=</span> nn.Linear(num_features, num_classes_new_task)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Only classifier parameters will be updated during training</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.Adam(model.classifier.parameters(), lr<span class="op">=</span><span class="fl">0.001</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
</section>
<section id="comparison-with-other-architectures" class="level2">
<h2 class="anchored" data-anchor-id="comparison-with-other-architectures">Comparison with Other Architectures</h2>
<section id="densenet-vs-resnet" class="level3">
<h3 class="anchored" data-anchor-id="densenet-vs-resnet">DenseNet vs ResNet</h3>
<div id="tbl-densenet-resnet" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-densenet-resnet-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2: DenseNet vs ResNet Comparison
</figcaption>
<div aria-describedby="tbl-densenet-resnet-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th>Aspect</th>
<th>DenseNet</th>
<th>ResNet</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Parameter Efficiency</td>
<td>✅ Better</td>
<td>❌ More parameters</td>
</tr>
<tr class="even">
<td>Gradient Flow</td>
<td>✅ Stronger</td>
<td>✅ Good</td>
</tr>
<tr class="odd">
<td>Memory Requirements</td>
<td>❌ Higher during training</td>
<td>✅ Lower</td>
</tr>
<tr class="even">
<td>Implementation</td>
<td>❌ More complex</td>
<td>✅ Simpler</td>
</tr>
<tr class="odd">
<td>Feature Reuse</td>
<td>✅ Excellent</td>
<td>❌ Limited</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="densenet-vs-inception" class="level3">
<h3 class="anchored" data-anchor-id="densenet-vs-inception">DenseNet vs Inception</h3>
<p><strong>DenseNet Advantages</strong>:</p>
<ul>
<li>Simpler architectural design</li>
<li>More consistent performance across tasks<br>
</li>
<li>Better parameter efficiency</li>
</ul>
<p><strong>Inception Advantages</strong>:</p>
<ul>
<li>More flexible computational budget allocation</li>
<li>Better computational efficiency in some scenarios</li>
</ul>
</section>
</section>
<section id="recent-developments-and-variants" class="level2">
<h2 class="anchored" data-anchor-id="recent-developments-and-variants">Recent Developments and Variants</h2>
<section id="densenet-extensions" class="level3">
<h3 class="anchored" data-anchor-id="densenet-extensions">DenseNet Extensions</h3>
<p>Several extensions and improvements to DenseNet have been proposed:</p>
<ul>
<li><strong>CondenseNet</strong>: Introduces learned sparse connectivity to improve computational efficiency while maintaining the benefits of dense connections</li>
<li><strong>PeleeNet</strong>: Optimizes DenseNet for mobile and embedded applications through architectural modifications and compression techniques</li>
<li><strong>DenseNet with Attention</strong>: Incorporates attention mechanisms to further improve feature selection and representation learning</li>
</ul>
</section>
<section id="integration-with-modern-techniques" class="level3">
<h3 class="anchored" data-anchor-id="integration-with-modern-techniques">Integration with Modern Techniques</h3>
<p>DenseNet continues to be relevant in modern deep learning through integration with contemporary techniques:</p>
<ol type="1">
<li><strong>Neural Architecture Search (NAS)</strong>: DenseNet-inspired connectivity patterns appear in many NAS-discovered architectures</li>
<li><strong>Vision Transformers</strong>: Some hybrid approaches combine DenseNet-style connectivity with transformer architectures</li>
<li><strong>EfficientNet Integration</strong>: Combining DenseNet principles with compound scaling methods for improved efficiency</li>
</ol>
</section>
</section>
<section id="best-practices-and-recommendations" class="level2">
<h2 class="anchored" data-anchor-id="best-practices-and-recommendations">Best Practices and Recommendations</h2>
<section id="architecture-design" class="level3">
<h3 class="anchored" data-anchor-id="architecture-design">Architecture Design</h3>
<p>When designing DenseNet-based architectures:</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Design Guidelines
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li><strong>Growth Rate Selection</strong>: Start with k=32 for large-scale tasks, k=12 for smaller datasets or computational constraints</li>
<li><strong>Block Configuration</strong>: Use proven configurations (6,12,24,16 for DenseNet-121) as starting points, adjusting based on specific requirements<br>
</li>
<li><strong>Compression Strategy</strong>: Maintain θ=0.5 unless specific memory or computational constraints require adjustment</li>
</ol>
</div>
</div>
</section>
<section id="implementation-guidelines" class="level3">
<h3 class="anchored" data-anchor-id="implementation-guidelines">Implementation Guidelines</h3>
<ol type="1">
<li><strong>Memory Management</strong>: Implement efficient concatenation operations and consider memory-efficient variants for resource-constrained environments</li>
<li><strong>Batch Normalization</strong>: Ensure proper batch normalization placement and initialization for optimal training dynamics</li>
<li><strong>Regularization</strong>: Apply dropout judiciously, particularly in deeper layers and for smaller datasets</li>
</ol>
</section>
<section id="training-optimization" class="level3">
<h3 class="anchored" data-anchor-id="training-optimization">Training Optimization</h3>
<ol type="1">
<li><strong>Learning Rate</strong>: Start with standard learning rates but be prepared to adjust based on the specific connectivity pattern effects</li>
<li><strong>Batch Size</strong>: Use larger batch sizes when possible to leverage the batch normalization layers effectively</li>
<li><strong>Augmentation</strong>: Standard augmentation techniques remain highly effective and often crucial for preventing overfitting</li>
</ol>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>DenseNet represents a fundamental advancement in convolutional neural network design, demonstrating that architectural innovations can achieve better performance with fewer parameters through improved connectivity patterns. The dense connectivity paradigm offers several key advantages: enhanced gradient flow, feature reuse, parameter efficiency, and implicit deep supervision.</p>
<p>While DenseNet introduces some implementation complexity and memory considerations, these challenges are outweighed by its strong empirical performance and theoretical elegance. The architecture’s influence extends beyond its direct applications, inspiring subsequent architectural innovations and contributing to our understanding of effective connectivity patterns in deep networks.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Key Takeaways
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>DenseNet achieves better parameter efficiency through feature reuse</li>
<li>Dense connectivity ensures robust gradient flow and training stability<br>
</li>
<li>Memory optimization strategies are crucial for practical implementation</li>
<li>The architecture remains relevant through integration with modern techniques</li>
</ul>
</div>
</div>
<p>The continued relevance of DenseNet in modern deep learning, through extensions, variants, and integration with contemporary techniques, underscores its fundamental contribution to the field. For practitioners, DenseNet offers a compelling choice when parameter efficiency, strong performance, and architectural elegance are priorities.</p>
<p>As the field continues to evolve, the principles underlying DenseNet—maximizing information flow, promoting feature reuse, and enabling efficient gradient propagation—remain valuable guideposts for future architectural innovations. The dense connectivity pattern pioneered by DenseNet continues to influence modern architecture design, from Vision Transformers to Neural Architecture Search discoveries, ensuring its lasting impact on deep learning research and practice.</p>



</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/theja-vanka\.github\.io\/blogs\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>© 2025 Krishnatheja Vanka</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>