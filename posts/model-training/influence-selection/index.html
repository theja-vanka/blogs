<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Krishnatheja Vanka">
<meta name="dcterms.date" content="2025-04-19">

<title>Active Learning Influence Selection: A Comprehensive Guide – Krishnatheja Vanka’s Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../favicon.ico" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-62c28fcd870f55f61984f019219cbd7c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../../styles.css">
</head>

<body class="floating nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Krishnatheja Vanka’s Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html"> 
<span class="menu-text">About me</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/theja-vanka"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-page-right">
      <h1 class="title">Active Learning Influence Selection: A Comprehensive Guide</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">code</div>
                <div class="quarto-category">research</div>
                <div class="quarto-category">advanced</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta column-page-right">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Krishnatheja Vanka </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">April 19, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#active-learning-influence-selection-a-comprehensive-guide" id="toc-active-learning-influence-selection-a-comprehensive-guide" class="nav-link active" data-scroll-target="#active-learning-influence-selection-a-comprehensive-guide">Active Learning Influence Selection: A Comprehensive Guide</a>
  <ul class="collapse">
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#table-of-contents" id="toc-table-of-contents" class="nav-link" data-scroll-target="#table-of-contents">Table of Contents</a></li>
  <li><a href="#fundamentals-of-active-learning" id="toc-fundamentals-of-active-learning" class="nav-link" data-scroll-target="#fundamentals-of-active-learning">Fundamentals of Active Learning</a>
  <ul class="collapse">
  <li><a href="#the-active-learning-loop" id="toc-the-active-learning-loop" class="nav-link" data-scroll-target="#the-active-learning-loop">The Active Learning Loop</a></li>
  <li><a href="#pool-based-vs.-stream-based-learning" id="toc-pool-based-vs.-stream-based-learning" class="nav-link" data-scroll-target="#pool-based-vs.-stream-based-learning">Pool-Based vs.&nbsp;Stream-Based Learning</a></li>
  </ul></li>
  <li><a href="#influence-selection-strategies" id="toc-influence-selection-strategies" class="nav-link" data-scroll-target="#influence-selection-strategies">Influence Selection Strategies</a></li>
  <li><a href="#uncertainty-based-methods" id="toc-uncertainty-based-methods" class="nav-link" data-scroll-target="#uncertainty-based-methods">Uncertainty-Based Methods</a>
  <ul class="collapse">
  <li><a href="#least-confidence" id="toc-least-confidence" class="nav-link" data-scroll-target="#least-confidence">Least Confidence</a></li>
  <li><a href="#margin-sampling" id="toc-margin-sampling" class="nav-link" data-scroll-target="#margin-sampling">Margin Sampling</a></li>
  <li><a href="#entropy-based-sampling" id="toc-entropy-based-sampling" class="nav-link" data-scroll-target="#entropy-based-sampling">Entropy-Based Sampling</a></li>
  <li><a href="#bayesian-active-learning-by-disagreement-bald" id="toc-bayesian-active-learning-by-disagreement-bald" class="nav-link" data-scroll-target="#bayesian-active-learning-by-disagreement-bald">Bayesian Active Learning by Disagreement (BALD)</a></li>
  </ul></li>
  <li><a href="#diversity-based-methods" id="toc-diversity-based-methods" class="nav-link" data-scroll-target="#diversity-based-methods">Diversity-Based Methods</a>
  <ul class="collapse">
  <li><a href="#clustering-based-sampling" id="toc-clustering-based-sampling" class="nav-link" data-scroll-target="#clustering-based-sampling">Clustering-Based Sampling</a></li>
  <li><a href="#core-set-approach" id="toc-core-set-approach" class="nav-link" data-scroll-target="#core-set-approach">Core-Set Approach</a></li>
  </ul></li>
  <li><a href="#expected-model-change" id="toc-expected-model-change" class="nav-link" data-scroll-target="#expected-model-change">Expected Model Change</a></li>
  <li><a href="#expected-error-reduction" id="toc-expected-error-reduction" class="nav-link" data-scroll-target="#expected-error-reduction">Expected Error Reduction</a></li>
  <li><a href="#influence-functions" id="toc-influence-functions" class="nav-link" data-scroll-target="#influence-functions">Influence Functions</a></li>
  <li><a href="#query-by-committee" id="toc-query-by-committee" class="nav-link" data-scroll-target="#query-by-committee">Query-by-Committee</a></li>
  <li><a href="#implementation-considerations" id="toc-implementation-considerations" class="nav-link" data-scroll-target="#implementation-considerations">Implementation Considerations</a>
  <ul class="collapse">
  <li><a href="#batch-mode-active-learning" id="toc-batch-mode-active-learning" class="nav-link" data-scroll-target="#batch-mode-active-learning">Batch Mode Active Learning</a></li>
  <li><a href="#handling-imbalanced-data" id="toc-handling-imbalanced-data" class="nav-link" data-scroll-target="#handling-imbalanced-data">Handling Imbalanced Data</a></li>
  <li><a href="#computational-efficiency" id="toc-computational-efficiency" class="nav-link" data-scroll-target="#computational-efficiency">Computational Efficiency</a></li>
  </ul></li>
  <li><a href="#evaluation-metrics" id="toc-evaluation-metrics" class="nav-link" data-scroll-target="#evaluation-metrics">Evaluation Metrics</a>
  <ul class="collapse">
  <li><a href="#learning-curves" id="toc-learning-curves" class="nav-link" data-scroll-target="#learning-curves">Learning Curves</a></li>
  <li><a href="#comparison-with-random-sampling" id="toc-comparison-with-random-sampling" class="nav-link" data-scroll-target="#comparison-with-random-sampling">Comparison with Random Sampling</a></li>
  <li><a href="#annotation-efficiency" id="toc-annotation-efficiency" class="nav-link" data-scroll-target="#annotation-efficiency">Annotation Efficiency</a></li>
  </ul></li>
  <li><a href="#practical-examples" id="toc-practical-examples" class="nav-link" data-scroll-target="#practical-examples">Practical Examples</a>
  <ul class="collapse">
  <li><a href="#image-classification-with-uncertainty-sampling" id="toc-image-classification-with-uncertainty-sampling" class="nav-link" data-scroll-target="#image-classification-with-uncertainty-sampling">Image Classification with Uncertainty Sampling</a></li>
  <li><a href="#text-classification-with-query-by-committee" id="toc-text-classification-with-query-by-committee" class="nav-link" data-scroll-target="#text-classification-with-query-by-committee">Text Classification with Query-by-Committee</a></li>
  </ul></li>
  <li><a href="#advanced-topics" id="toc-advanced-topics" class="nav-link" data-scroll-target="#advanced-topics">Advanced Topics</a>
  <ul class="collapse">
  <li><a href="#transfer-learning-with-active-learning" id="toc-transfer-learning-with-active-learning" class="nav-link" data-scroll-target="#transfer-learning-with-active-learning">Transfer Learning with Active Learning</a></li>
  <li><a href="#active-learning-with-deep-learning" id="toc-active-learning-with-deep-learning" class="nav-link" data-scroll-target="#active-learning-with-deep-learning">Active Learning with Deep Learning</a></li>
  <li><a href="#semi-supervised-active-learning" id="toc-semi-supervised-active-learning" class="nav-link" data-scroll-target="#semi-supervised-active-learning">Semi-Supervised Active Learning</a></li>
  <li><a href="#active-learning-for-domain-adaptation" id="toc-active-learning-for-domain-adaptation" class="nav-link" data-scroll-target="#active-learning-for-domain-adaptation">Active Learning for Domain Adaptation</a></li>
  <li><a href="#human-in-the-loop-considerations" id="toc-human-in-the-loop-considerations" class="nav-link" data-scroll-target="#human-in-the-loop-considerations">Human-in-the-Loop Considerations</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block column-page-right" id="quarto-document-content">





<section id="active-learning-influence-selection-a-comprehensive-guide" class="level1">
<h1>Active Learning Influence Selection: A Comprehensive Guide</h1>
<p><img src="learn.png" class="img-fluid"></p>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Active learning is a machine learning paradigm where the algorithm can interactively query an oracle (typically a human annotator) to label new data points. The key idea is to select the most informative samples to be labeled, reducing the overall labeling effort while maintaining or improving model performance. This guide focuses on influence selection methods used in active learning strategies.</p>
</section>
<section id="table-of-contents" class="level2">
<h2 class="anchored" data-anchor-id="table-of-contents">Table of Contents</h2>
<ol type="1">
<li><a href="#fundamentals-of-active-learning">Fundamentals of Active Learning</a></li>
<li><a href="#influence-selection-strategies">Influence Selection Strategies</a></li>
<li><a href="#uncertainty-based-methods">Uncertainty-Based Methods</a></li>
<li><a href="#diversity-based-methods">Diversity-Based Methods</a></li>
<li><a href="#expected-model-change">Expected Model Change</a></li>
<li><a href="#expected-error-reduction">Expected Error Reduction</a></li>
<li><a href="#influence-functions">Influence Functions</a></li>
<li><a href="#query-by-committee">Query-by-Committee</a></li>
<li><a href="#implementation-considerations">Implementation Considerations</a></li>
<li><a href="#evaluation-metrics">Evaluation Metrics</a></li>
<li><a href="#practical-examples">Practical Examples</a></li>
<li><a href="#advanced-topics">Advanced Topics</a></li>
</ol>
</section>
<section id="fundamentals-of-active-learning" class="level2">
<h2 class="anchored" data-anchor-id="fundamentals-of-active-learning">Fundamentals of Active Learning</h2>
<section id="the-active-learning-loop" class="level3">
<h3 class="anchored" data-anchor-id="the-active-learning-loop">The Active Learning Loop</h3>
<p>The typical active learning process follows these steps:</p>
<ol type="1">
<li>Start with a small labeled dataset and a large unlabeled pool</li>
<li>Train an initial model on the labeled data</li>
<li>Apply an influence selection strategy to choose informative samples from the unlabeled pool</li>
<li>Get annotations for the selected samples</li>
<li>Add the newly labeled samples to the training set</li>
<li>Retrain the model and repeat steps 3-6 until a stopping condition is met</li>
</ol>
</section>
<section id="pool-based-vs.-stream-based-learning" class="level3">
<h3 class="anchored" data-anchor-id="pool-based-vs.-stream-based-learning">Pool-Based vs.&nbsp;Stream-Based Learning</h3>
<ul>
<li><strong>Pool-based</strong>: The learner has access to a pool of unlabeled data and selects the most informative samples</li>
<li><strong>Stream-based</strong>: Samples arrive sequentially, and the learner must decide on-the-fly whether to request labels</li>
</ul>
</section>
</section>
<section id="influence-selection-strategies" class="level2">
<h2 class="anchored" data-anchor-id="influence-selection-strategies">Influence Selection Strategies</h2>
<p>Influence selection is about identifying which unlabeled samples would be most beneficial to label next. Here are the main strategies:</p>
</section>
<section id="uncertainty-based-methods" class="level2">
<h2 class="anchored" data-anchor-id="uncertainty-based-methods">Uncertainty-Based Methods</h2>
<p>These methods select samples that the model is most uncertain about.</p>
<section id="least-confidence" class="level3">
<h3 class="anchored" data-anchor-id="least-confidence">Least Confidence</h3>
<div id="18c45f50" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> least_confidence(model, unlabeled_pool, k):</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Predict probabilities for each sample in the unlabeled pool</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    probabilities <span class="op">=</span> model.predict_proba(unlabeled_pool)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get the confidence values for the most probable class</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    confidences <span class="op">=</span> np.<span class="bu">max</span>(probabilities, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Select the k samples with the lowest confidence</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    least_confident_indices <span class="op">=</span> np.argsort(confidences)[:k]</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> unlabeled_pool[least_confident_indices]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="margin-sampling" class="level3">
<h3 class="anchored" data-anchor-id="margin-sampling">Margin Sampling</h3>
<p>Selects samples with the smallest margin between the two most likely classes:</p>
<div id="49259a6b" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> margin_sampling(model, unlabeled_pool, k):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Predict probabilities for each sample in the unlabeled pool</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    probabilities <span class="op">=</span> model.predict_proba(unlabeled_pool)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sort the probabilities in descending order</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    sorted_probs <span class="op">=</span> np.sort(probabilities, axis<span class="op">=</span><span class="dv">1</span>)[:, ::<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate the margin between the first and second most probable classes</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    margins <span class="op">=</span> sorted_probs[:, <span class="dv">0</span>] <span class="op">-</span> sorted_probs[:, <span class="dv">1</span>]</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Select the k samples with the smallest margins</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    smallest_margin_indices <span class="op">=</span> np.argsort(margins)[:k]</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> unlabeled_pool[smallest_margin_indices]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="entropy-based-sampling" class="level3">
<h3 class="anchored" data-anchor-id="entropy-based-sampling">Entropy-Based Sampling</h3>
<p>Selects samples with the highest predictive entropy:</p>
<div id="f2f0cc96" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> entropy_sampling(model, unlabeled_pool, k):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Predict probabilities for each sample in the unlabeled pool</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    probabilities <span class="op">=</span> model.predict_proba(unlabeled_pool)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate entropy for each sample</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    entropies <span class="op">=</span> <span class="op">-</span>np.<span class="bu">sum</span>(probabilities <span class="op">*</span> np.log(probabilities <span class="op">+</span> <span class="fl">1e-10</span>), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Select the k samples with the highest entropy</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    highest_entropy_indices <span class="op">=</span> np.argsort(entropies)[::<span class="op">-</span><span class="dv">1</span>][:k]</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> unlabeled_pool[highest_entropy_indices]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="bayesian-active-learning-by-disagreement-bald" class="level3">
<h3 class="anchored" data-anchor-id="bayesian-active-learning-by-disagreement-bald">Bayesian Active Learning by Disagreement (BALD)</h3>
<p>For Bayesian models, BALD selects samples that maximize the mutual information between predictions and model parameters:</p>
<div id="0d2ed53f" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> bald_sampling(bayesian_model, unlabeled_pool, k, n_samples<span class="op">=</span><span class="dv">100</span>):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get multiple predictions by sampling from the model's posterior</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    probs_samples <span class="op">=</span> []</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_samples):</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>        probs <span class="op">=</span> bayesian_model.predict_proba(unlabeled_pool)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>        probs_samples.append(probs)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Stack into a 3D array: (samples, data points, classes)</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    probs_samples <span class="op">=</span> np.stack(probs_samples)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate the average probability across all samples</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    mean_probs <span class="op">=</span> np.mean(probs_samples, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate the entropy of the average prediction</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    entropy_mean <span class="op">=</span> <span class="op">-</span>np.<span class="bu">sum</span>(mean_probs <span class="op">*</span> np.log(mean_probs <span class="op">+</span> <span class="fl">1e-10</span>), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate the average entropy across all samples</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>    entropy_samples <span class="op">=</span> <span class="op">-</span>np.<span class="bu">sum</span>(probs_samples <span class="op">*</span> np.log(probs_samples <span class="op">+</span> <span class="fl">1e-10</span>), axis<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    mean_entropy <span class="op">=</span> np.mean(entropy_samples, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Mutual information = entropy of the mean - mean of entropies</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>    bald_scores <span class="op">=</span> entropy_mean <span class="op">-</span> mean_entropy</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Select the k samples with the highest BALD scores</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>    highest_bald_indices <span class="op">=</span> np.argsort(bald_scores)[::<span class="op">-</span><span class="dv">1</span>][:k]</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> unlabeled_pool[highest_bald_indices]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="diversity-based-methods" class="level2">
<h2 class="anchored" data-anchor-id="diversity-based-methods">Diversity-Based Methods</h2>
<p>These methods aim to select a diverse set of examples to ensure broad coverage of the input space.</p>
<section id="clustering-based-sampling" class="level3">
<h3 class="anchored" data-anchor-id="clustering-based-sampling">Clustering-Based Sampling</h3>
<div id="4248ccbf" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> clustering_based_sampling(unlabeled_pool, k, n_clusters<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> n_clusters <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>        n_clusters <span class="op">=</span> k</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Apply K-means clustering</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>n_clusters)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    kmeans.fit(unlabeled_pool)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get the cluster centers and distances to each point</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    centers <span class="op">=</span> kmeans.cluster_centers_</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    distances <span class="op">=</span> kmeans.transform(unlabeled_pool)  <span class="co"># Distance to each cluster center</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Select one sample from each cluster (closest to the center)</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    selected_indices <span class="op">=</span> []</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_clusters):</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the samples in this cluster</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>        cluster_samples <span class="op">=</span> np.where(kmeans.labels_ <span class="op">==</span> i)[<span class="dv">0</span>]</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Find the sample closest to the center</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>        closest_sample <span class="op">=</span> cluster_samples[np.argmin(distances[cluster_samples, i])]</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>        selected_indices.append(closest_sample)</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># If we need more samples than clusters, fill with the most uncertain samples</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> k <span class="op">&gt;</span> n_clusters:</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Implementation depends on uncertainty measure</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> unlabeled_pool[selected_indices[:k]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="core-set-approach" class="level3">
<h3 class="anchored" data-anchor-id="core-set-approach">Core-Set Approach</h3>
<p>The core-set approach aims to select a subset of data that best represents the whole dataset:</p>
<div id="bf51f60e" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> core_set_sampling(labeled_pool, unlabeled_pool, k):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Combine labeled and unlabeled data for distance calculations</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    all_data <span class="op">=</span> np.vstack((labeled_pool, unlabeled_pool))</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute pairwise distances</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    distances <span class="op">=</span> pairwise_distances(all_data)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Split distances into labeled-unlabeled and unlabeled-unlabeled</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    n_labeled <span class="op">=</span> labeled_pool.shape[<span class="dv">0</span>]</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    dist_labeled_unlabeled <span class="op">=</span> distances[:n_labeled, n_labeled:]</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># For each unlabeled sample, find the minimum distance to any labeled sample</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    min_distances <span class="op">=</span> np.<span class="bu">min</span>(dist_labeled_unlabeled, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Select the k samples with the largest minimum distances</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>    farthest_indices <span class="op">=</span> np.argsort(min_distances)[::<span class="op">-</span><span class="dv">1</span>][:k]</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> unlabeled_pool[farthest_indices]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="expected-model-change" class="level2">
<h2 class="anchored" data-anchor-id="expected-model-change">Expected Model Change</h2>
<p>The Expected Model Change (EMC) method selects samples that would cause the greatest change in the model if they were labeled:</p>
<div id="477b658a" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> expected_model_change(model, unlabeled_pool, k):</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Predict probabilities for each sample in the unlabeled pool</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    probabilities <span class="op">=</span> model.predict_proba(unlabeled_pool)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    n_classes <span class="op">=</span> probabilities.shape[<span class="dv">1</span>]</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate expected gradient length for each sample</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    expected_changes <span class="op">=</span> []</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, x <span class="kw">in</span> <span class="bu">enumerate</span>(unlabeled_pool):</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate expected gradient length across all possible labels</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>        change <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(n_classes):</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>            <span class="co"># For each possible class, calculate the gradient if this was the true label</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>            x_expanded <span class="op">=</span> x.reshape(<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Here we would compute the gradient of the model with respect to the sample</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>            <span class="co"># For simplicity, we use a placeholder</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>            gradient <span class="op">=</span> compute_gradient(model, x_expanded, c)</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>            norm_gradient <span class="op">=</span> np.linalg.norm(gradient)</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Weight by the probability of this class</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>            change <span class="op">+=</span> probabilities[i, c] <span class="op">*</span> norm_gradient</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>        expected_changes.append(change)</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Select the k samples with the highest expected change</span></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>    highest_change_indices <span class="op">=</span> np.argsort(expected_changes)[::<span class="op">-</span><span class="dv">1</span>][:k]</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> unlabeled_pool[highest_change_indices]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><em>Note: The <code>compute_gradient</code> function would need to be implemented based on the specific model being used.</em></p>
</section>
<section id="expected-error-reduction" class="level2">
<h2 class="anchored" data-anchor-id="expected-error-reduction">Expected Error Reduction</h2>
<p>The Expected Error Reduction method selects samples that, when labeled, would minimally reduce the model’s expected error:</p>
<div id="86d341a2" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> expected_error_reduction(model, unlabeled_pool, unlabeled_pool_remaining, k):</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Predict probabilities for all remaining unlabeled data</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    current_probs <span class="op">=</span> model.predict_proba(unlabeled_pool_remaining)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    current_entropy <span class="op">=</span> <span class="op">-</span>np.<span class="bu">sum</span>(current_probs <span class="op">*</span> np.log(current_probs <span class="op">+</span> <span class="fl">1e-10</span>), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    expected_error_reductions <span class="op">=</span> []</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># For each sample in the unlabeled pool we're considering</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, x <span class="kw">in</span> <span class="bu">enumerate</span>(unlabeled_pool):</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Predict probabilities for this sample</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>        probs <span class="op">=</span> model.predict_proba(x.reshape(<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>))[<span class="dv">0</span>]</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate the expected error reduction for each possible label</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>        error_reduction <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(probs)):</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Create a hypothetical new model with this labeled sample</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>            <span class="co"># For simplicity, we use a placeholder function</span></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>            hypothetical_model <span class="op">=</span> train_with_additional_sample(model, x, c)</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Get new probabilities with this model</span></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>            new_probs <span class="op">=</span> hypothetical_model.predict_proba(unlabeled_pool_remaining)</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>            new_entropy <span class="op">=</span> <span class="op">-</span>np.<span class="bu">sum</span>(new_probs <span class="op">*</span> np.log(new_probs <span class="op">+</span> <span class="fl">1e-10</span>), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Expected entropy reduction</span></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>            reduction <span class="op">=</span> np.<span class="bu">sum</span>(current_entropy <span class="op">-</span> new_entropy)</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Weight by the probability of this class</span></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>            error_reduction <span class="op">+=</span> probs[c] <span class="op">*</span> reduction</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>        expected_error_reductions.append(error_reduction)</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Select the k samples with the highest expected error reduction</span></span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>    highest_reduction_indices <span class="op">=</span> np.argsort(expected_error_reductions)[::<span class="op">-</span><span class="dv">1</span>][:k]</span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> unlabeled_pool[highest_reduction_indices]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><em>Note: The <code>train_with_additional_sample</code> function would need to be implemented based on the specific model being used.</em></p>
</section>
<section id="influence-functions" class="level2">
<h2 class="anchored" data-anchor-id="influence-functions">Influence Functions</h2>
<p>Influence functions approximate the effect of adding or removing a training example without retraining the model:</p>
<div id="346e8092" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> influence_function_sampling(model, unlabeled_pool, labeled_pool, k, labels):</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    influences <span class="op">=</span> []</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># For each unlabeled sample</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> x_u <span class="kw">in</span> unlabeled_pool:</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate the influence of adding this sample to the training set</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>        influence <span class="op">=</span> calculate_influence(model, x_u, labeled_pool, labels)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>        influences.append(influence)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Select the k samples with the highest influence</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    highest_influence_indices <span class="op">=</span> np.argsort(influences)[::<span class="op">-</span><span class="dv">1</span>][:k]</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> unlabeled_pool[highest_influence_indices]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><em>Note: The <code>calculate_influence</code> function would need to be implemented based on the specific model and influence metric being used.</em></p>
</section>
<section id="query-by-committee" class="level2">
<h2 class="anchored" data-anchor-id="query-by-committee">Query-by-Committee</h2>
<p>Query-by-Committee (QBC) methods train multiple models (a committee) and select samples where they disagree:</p>
<div id="9597bd48" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> query_by_committee(committee_models, unlabeled_pool, k):</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get predictions from all committee members</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    all_predictions <span class="op">=</span> []</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> model <span class="kw">in</span> committee_models:</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>        preds <span class="op">=</span> model.predict(unlabeled_pool)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>        all_predictions.append(preds)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Stack predictions into a 2D array (committee members, data points)</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    all_predictions <span class="op">=</span> np.stack(all_predictions)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate disagreement (e.g., using vote entropy)</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    disagreements <span class="op">=</span> []</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(unlabeled_pool.shape[<span class="dv">0</span>]):</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Count votes for each class</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>        votes <span class="op">=</span> np.bincount(all_predictions[:, i])</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Normalize to get probabilities</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>        vote_probs <span class="op">=</span> votes <span class="op">/</span> <span class="bu">len</span>(committee_models)</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate entropy</span></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>        entropy <span class="op">=</span> <span class="op">-</span>np.<span class="bu">sum</span>(vote_probs <span class="op">*</span> np.log2(vote_probs <span class="op">+</span> <span class="fl">1e-10</span>))</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>        disagreements.append(entropy)</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Select the k samples with the highest disagreement</span></span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>    highest_disagreement_indices <span class="op">=</span> np.argsort(disagreements)[::<span class="op">-</span><span class="dv">1</span>][:k]</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> unlabeled_pool[highest_disagreement_indices]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="implementation-considerations" class="level2">
<h2 class="anchored" data-anchor-id="implementation-considerations">Implementation Considerations</h2>
<section id="batch-mode-active-learning" class="level3">
<h3 class="anchored" data-anchor-id="batch-mode-active-learning">Batch Mode Active Learning</h3>
<p>In practice, it’s often more efficient to select multiple samples at once. However, simply selecting the top-k samples may lead to redundancy. Consider using:</p>
<ol type="1">
<li><strong>Greedy Selection with Diversity</strong>: Select one sample at a time, then update the diversity metrics to avoid selecting similar samples.</li>
</ol>
<div id="c1d1a685" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> batch_selection_with_diversity(model, unlabeled_pool, k, lambda_diversity<span class="op">=</span><span class="fl">0.5</span>):</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    selected_indices <span class="op">=</span> []</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    remaining_indices <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="bu">len</span>(unlabeled_pool)))</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate uncertainty scores for all samples</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    probabilities <span class="op">=</span> model.predict_proba(unlabeled_pool)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    entropies <span class="op">=</span> <span class="op">-</span>np.<span class="bu">sum</span>(probabilities <span class="op">*</span> np.log(probabilities <span class="op">+</span> <span class="fl">1e-10</span>), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate distance matrix for diversity</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    distance_matrix <span class="op">=</span> pairwise_distances(unlabeled_pool)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(k):</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> remaining_indices:</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>        scores <span class="op">=</span> np.zeros(<span class="bu">len</span>(remaining_indices))</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate uncertainty scores</span></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>        uncertainty_scores <span class="op">=</span> entropies[remaining_indices]</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate diversity scores (if we have already selected some samples)</span></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> selected_indices:</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>            <span class="co"># For each remaining sample, calculate the minimum distance to any selected sample</span></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>            diversity_scores <span class="op">=</span> np.<span class="bu">min</span>(distance_matrix[remaining_indices][:, selected_indices], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>            diversity_scores <span class="op">=</span> np.zeros(<span class="bu">len</span>(remaining_indices))</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Normalize scores</span></span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>        uncertainty_scores <span class="op">=</span> (uncertainty_scores <span class="op">-</span> np.<span class="bu">min</span>(uncertainty_scores)) <span class="op">/</span> (np.<span class="bu">max</span>(uncertainty_scores) <span class="op">-</span> np.<span class="bu">min</span>(uncertainty_scores) <span class="op">+</span> <span class="fl">1e-10</span>)</span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> selected_indices:</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>            diversity_scores <span class="op">=</span> (diversity_scores <span class="op">-</span> np.<span class="bu">min</span>(diversity_scores)) <span class="op">/</span> (np.<span class="bu">max</span>(diversity_scores) <span class="op">-</span> np.<span class="bu">min</span>(diversity_scores) <span class="op">+</span> <span class="fl">1e-10</span>)</span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Combine scores</span></span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a>        scores <span class="op">=</span> (<span class="dv">1</span> <span class="op">-</span> lambda_diversity) <span class="op">*</span> uncertainty_scores <span class="op">+</span> lambda_diversity <span class="op">*</span> diversity_scores</span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Select the sample with the highest score</span></span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a>        best_idx <span class="op">=</span> np.argmax(scores)</span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a>        selected_idx <span class="op">=</span> remaining_indices[best_idx]</span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add to selected and remove from remaining</span></span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a>        selected_indices.append(selected_idx)</span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a>        remaining_indices.remove(selected_idx)</span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> unlabeled_pool[selected_indices]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="2" type="1">
<li><strong>Submodular Function Maximization</strong>: Use a submodular function to ensure diversity in the selected batch.</li>
</ol>
</section>
<section id="handling-imbalanced-data" class="level3">
<h3 class="anchored" data-anchor-id="handling-imbalanced-data">Handling Imbalanced Data</h3>
<p>Active learning can inadvertently reinforce class imbalance. Consider:</p>
<ol type="1">
<li><strong>Stratified Sampling</strong>: Ensure representation from all classes.</li>
<li><strong>Hybrid Approaches</strong>: Combine uncertainty-based and density-based methods.</li>
<li><strong>Diversity Constraints</strong>: Explicitly enforce diversity in feature space.</li>
</ol>
</section>
<section id="computational-efficiency" class="level3">
<h3 class="anchored" data-anchor-id="computational-efficiency">Computational Efficiency</h3>
<p>Some methods (like expected error reduction) can be computationally expensive. Consider:</p>
<ol type="1">
<li><strong>Subsample the Unlabeled Pool</strong>: Only consider a random subset for selection.</li>
<li><strong>Pre-compute Embeddings</strong>: Use a fixed feature extractor to pre-compute embeddings.</li>
<li><strong>Approximate Methods</strong>: Use approximations for expensive operations.</li>
</ol>
</section>
</section>
<section id="evaluation-metrics" class="level2">
<h2 class="anchored" data-anchor-id="evaluation-metrics">Evaluation Metrics</h2>
<section id="learning-curves" class="level3">
<h3 class="anchored" data-anchor-id="learning-curves">Learning Curves</h3>
<p>Plot model performance vs.&nbsp;number of labeled samples:</p>
<div id="5d037211" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_learning_curve(model_factory, X_train, y_train, X_test, y_test, </span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>                        active_learning_strategy, initial_size<span class="op">=</span><span class="dv">10</span>, </span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>                        batch_size<span class="op">=</span><span class="dv">10</span>, n_iterations<span class="op">=</span><span class="dv">20</span>):</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize with a small labeled set</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    labeled_indices <span class="op">=</span> np.random.choice(<span class="bu">len</span>(X_train), initial_size, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    unlabeled_indices <span class="op">=</span> np.setdiff1d(np.arange(<span class="bu">len</span>(X_train)), labeled_indices)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    performance <span class="op">=</span> []</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_iterations):</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create a fresh model</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> model_factory()</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Train on the currently labeled data</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>        model.fit(X_train[labeled_indices], y_train[labeled_indices])</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Evaluate on the test set</span></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>        score <span class="op">=</span> model.score(X_test, y_test)</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>        performance.append((<span class="bu">len</span>(labeled_indices), score))</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Select the next batch of samples</span></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(unlabeled_indices) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Use the specified active learning strategy</span></span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>            selected_indices <span class="op">=</span> active_learning_strategy(</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>                model, X_train[unlabeled_indices], batch_size</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Map back to original indices</span></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>            selected_original_indices <span class="op">=</span> unlabeled_indices[selected_indices]</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Update labeled and unlabeled indices</span></span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>            labeled_indices <span class="op">=</span> np.append(labeled_indices, selected_original_indices)</span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>            unlabeled_indices <span class="op">=</span> np.setdiff1d(unlabeled_indices, selected_original_indices)</span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot the learning curve</span></span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>    counts, scores <span class="op">=</span> <span class="bu">zip</span>(<span class="op">*</span>performance)</span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>    plt.plot(counts, scores, <span class="st">'o-'</span>)</span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Number of labeled samples'</span>)</span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Model accuracy'</span>)</span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Active Learning Performance'</span>)</span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a>    plt.grid(<span class="va">True</span>)</span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> performance</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="comparison-with-random-sampling" class="level3">
<h3 class="anchored" data-anchor-id="comparison-with-random-sampling">Comparison with Random Sampling</h3>
<p>Always compare your active learning strategy with random sampling as a baseline.</p>
</section>
<section id="annotation-efficiency" class="level3">
<h3 class="anchored" data-anchor-id="annotation-efficiency">Annotation Efficiency</h3>
<p>Calculate how many annotations you saved compared to using the entire dataset.</p>
</section>
</section>
<section id="practical-examples" class="level2">
<h2 class="anchored" data-anchor-id="practical-examples">Practical Examples</h2>
<section id="image-classification-with-uncertainty-sampling" class="level3">
<h3 class="anchored" data-anchor-id="image-classification-with-uncertainty-sampling">Image Classification with Uncertainty Sampling</h3>
<div id="99de6460" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_openml</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Load data</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>mnist <span class="op">=</span> fetch_openml(<span class="st">'mnist_784'</span>, version<span class="op">=</span><span class="dv">1</span>, cache<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> mnist[<span class="st">'data'</span>], mnist[<span class="st">'target'</span>]</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Split into train and test</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Initially, only a small portion is labeled</span></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>initial_size <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>labeled_indices <span class="op">=</span> np.random.choice(<span class="bu">len</span>(X_train), initial_size, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>unlabeled_indices <span class="op">=</span> np.setdiff1d(np.arange(<span class="bu">len</span>(X_train)), labeled_indices)</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Tracking performance</span></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>active_learning_performance <span class="op">=</span> []</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>random_sampling_performance <span class="op">=</span> []</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Active learning loop</span></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):  <span class="co"># 10 iterations</span></span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Train a model on the currently labeled data</span></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">50</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>    model.fit(X_train.iloc[labeled_indices], y_train.iloc[labeled_indices])</span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Evaluate on the test set</span></span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> model.predict(X_test)</span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>    accuracy <span class="op">=</span> accuracy_score(y_test, y_pred)</span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a>    active_learning_performance.append((<span class="bu">len</span>(labeled_indices), accuracy))</span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Iteration </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">: </span><span class="sc">{</span><span class="bu">len</span>(labeled_indices)<span class="sc">}</span><span class="ss"> labeled samples, "</span></span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a>          <span class="ss">f"accuracy: </span><span class="sc">{</span>accuracy<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Select 100 new samples using entropy sampling</span></span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(unlabeled_indices) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Predict probabilities for each unlabeled sample</span></span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a>        probs <span class="op">=</span> model.predict_proba(X_train.iloc[unlabeled_indices])</span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate entropy</span></span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a>        entropies <span class="op">=</span> <span class="op">-</span>np.<span class="bu">sum</span>(probs <span class="op">*</span> np.log(probs <span class="op">+</span> <span class="fl">1e-10</span>), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Select samples with the highest entropy</span></span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a>        top_indices <span class="op">=</span> np.argsort(entropies)[::<span class="op">-</span><span class="dv">1</span>][:<span class="dv">100</span>]</span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Update labeled and unlabeled indices</span></span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a>        selected_indices <span class="op">=</span> unlabeled_indices[top_indices]</span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a>        labeled_indices <span class="op">=</span> np.append(labeled_indices, selected_indices)</span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a>        unlabeled_indices <span class="op">=</span> np.setdiff1d(unlabeled_indices, selected_indices)</span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-56"><a href="#cb13-56" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot learning curve</span></span>
<span id="cb13-57"><a href="#cb13-57" aria-hidden="true" tabindex="-1"></a>counts, scores <span class="op">=</span> <span class="bu">zip</span>(<span class="op">*</span>active_learning_performance)</span>
<span id="cb13-58"><a href="#cb13-58" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb13-59"><a href="#cb13-59" aria-hidden="true" tabindex="-1"></a>plt.plot(counts, scores, <span class="st">'o-'</span>, label<span class="op">=</span><span class="st">'Active Learning'</span>)</span>
<span id="cb13-60"><a href="#cb13-60" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Number of labeled samples'</span>)</span>
<span id="cb13-61"><a href="#cb13-61" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Model accuracy'</span>)</span>
<span id="cb13-62"><a href="#cb13-62" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Active Learning Performance'</span>)</span>
<span id="cb13-63"><a href="#cb13-63" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb13-64"><a href="#cb13-64" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb13-65"><a href="#cb13-65" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Iteration 1: 100 labeled samples, accuracy: 0.6410
Iteration 2: 200 labeled samples, accuracy: 0.6991
Iteration 3: 300 labeled samples, accuracy: 0.7400
Iteration 4: 400 labeled samples, accuracy: 0.7814
Iteration 5: 500 labeled samples, accuracy: 0.8070
Iteration 6: 600 labeled samples, accuracy: 0.8319
Iteration 7: 700 labeled samples, accuracy: 0.8449
Iteration 8: 800 labeled samples, accuracy: 0.8444
Iteration 9: 900 labeled samples, accuracy: 0.8779
Iteration 10: 1000 labeled samples, accuracy: 0.8772</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-14-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="text-classification-with-query-by-committee" class="level3">
<h3 class="anchored" data-anchor-id="text-classification-with-query-by-committee">Text Classification with Query-by-Committee</h3>
<div id="71f7d412" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfVectorizer</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> MultinomialNB</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> VotingClassifier</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_20newsgroups</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Load data</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>categories <span class="op">=</span> [<span class="st">'alt.atheism'</span>, <span class="st">'soc.religion.christian'</span>, <span class="st">'comp.graphics'</span>, <span class="st">'sci.med'</span>]</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>twenty_train <span class="op">=</span> fetch_20newsgroups(subset<span class="op">=</span><span class="st">'train'</span>, categories<span class="op">=</span>categories, shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>twenty_test <span class="op">=</span> fetch_20newsgroups(subset<span class="op">=</span><span class="st">'test'</span>, categories<span class="op">=</span>categories, shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Feature extraction</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>vectorizer <span class="op">=</span> TfidfVectorizer(stop_words<span class="op">=</span><span class="st">'english'</span>)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> vectorizer.fit_transform(twenty_train.data)</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> vectorizer.transform(twenty_test.data)</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> twenty_train.target</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> twenty_test.target</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Initially, only a small portion is labeled</span></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>initial_size <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>labeled_indices <span class="op">=</span> np.random.choice(<span class="bu">len</span>(X_train.toarray()), initial_size, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>unlabeled_indices <span class="op">=</span> np.setdiff1d(np.arange(<span class="bu">len</span>(X_train.toarray())), labeled_indices)</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a committee of models</span></span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> [</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'nb'</span>, MultinomialNB()),</span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'svm'</span>, SVC(kernel<span class="op">=</span><span class="st">'linear'</span>, probability<span class="op">=</span><span class="va">True</span>)),</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'svm2'</span>, SVC(kernel<span class="op">=</span><span class="st">'rbf'</span>, probability<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Active learning loop</span></span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):  <span class="co"># 10 iterations</span></span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Train each model on the currently labeled data</span></span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a>    committee_models <span class="op">=</span> []</span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> name, model <span class="kw">in</span> models:</span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a>        model.fit(X_train[labeled_indices], y_train[labeled_indices])</span>
<span id="cb15-37"><a href="#cb15-37" aria-hidden="true" tabindex="-1"></a>        committee_models.append(model)</span>
<span id="cb15-38"><a href="#cb15-38" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-39"><a href="#cb15-39" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Evaluate using the VotingClassifier</span></span>
<span id="cb15-40"><a href="#cb15-40" aria-hidden="true" tabindex="-1"></a>    voting_clf <span class="op">=</span> VotingClassifier(estimators<span class="op">=</span>models, voting<span class="op">=</span><span class="st">'soft'</span>)</span>
<span id="cb15-41"><a href="#cb15-41" aria-hidden="true" tabindex="-1"></a>    voting_clf.fit(X_train[labeled_indices], y_train[labeled_indices])</span>
<span id="cb15-42"><a href="#cb15-42" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-43"><a href="#cb15-43" aria-hidden="true" tabindex="-1"></a>    accuracy <span class="op">=</span> voting_clf.score(X_test, y_test)</span>
<span id="cb15-44"><a href="#cb15-44" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Iteration </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">: </span><span class="sc">{</span><span class="bu">len</span>(labeled_indices)<span class="sc">}</span><span class="ss"> labeled samples, "</span></span>
<span id="cb15-45"><a href="#cb15-45" aria-hidden="true" tabindex="-1"></a>          <span class="ss">f"accuracy: </span><span class="sc">{</span>accuracy<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb15-46"><a href="#cb15-46" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-47"><a href="#cb15-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Select 10 new samples using Query-by-Committee</span></span>
<span id="cb15-48"><a href="#cb15-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(unlabeled_indices) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb15-49"><a href="#cb15-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get predictions from all committee members</span></span>
<span id="cb15-50"><a href="#cb15-50" aria-hidden="true" tabindex="-1"></a>        all_predictions <span class="op">=</span> []</span>
<span id="cb15-51"><a href="#cb15-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> model <span class="kw">in</span> committee_models:</span>
<span id="cb15-52"><a href="#cb15-52" aria-hidden="true" tabindex="-1"></a>            preds <span class="op">=</span> model.predict(X_train[unlabeled_indices])</span>
<span id="cb15-53"><a href="#cb15-53" aria-hidden="true" tabindex="-1"></a>            all_predictions.append(preds)</span>
<span id="cb15-54"><a href="#cb15-54" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb15-55"><a href="#cb15-55" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate vote entropy</span></span>
<span id="cb15-56"><a href="#cb15-56" aria-hidden="true" tabindex="-1"></a>        vote_entropies <span class="op">=</span> []</span>
<span id="cb15-57"><a href="#cb15-57" aria-hidden="true" tabindex="-1"></a>        all_predictions <span class="op">=</span> np.array(all_predictions)</span>
<span id="cb15-58"><a href="#cb15-58" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(unlabeled_indices)):</span>
<span id="cb15-59"><a href="#cb15-59" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Count votes for each class</span></span>
<span id="cb15-60"><a href="#cb15-60" aria-hidden="true" tabindex="-1"></a>            votes <span class="op">=</span> np.bincount(all_predictions[:, i], minlength<span class="op">=</span><span class="bu">len</span>(categories))</span>
<span id="cb15-61"><a href="#cb15-61" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Normalize to get probabilities</span></span>
<span id="cb15-62"><a href="#cb15-62" aria-hidden="true" tabindex="-1"></a>            vote_probs <span class="op">=</span> votes <span class="op">/</span> <span class="bu">len</span>(committee_models)</span>
<span id="cb15-63"><a href="#cb15-63" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Calculate entropy</span></span>
<span id="cb15-64"><a href="#cb15-64" aria-hidden="true" tabindex="-1"></a>            entropy <span class="op">=</span> <span class="op">-</span>np.<span class="bu">sum</span>(vote_probs <span class="op">*</span> np.log2(vote_probs <span class="op">+</span> <span class="fl">1e-10</span>))</span>
<span id="cb15-65"><a href="#cb15-65" aria-hidden="true" tabindex="-1"></a>            vote_entropies.append(entropy)</span>
<span id="cb15-66"><a href="#cb15-66" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb15-67"><a href="#cb15-67" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Select samples with the highest vote entropy</span></span>
<span id="cb15-68"><a href="#cb15-68" aria-hidden="true" tabindex="-1"></a>        top_indices <span class="op">=</span> np.argsort(vote_entropies)[::<span class="op">-</span><span class="dv">1</span>][:<span class="dv">10</span>]</span>
<span id="cb15-69"><a href="#cb15-69" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb15-70"><a href="#cb15-70" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Update labeled and unlabeled indices</span></span>
<span id="cb15-71"><a href="#cb15-71" aria-hidden="true" tabindex="-1"></a>        selected_indices <span class="op">=</span> unlabeled_indices[top_indices]</span>
<span id="cb15-72"><a href="#cb15-72" aria-hidden="true" tabindex="-1"></a>        labeled_indices <span class="op">=</span> np.append(labeled_indices, selected_indices)</span>
<span id="cb15-73"><a href="#cb15-73" aria-hidden="true" tabindex="-1"></a>        unlabeled_indices <span class="op">=</span> np.setdiff1d(unlabeled_indices, selected_indices)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Iteration 1: 20 labeled samples, accuracy: 0.2124
Iteration 2: 30 labeled samples, accuracy: 0.2690
Iteration 3: 40 labeled samples, accuracy: 0.3662
Iteration 4: 50 labeled samples, accuracy: 0.5346
Iteration 5: 60 labeled samples, accuracy: 0.5067
Iteration 6: 70 labeled samples, accuracy: 0.5486
Iteration 7: 80 labeled samples, accuracy: 0.6079
Iteration 8: 90 labeled samples, accuracy: 0.5859
Iteration 9: 100 labeled samples, accuracy: 0.7450
Iteration 10: 110 labeled samples, accuracy: 0.7450</code></pre>
</div>
</div>
</section>
</section>
<section id="advanced-topics" class="level2">
<h2 class="anchored" data-anchor-id="advanced-topics">Advanced Topics</h2>
<section id="transfer-learning-with-active-learning" class="level3">
<h3 class="anchored" data-anchor-id="transfer-learning-with-active-learning">Transfer Learning with Active Learning</h3>
<p>Combining transfer learning with active learning can be powerful:</p>
<ol type="1">
<li>Use pre-trained models as feature extractors.</li>
<li>Apply active learning on the feature space.</li>
<li>Fine-tune the model on the selected samples.</li>
</ol>
</section>
<section id="active-learning-with-deep-learning" class="level3">
<h3 class="anchored" data-anchor-id="active-learning-with-deep-learning">Active Learning with Deep Learning</h3>
<p>Special considerations for deep learning models:</p>
<ol type="1">
<li><strong>Uncertainty Estimation</strong>: Use dropout or ensemble methods for better uncertainty estimation.</li>
<li><strong>Batch Normalization</strong>: Be careful with batch normalization layers when retraining.</li>
<li><strong>Data Augmentation</strong>: Apply data augmentation to increase the effective size of the labeled pool.</li>
</ol>
<div id="fc973641" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, Subset</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms <span class="im">as</span> transforms</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.datasets <span class="im">as</span> datasets</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a simple CNN</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SimpleCNN(nn.Module):</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(SimpleCNN, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> nn.Conv2d(<span class="dv">1</span>, <span class="dv">32</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv2 <span class="op">=</span> nn.Conv2d(<span class="dv">32</span>, <span class="dv">64</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout1 <span class="op">=</span> nn.Dropout2d(<span class="fl">0.25</span>)</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout2 <span class="op">=</span> nn.Dropout2d(<span class="fl">0.5</span>)</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(<span class="dv">9216</span>, <span class="dv">128</span>)</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc2 <span class="op">=</span> nn.Linear(<span class="dv">128</span>, <span class="dv">10</span>)</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, dropout<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.conv1(x)</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.relu(x)</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.conv2(x)</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.relu(x)</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.max_pool2d(x, <span class="dv">2</span>)</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> dropout:</span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> <span class="va">self</span>.dropout1(x)</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.flatten(x, <span class="dv">1</span>)</span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.fc1(x)</span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.relu(x)</span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> dropout:</span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> <span class="va">self</span>.dropout2(x)</span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.fc2(x)</span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a><span class="co"># MC Dropout for uncertainty estimation</span></span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mc_dropout_uncertainty(model, data_loader, n_samples<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a>    all_probs <span class="op">=</span> []</span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_samples):</span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a>            batch_probs <span class="op">=</span> []</span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> data, _ <span class="kw">in</span> data_loader:</span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a>                output <span class="op">=</span> model(data, dropout<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a>                probs <span class="op">=</span> F.softmax(output, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb17-46"><a href="#cb17-46" aria-hidden="true" tabindex="-1"></a>                batch_probs.append(probs)</span>
<span id="cb17-47"><a href="#cb17-47" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb17-48"><a href="#cb17-48" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Concatenate batch probabilities</span></span>
<span id="cb17-49"><a href="#cb17-49" aria-hidden="true" tabindex="-1"></a>            all_probs.append(torch.cat(batch_probs))</span>
<span id="cb17-50"><a href="#cb17-50" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-51"><a href="#cb17-51" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Stack along a new dimension</span></span>
<span id="cb17-52"><a href="#cb17-52" aria-hidden="true" tabindex="-1"></a>    all_probs <span class="op">=</span> torch.stack(all_probs)</span>
<span id="cb17-53"><a href="#cb17-53" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-54"><a href="#cb17-54" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate the mean probabilities</span></span>
<span id="cb17-55"><a href="#cb17-55" aria-hidden="true" tabindex="-1"></a>    mean_probs <span class="op">=</span> torch.mean(all_probs, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb17-56"><a href="#cb17-56" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-57"><a href="#cb17-57" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate entropy of the mean prediction</span></span>
<span id="cb17-58"><a href="#cb17-58" aria-hidden="true" tabindex="-1"></a>    entropy <span class="op">=</span> <span class="op">-</span>torch.<span class="bu">sum</span>(mean_probs <span class="op">*</span> torch.log(mean_probs <span class="op">+</span> <span class="fl">1e-10</span>), dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb17-59"><a href="#cb17-59" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-60"><a href="#cb17-60" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> entropy.numpy()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="semi-supervised-active-learning" class="level3">
<h3 class="anchored" data-anchor-id="semi-supervised-active-learning">Semi-Supervised Active Learning</h3>
<p>Leverage both labeled and unlabeled data during training:</p>
<ol type="1">
<li><strong>Self-Training</strong>: Use model predictions on unlabeled data as pseudo-labels.</li>
<li><strong>Co-Training</strong>: Train multiple models and use their predictions to teach each other.</li>
<li><strong>Consistency Regularization</strong>: Enforce consistent predictions across different perturbations.</li>
</ol>
<div id="249a72c7" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> semi_supervised_active_learning(labeled_X, labeled_y, unlabeled_X, model, confidence_threshold<span class="op">=</span><span class="fl">0.95</span>):</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Train model on labeled data</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    model.fit(labeled_X, labeled_y)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Predict on unlabeled data</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    probabilities <span class="op">=</span> model.predict_proba(unlabeled_X)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    max_probs <span class="op">=</span> np.<span class="bu">max</span>(probabilities, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get high confidence predictions</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    confident_indices <span class="op">=</span> np.where(max_probs <span class="op">&gt;=</span> confidence_threshold)[<span class="dv">0</span>]</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get pseudo-labels for confident predictions</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>    pseudo_labels <span class="op">=</span> model.predict(unlabeled_X[confident_indices])</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Train on combined dataset</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    combined_X <span class="op">=</span> np.vstack([labeled_X, unlabeled_X[confident_indices]])</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>    combined_y <span class="op">=</span> np.concatenate([labeled_y, pseudo_labels])</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>    model.fit(combined_X, combined_y)</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model, confident_indices</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="active-learning-for-domain-adaptation" class="level3">
<h3 class="anchored" data-anchor-id="active-learning-for-domain-adaptation">Active Learning for Domain Adaptation</h3>
<p>When labeled data from the target domain is scarce, active learning can help select the most informative samples:</p>
<ol type="1">
<li><strong>Domain Discrepancy Measures</strong>: Select samples that minimize domain discrepancy.</li>
<li><strong>Adversarial Selection</strong>: Select samples that the domain discriminator is most uncertain about.</li>
<li><strong>Feature Space Alignment</strong>: Select samples that help align feature spaces between domains.</li>
</ol>
</section>
<section id="human-in-the-loop-considerations" class="level3">
<h3 class="anchored" data-anchor-id="human-in-the-loop-considerations">Human-in-the-Loop Considerations</h3>
<ol type="1">
<li><strong>Annotation Interface Design</strong>: Make the annotation process intuitive and efficient.</li>
<li><strong>Cognitive Load Management</strong>: Group similar samples to reduce cognitive switching.</li>
<li><strong>Explanations</strong>: Provide model explanations to help annotators understand the current model’s decisions.</li>
<li><strong>Quality Control</strong>: Incorporate mechanisms to detect and correct annotation errors.</li>
</ol>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Active learning provides a powerful framework for efficiently building machine learning models with limited labeled data. By selecting the most informative samples for annotation, active learning can significantly reduce the labeling effort while maintaining high model performance.</p>
<p>The key to successful active learning is choosing the right influence selection strategy for your specific problem and data characteristics. Consider the following when designing your active learning pipeline:</p>
<ol type="1">
<li><strong>Data Characteristics</strong>: Dense vs.&nbsp;sparse data, balanced vs.&nbsp;imbalanced classes, feature distribution.</li>
<li><strong>Model Type</strong>: Linear models, tree-based models, deep learning models.</li>
<li><strong>Computational Resources</strong>: Available memory and processing power.</li>
<li><strong>Annotation Budget</strong>: Number of samples that can be labeled.</li>
<li><strong>Task Complexity</strong>: Classification vs.&nbsp;regression, number of classes, difficulty of the task.</li>
</ol>
<p>By carefully considering these factors and implementing the appropriate influence selection methods, you can build high-performance models with minimal annotation effort.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/theja-vanka\.github\.io\/blogs\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>© 2025 Krishnatheja Vanka</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>