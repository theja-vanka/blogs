<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Krishnatheja Vanka">
<meta name="dcterms.date" content="2025-07-15">

<title>Switch Transformer: Scaling Neural Networks with Sparsity – Krishnatheja Vanka’s Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../favicon.ico" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark-707d8167ce6003fca903bfe2be84ab7f.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-db7551fb198f90e53e140817f36f545d.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark-941aa739f4f6ead0e06d988344f7e38f.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../../site_libs/bootstrap/bootstrap-db7551fb198f90e53e140817f36f545d.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../styles/styles.css">
</head>

<body class="floating nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Krishnatheja Vanka’s Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html"> 
<span class="menu-text">About me</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/theja-vanka"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-page-right">
      <h1 class="title">Switch Transformer: Scaling Neural Networks with Sparsity</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">research</div>
                <div class="quarto-category">advanced</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta column-page-right">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Krishnatheja Vanka </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">July 15, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#switch-transformer-scaling-neural-networks-with-sparsity" id="toc-switch-transformer-scaling-neural-networks-with-sparsity" class="nav-link active" data-scroll-target="#switch-transformer-scaling-neural-networks-with-sparsity">Switch Transformer: Scaling Neural Networks with Sparsity</a>
  <ul class="collapse">
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#background-and-motivation" id="toc-background-and-motivation" class="nav-link" data-scroll-target="#background-and-motivation">Background and Motivation</a>
  <ul class="collapse">
  <li><a href="#the-scaling-challenge" id="toc-the-scaling-challenge" class="nav-link" data-scroll-target="#the-scaling-challenge">The Scaling Challenge</a></li>
  <li><a href="#mixture-of-experts-moe-foundation" id="toc-mixture-of-experts-moe-foundation" class="nav-link" data-scroll-target="#mixture-of-experts-moe-foundation">Mixture of Experts (MoE) Foundation</a></li>
  </ul></li>
  <li><a href="#architecture-overview" id="toc-architecture-overview" class="nav-link" data-scroll-target="#architecture-overview">Architecture Overview</a>
  <ul class="collapse">
  <li><a href="#core-components" id="toc-core-components" class="nav-link" data-scroll-target="#core-components">Core Components</a></li>
  <li><a href="#mathematical-foundation" id="toc-mathematical-foundation" class="nav-link" data-scroll-target="#mathematical-foundation">Mathematical Foundation</a></li>
  </ul></li>
  <li><a href="#key-innovations" id="toc-key-innovations" class="nav-link" data-scroll-target="#key-innovations">Key Innovations</a>
  <ul class="collapse">
  <li><a href="#simplified-routing-algorithm" id="toc-simplified-routing-algorithm" class="nav-link" data-scroll-target="#simplified-routing-algorithm">Simplified Routing Algorithm</a></li>
  <li><a href="#expert-capacity-and-load-balancing" id="toc-expert-capacity-and-load-balancing" class="nav-link" data-scroll-target="#expert-capacity-and-load-balancing">Expert Capacity and Load Balancing</a></li>
  <li><a href="#selective-precision-training" id="toc-selective-precision-training" class="nav-link" data-scroll-target="#selective-precision-training">Selective Precision Training</a></li>
  </ul></li>
  <li><a href="#technical-implementation-details" id="toc-technical-implementation-details" class="nav-link" data-scroll-target="#technical-implementation-details">Technical Implementation Details</a>
  <ul class="collapse">
  <li><a href="#training-considerations" id="toc-training-considerations" class="nav-link" data-scroll-target="#training-considerations">Training Considerations</a></li>
  <li><a href="#inference-optimization" id="toc-inference-optimization" class="nav-link" data-scroll-target="#inference-optimization">Inference Optimization</a></li>
  </ul></li>
  <li><a href="#performance-and-scalability" id="toc-performance-and-scalability" class="nav-link" data-scroll-target="#performance-and-scalability">Performance and Scalability</a>
  <ul class="collapse">
  <li><a href="#empirical-results" id="toc-empirical-results" class="nav-link" data-scroll-target="#empirical-results">Empirical Results</a></li>
  <li><a href="#scaling-properties" id="toc-scaling-properties" class="nav-link" data-scroll-target="#scaling-properties">Scaling Properties</a></li>
  </ul></li>
  <li><a href="#advantages-and-limitations" id="toc-advantages-and-limitations" class="nav-link" data-scroll-target="#advantages-and-limitations">Advantages and Limitations</a>
  <ul class="collapse">
  <li><a href="#advantages" id="toc-advantages" class="nav-link" data-scroll-target="#advantages">Advantages</a></li>
  <li><a href="#limitations" id="toc-limitations" class="nav-link" data-scroll-target="#limitations">Limitations</a></li>
  </ul></li>
  <li><a href="#applications-and-use-cases" id="toc-applications-and-use-cases" class="nav-link" data-scroll-target="#applications-and-use-cases">Applications and Use Cases</a>
  <ul class="collapse">
  <li><a href="#natural-language-processing" id="toc-natural-language-processing" class="nav-link" data-scroll-target="#natural-language-processing">Natural Language Processing</a></li>
  <li><a href="#beyond-nlp" id="toc-beyond-nlp" class="nav-link" data-scroll-target="#beyond-nlp">Beyond NLP</a></li>
  </ul></li>
  <li><a href="#implementation-considerations" id="toc-implementation-considerations" class="nav-link" data-scroll-target="#implementation-considerations">Implementation Considerations</a>
  <ul class="collapse">
  <li><a href="#framework-support" id="toc-framework-support" class="nav-link" data-scroll-target="#framework-support">Framework Support</a></li>
  <li><a href="#deployment-strategies" id="toc-deployment-strategies" class="nav-link" data-scroll-target="#deployment-strategies">Deployment Strategies</a></li>
  </ul></li>
  <li><a href="#future-directions-and-research" id="toc-future-directions-and-research" class="nav-link" data-scroll-target="#future-directions-and-research">Future Directions and Research</a>
  <ul class="collapse">
  <li><a href="#ongoing-research-areas" id="toc-ongoing-research-areas" class="nav-link" data-scroll-target="#ongoing-research-areas">Ongoing Research Areas</a></li>
  <li><a href="#emerging-variants" id="toc-emerging-variants" class="nav-link" data-scroll-target="#emerging-variants">Emerging Variants</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  <li><a href="#references-and-further-reading" id="toc-references-and-further-reading" class="nav-link" data-scroll-target="#references-and-further-reading">References and Further Reading</a></li>
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block column-page-right" id="quarto-document-content">






<section id="switch-transformer-scaling-neural-networks-with-sparsity" class="level1">
<h1>Switch Transformer: Scaling Neural Networks with Sparsity</h1>
<p><img src="switch.png" class="img-fluid"></p>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>The Switch Transformer represents a groundbreaking advancement in neural network architecture, introduced by Google Research in 2021. This innovative model addresses one of the most pressing challenges in deep learning: how to scale neural networks to unprecedented sizes while maintaining computational efficiency. By leveraging the concept of sparsity and expert routing, Switch Transformer achieves remarkable performance improvements with fewer computational resources per token.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Key Insight
</div>
</div>
<div class="callout-body-container callout-body">
<p>Not all parts of a neural network need to be active for every input. Switch Transformer employs a sparse approach where only a subset of the model’s parameters are activated for each token.</p>
</div>
</div>
<p>The key insight behind Switch Transformer is that not all parts of a neural network need to be active for every input. Instead of using dense computations across the entire network, Switch Transformer employs a sparse approach where only a subset of the model’s parameters are activated for each token, dramatically improving efficiency while scaling to trillions of parameters.</p>
</section>
<section id="background-and-motivation" class="level2">
<h2 class="anchored" data-anchor-id="background-and-motivation">Background and Motivation</h2>
<section id="the-scaling-challenge" class="level3">
<h3 class="anchored" data-anchor-id="the-scaling-challenge">The Scaling Challenge</h3>
<p>Traditional transformer models face a fundamental trade-off between model capacity and computational efficiency. While larger models generally perform better, they require exponentially more computational resources. For instance, GPT-3 with 175 billion parameters requires enormous computational power for both training and inference, making it accessible only to organizations with substantial resources.</p>
</section>
<section id="mixture-of-experts-moe-foundation" class="level3">
<h3 class="anchored" data-anchor-id="mixture-of-experts-moe-foundation">Mixture of Experts (MoE) Foundation</h3>
<p>Switch Transformer builds upon the Mixture of Experts (MoE) paradigm, which has been explored in various forms since the 1990s. The core idea is to have multiple specialized “expert” networks, with a gating mechanism that determines which experts should process each input. This approach allows for increased model capacity without proportionally increasing computational cost.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Previous MoE Challenges
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Complex routing algorithms</li>
<li>Training instability</li>
<li>Load balancing issues</li>
<li>Difficulty in scaling to very large numbers of experts</li>
</ul>
</div>
</div>
<p>Switch Transformer addresses these limitations through elegant simplifications and innovations.</p>
</section>
</section>
<section id="architecture-overview" class="level2">
<h2 class="anchored" data-anchor-id="architecture-overview">Architecture Overview</h2>
<section id="core-components" class="level3">
<h3 class="anchored" data-anchor-id="core-components">Core Components</h3>
<p>The Switch Transformer architecture consists of several key components that work together to achieve efficient sparse computation:</p>
<section id="switch-layer" class="level4">
<h4 class="anchored" data-anchor-id="switch-layer">Switch Layer</h4>
<p>The fundamental building block of Switch Transformer is the Switch Layer, which replaces the traditional feed-forward network (FFN) in transformer blocks. Each Switch Layer contains multiple expert networks, typically implemented as separate FFN modules.</p>
</section>
<section id="switch-routing" class="level4">
<h4 class="anchored" data-anchor-id="switch-routing">Switch Routing</h4>
<p>The routing mechanism is dramatically simplified compared to previous MoE approaches. Instead of complex routing algorithms, Switch Transformer uses a straightforward approach:</p>
<ul>
<li>Each token is routed to exactly one expert</li>
<li>The routing decision is made by a learned gating function</li>
<li>This “hard routing” approach eliminates the need for complex load balancing</li>
</ul>
</section>
<section id="expert-networks" class="level4">
<h4 class="anchored" data-anchor-id="expert-networks">Expert Networks</h4>
<p>Expert networks are individual feed-forward networks that specialize in processing specific types of inputs. Each expert has the same architecture as a standard transformer FFN but develops specialized representations during training.</p>
</section>
</section>
<section id="mathematical-foundation" class="level3">
<h3 class="anchored" data-anchor-id="mathematical-foundation">Mathematical Foundation</h3>
<p>The Switch Transformer routing can be expressed mathematically as:</p>
<div id="31bba9c7" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Switch Transformer routing function</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> switch_routing(x, experts, gating_function):</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co">    y = Switch(x) = Σ(i=1 to N) G(x)_i * E_i(x)</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Where:</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">    - x is the input token</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">    - N is the number of experts</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co">    - G(x)_i is the gating function output for expert i</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co">    - E_i(x) is the output of expert i</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    N <span class="op">=</span> <span class="bu">len</span>(experts)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    gating_weights <span class="op">=</span> gating_function(x)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Key innovation: sparse output where only one expert gets non-zero weight</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    selected_expert <span class="op">=</span> argmax(gating_weights)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> experts[selected_expert](x)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>The key innovation is that <code>G(x)</code> produces a sparse output where only one expert receives a non-zero weight, simplifying computation significantly.</p>
</section>
</section>
<section id="key-innovations" class="level2">
<h2 class="anchored" data-anchor-id="key-innovations">Key Innovations</h2>
<section id="simplified-routing-algorithm" class="level3">
<h3 class="anchored" data-anchor-id="simplified-routing-algorithm">Simplified Routing Algorithm</h3>
<p>Switch Transformer introduces a dramatically simplified routing mechanism:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true" href="">Traditional MoE Routing</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false" href="">Switch Routing</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<ul>
<li>Complex gating functions</li>
<li>Multiple experts per token</li>
<li>Soft routing with weighted combinations</li>
<li>Difficult load balancing</li>
</ul>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<ul>
<li>Single expert per token</li>
<li>Hard routing decisions</li>
<li>Simple argmax selection</li>
<li>Natural load distribution</li>
</ul>
</div>
</div>
</div>
<p>This simplification reduces computational overhead while maintaining the benefits of expert specialization.</p>
</section>
<section id="expert-capacity-and-load-balancing" class="level3">
<h3 class="anchored" data-anchor-id="expert-capacity-and-load-balancing">Expert Capacity and Load Balancing</h3>
<p>One of the most innovative aspects of Switch Transformer is its approach to load balancing:</p>
<section id="capacity-factor" class="level4">
<h4 class="anchored" data-anchor-id="capacity-factor">Capacity Factor</h4>
<p>The model uses a capacity factor to determine how many tokens each expert can process. This is calculated as:</p>
<div id="9ddd61fe" class="cell" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_expert_capacity(tokens_per_batch, num_experts, capacity_factor):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Expert Capacity = (tokens_per_batch / num_experts) * capacity_factor</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (tokens_per_batch <span class="op">/</span> num_experts) <span class="op">*</span> capacity_factor</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="auxiliary-loss" class="level4">
<h4 class="anchored" data-anchor-id="auxiliary-loss">Auxiliary Loss</h4>
<p>To encourage balanced routing, Switch Transformer employs an auxiliary loss function that penalizes uneven distribution of tokens across experts:</p>
<div id="140facb3" class="cell" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> auxiliary_loss(expert_frequencies, expert_probabilities, alpha<span class="op">=</span><span class="fl">0.01</span>):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co">    L_aux = α * Σ(i=1 to N) f_i * P_i</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Where f_i is the fraction of tokens routed to expert i,</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co">    and P_i is the probability mass for expert i.</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> alpha <span class="op">*</span> <span class="bu">sum</span>(f <span class="op">*</span> p <span class="cf">for</span> f, p <span class="kw">in</span> <span class="bu">zip</span>(expert_frequencies, expert_probabilities))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
</section>
<section id="selective-precision-training" class="level3">
<h3 class="anchored" data-anchor-id="selective-precision-training">Selective Precision Training</h3>
<p>Switch Transformer introduces selective precision training, where different components use different numerical precisions:</p>
<ul>
<li>Router computations use float32 for stability</li>
<li>Expert computations can use lower precision (bfloat16)</li>
<li>This approach balances training stability with computational efficiency</li>
</ul>
</section>
</section>
<section id="technical-implementation-details" class="level2">
<h2 class="anchored" data-anchor-id="technical-implementation-details">Technical Implementation Details</h2>
<section id="training-considerations" class="level3">
<h3 class="anchored" data-anchor-id="training-considerations">Training Considerations</h3>
<p>Training Switch Transformer models requires careful consideration of several factors:</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Training Best Practices
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li><strong>Initialization Strategy</strong>
<ul>
<li>Experts are initialized with small random weights</li>
<li>Router weights are initialized to produce uniform distributions</li>
<li>Proper initialization is crucial for achieving expert specialization</li>
</ul></li>
<li><strong>Regularization Techniques</strong>
<ul>
<li>Dropout is applied within expert networks</li>
<li>Auxiliary loss provides implicit regularization</li>
<li>Expert dropout can be used to improve robustness</li>
</ul></li>
<li><strong>Distributed Training</strong>
<ul>
<li>Experts can be distributed across different machines</li>
<li>All-to-all communication patterns are used for token routing</li>
<li>Careful attention to communication efficiency is required</li>
</ul></li>
</ol>
</div>
</div>
</section>
<section id="inference-optimization" class="level3">
<h3 class="anchored" data-anchor-id="inference-optimization">Inference Optimization</h3>
<p>Inference with Switch Transformer models involves several optimizations:</p>
<section id="expert-caching" class="level4">
<h4 class="anchored" data-anchor-id="expert-caching">Expert Caching</h4>
<ul>
<li>Frequently used experts can be cached in fast memory</li>
<li>Dynamic expert loading based on input characteristics</li>
<li>Predictive expert prefetching</li>
</ul>
</section>
<section id="batching-strategies" class="level4">
<h4 class="anchored" data-anchor-id="batching-strategies">Batching Strategies</h4>
<ul>
<li>Tokens routed to the same expert are batched together</li>
<li>Dynamic batching based on routing decisions</li>
<li>Memory-efficient expert execution</li>
</ul>
</section>
</section>
</section>
<section id="performance-and-scalability" class="level2">
<h2 class="anchored" data-anchor-id="performance-and-scalability">Performance and Scalability</h2>
<section id="empirical-results" class="level3">
<h3 class="anchored" data-anchor-id="empirical-results">Empirical Results</h3>
<p>Switch Transformer has demonstrated impressive performance across various benchmarks:</p>
<div id="87645018" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample data for illustration</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> [<span class="st">'Dense Transformer'</span>, <span class="st">'Traditional MoE'</span>, <span class="st">'Switch Transformer'</span>]</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>flops_per_token <span class="op">=</span> [<span class="dv">100</span>, <span class="dv">80</span>, <span class="dv">30</span>]</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>performance_score <span class="op">=</span> [<span class="dv">85</span>, <span class="dv">88</span>, <span class="dv">92</span>]</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co"># FLOPs comparison</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>ax1.bar(models, flops_per_token, color<span class="op">=</span>[<span class="st">'#ff6b6b'</span>, <span class="st">'#4ecdc4'</span>, <span class="st">'#45b7d1'</span>])</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'FLOPs per Token (Relative)'</span>)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">'Computational Efficiency'</span>)</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>ax1.tick_params(axis<span class="op">=</span><span class="st">'x'</span>, rotation<span class="op">=</span><span class="dv">45</span>)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Performance comparison</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>ax2.bar(models, performance_score, color<span class="op">=</span>[<span class="st">'#ff6b6b'</span>, <span class="st">'#4ecdc4'</span>, <span class="st">'#45b7d1'</span>])</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'Performance Score'</span>)</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">'Model Performance'</span>)</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>ax2.tick_params(axis<span class="op">=</span><span class="st">'x'</span>, rotation<span class="op">=</span><span class="dv">45</span>)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="index_files/figure-html/cell-5-output-1.png" class="img-fluid figure-img"></p>
<figcaption>Performance comparison showing Switch Transformer’s efficiency gains</figcaption>
</figure>
</div>
</div>
</div>
<section id="language-modeling" class="level4">
<h4 class="anchored" data-anchor-id="language-modeling">Language Modeling</h4>
<ul>
<li>Achieved state-of-the-art results on language modeling tasks</li>
<li>Significant improvements in perplexity with fewer FLOPs</li>
<li>Effective scaling to trillion-parameter models</li>
</ul>
</section>
<section id="multi-task-learning" class="level4">
<h4 class="anchored" data-anchor-id="multi-task-learning">Multi-task Learning</h4>
<ul>
<li>Strong performance across diverse NLP tasks</li>
<li>Effective knowledge transfer between tasks</li>
<li>Improved sample efficiency</li>
</ul>
</section>
</section>
<section id="scaling-properties" class="level3">
<h3 class="anchored" data-anchor-id="scaling-properties">Scaling Properties</h3>
<p>The scaling properties of Switch Transformer are particularly noteworthy:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true" href="">Parameter Scaling</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false" href="">Expert Specialization</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-3" role="tab" aria-controls="tabset-2-3" aria-selected="false" href="">Computational Efficiency</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<ul>
<li>Linear increase in parameters with number of experts</li>
<li>Sublinear increase in computational cost</li>
<li>Maintained quality with increased sparsity</li>
</ul>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<ul>
<li>Experts develop clear specializations during training</li>
<li>Linguistic experts emerge (syntax, semantics, etc.)</li>
<li>Domain-specific experts for specialized tasks</li>
</ul>
</div>
<div id="tabset-2-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-3-tab">
<ul>
<li>Significant reduction in FLOPs per token</li>
<li>Improved throughput for large-scale applications</li>
<li>Better resource utilization in distributed settings</li>
</ul>
</div>
</div>
</div>
</section>
</section>
<section id="advantages-and-limitations" class="level2">
<h2 class="anchored" data-anchor-id="advantages-and-limitations">Advantages and Limitations</h2>
<section id="advantages" class="level3">
<h3 class="anchored" data-anchor-id="advantages">Advantages</h3>
<ol type="1">
<li><strong>Computational Efficiency</strong>: Dramatically reduced computational cost per token while maintaining large model capacity</li>
<li><strong>Scalability</strong>: Ability to scale to trillions of parameters without proportional increase in computation</li>
<li><strong>Specialization</strong>: Experts develop clear specializations, leading to better performance on diverse tasks</li>
<li><strong>Flexibility</strong>: Can be applied to various transformer architectures and tasks</li>
<li><strong>Resource Optimization</strong>: Better utilization of computational resources in distributed settings</li>
</ol>
</section>
<section id="limitations" class="level3">
<h3 class="anchored" data-anchor-id="limitations">Limitations</h3>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Caution</span>Current Limitations
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li><strong>Memory Requirements</strong>: Despite computational efficiency, large models still require substantial memory</li>
<li><strong>Communication Overhead</strong>: Distributed training requires careful optimization of communication patterns</li>
<li><strong>Load Balancing</strong>: Achieving perfect load balance across experts remains challenging</li>
<li><strong>Complexity</strong>: Implementation complexity is higher than standard transformers</li>
<li><strong>Hardware Dependencies</strong>: Optimal performance requires specialized hardware configurations</li>
</ol>
</div>
</div>
</section>
</section>
<section id="applications-and-use-cases" class="level2">
<h2 class="anchored" data-anchor-id="applications-and-use-cases">Applications and Use Cases</h2>
<section id="natural-language-processing" class="level3">
<h3 class="anchored" data-anchor-id="natural-language-processing">Natural Language Processing</h3>
<p>Switch Transformer has shown particular strength in various NLP applications:</p>
<section id="language-modeling-1" class="level4">
<h4 class="anchored" data-anchor-id="language-modeling-1">Language Modeling</h4>
<ul>
<li>Large-scale language model pretraining</li>
<li>Improved efficiency for autoregressive generation</li>
<li>Better handling of diverse linguistic phenomena</li>
</ul>
</section>
<section id="machine-translation" class="level4">
<h4 class="anchored" data-anchor-id="machine-translation">Machine Translation</h4>
<ul>
<li>Multilingual translation systems</li>
<li>Language-specific expert development</li>
<li>Improved handling of low-resource languages</li>
</ul>
</section>
<section id="text-classification" class="level4">
<h4 class="anchored" data-anchor-id="text-classification">Text Classification</h4>
<ul>
<li>Multi-domain classification tasks</li>
<li>Efficient fine-tuning for specific domains</li>
<li>Robust performance across diverse text types</li>
</ul>
</section>
</section>
<section id="beyond-nlp" class="level3">
<h3 class="anchored" data-anchor-id="beyond-nlp">Beyond NLP</h3>
<p>While primarily developed for NLP, Switch Transformer principles can be applied to other domains:</p>
<section id="computer-vision" class="level4">
<h4 class="anchored" data-anchor-id="computer-vision">Computer Vision</h4>
<ul>
<li>Vision transformers with expert routing</li>
<li>Specialized processing for different visual patterns</li>
<li>Efficient scaling for large vision models</li>
</ul>
</section>
<section id="multimodal-learning" class="level4">
<h4 class="anchored" data-anchor-id="multimodal-learning">Multimodal Learning</h4>
<ul>
<li>Cross-modal expert specialization</li>
<li>Efficient processing of diverse input modalities</li>
<li>Improved scaling for multimodal models</li>
</ul>
</section>
</section>
</section>
<section id="implementation-considerations" class="level2">
<h2 class="anchored" data-anchor-id="implementation-considerations">Implementation Considerations</h2>
<section id="framework-support" class="level3">
<h3 class="anchored" data-anchor-id="framework-support">Framework Support</h3>
<p>Switch Transformer implementations are available in several frameworks:</p>
<div id="79589915" class="cell" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example implementation structure in PyTorch</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SwitchTransformerLayer(nn.Module):</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, d_model, num_experts, expert_capacity):</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.d_model <span class="op">=</span> d_model</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_experts <span class="op">=</span> num_experts</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.expert_capacity <span class="op">=</span> expert_capacity</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Router network</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.router <span class="op">=</span> nn.Linear(d_model, num_experts)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Expert networks</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.experts <span class="op">=</span> nn.ModuleList([</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>            nn.Sequential(</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>                nn.Linear(d_model, d_model <span class="op">*</span> <span class="dv">4</span>),</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>                nn.ReLU(),</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>                nn.Linear(d_model <span class="op">*</span> <span class="dv">4</span>, d_model)</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>            ) <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(num_experts)</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Router decision</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>        router_logits <span class="op">=</span> <span class="va">self</span>.router(x)</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>        expert_weights <span class="op">=</span> torch.softmax(router_logits, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Select expert (hard routing)</span></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>        selected_expert <span class="op">=</span> torch.argmax(expert_weights, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply selected expert</span></span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>        batch_size, seq_len <span class="op">=</span> x.shape[:<span class="dv">2</span>]</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> torch.zeros_like(x)</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.num_experts):</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>            mask <span class="op">=</span> (selected_expert <span class="op">==</span> i)</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> mask.<span class="bu">any</span>():</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>                expert_input <span class="op">=</span> x[mask]</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>                expert_output <span class="op">=</span> <span class="va">self</span>.experts[i](expert_input)</span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>                output[mask] <span class="op">=</span> expert_output</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<section id="jaxflax" class="level4">
<h4 class="anchored" data-anchor-id="jaxflax">JAX/Flax</h4>
<ul>
<li>Original implementation from Google Research</li>
<li>Optimized for TPU training</li>
<li>Comprehensive distributed training support</li>
</ul>
</section>
<section id="pytorch" class="level4">
<h4 class="anchored" data-anchor-id="pytorch">PyTorch</h4>
<ul>
<li>Community implementations available</li>
<li>Integration with Hugging Face Transformers</li>
<li>Support for GPU training</li>
</ul>
</section>
<section id="tensorflow" class="level4">
<h4 class="anchored" data-anchor-id="tensorflow">TensorFlow</h4>
<ul>
<li>TensorFlow Model Garden implementations</li>
<li>Integration with TensorFlow Serving</li>
<li>Support for various deployment scenarios</li>
</ul>
</section>
</section>
<section id="deployment-strategies" class="level3">
<h3 class="anchored" data-anchor-id="deployment-strategies">Deployment Strategies</h3>
<p>Deploying Switch Transformer models requires careful consideration:</p>
<section id="inference-optimization-1" class="level4">
<h4 class="anchored" data-anchor-id="inference-optimization-1">Inference Optimization</h4>
<ul>
<li>Expert pruning for reduced model size</li>
<li>Dynamic expert loading</li>
<li>Efficient batching strategies</li>
</ul>
</section>
<section id="serving-infrastructure" class="level4">
<h4 class="anchored" data-anchor-id="serving-infrastructure">Serving Infrastructure</h4>
<ul>
<li>Distributed serving across multiple machines</li>
<li>Load balancing for expert utilization</li>
<li>Caching strategies for frequently used experts</li>
</ul>
</section>
</section>
</section>
<section id="future-directions-and-research" class="level2">
<h2 class="anchored" data-anchor-id="future-directions-and-research">Future Directions and Research</h2>
<section id="ongoing-research-areas" class="level3">
<h3 class="anchored" data-anchor-id="ongoing-research-areas">Ongoing Research Areas</h3>
<p>Several areas of active research are extending Switch Transformer capabilities:</p>
<section id="improved-routing-algorithms" class="level4">
<h4 class="anchored" data-anchor-id="improved-routing-algorithms">Improved Routing Algorithms</h4>
<ul>
<li>More sophisticated routing mechanisms</li>
<li>Adaptive routing based on input characteristics</li>
<li>Learned routing policies</li>
</ul>
</section>
<section id="dynamic-expert-creation" class="level4">
<h4 class="anchored" data-anchor-id="dynamic-expert-creation">Dynamic Expert Creation</h4>
<ul>
<li>Automatic expert creation and pruning</li>
<li>Adaptive model capacity based on task requirements</li>
<li>Continual learning with expert specialization</li>
</ul>
</section>
<section id="cross-domain-applications" class="level4">
<h4 class="anchored" data-anchor-id="cross-domain-applications">Cross-domain Applications</h4>
<ul>
<li>Extension to other domains beyond NLP</li>
<li>Universal expert architectures</li>
<li>Multi-task expert sharing</li>
</ul>
</section>
</section>
<section id="emerging-variants" class="level3">
<h3 class="anchored" data-anchor-id="emerging-variants">Emerging Variants</h3>
<p>Several variants and extensions of Switch Transformer are being explored:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true" href="">GLaM (Generalist Language Model)</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false" href="">PaLM (Pathways Language Model)</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-3" role="tab" aria-controls="tabset-3-3" aria-selected="false" href="">Switch Transformer V2</a></li></ul>
<div class="tab-content">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<ul>
<li>Improved routing mechanisms</li>
<li>Better scaling properties</li>
<li>Enhanced expert specialization</li>
</ul>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<ul>
<li>Integration with Google’s Pathways system</li>
<li>Improved distributed training</li>
<li>Better hardware utilization</li>
</ul>
</div>
<div id="tabset-3-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-3-tab">
<ul>
<li>Architectural improvements</li>
<li>Better training stability</li>
<li>Enhanced expert utilization</li>
</ul>
</div>
</div>
</div>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Switch Transformer represents a significant advancement in neural network architecture, demonstrating that sparse computation can achieve remarkable efficiency gains while maintaining or improving model performance. By simplifying the routing mechanism and leveraging expert specialization, Switch Transformer has opened new possibilities for scaling neural networks to unprecedented sizes.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Key Contributions
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Simplified routing algorithm</strong> that maintains effectiveness while reducing complexity</li>
<li><strong>Efficient scaling</strong> to trillion-parameter models with sublinear computational cost</li>
<li><strong>Demonstrated effectiveness</strong> across diverse NLP tasks</li>
<li><strong>Foundation</strong> for future sparse neural network architectures</li>
</ul>
</div>
</div>
<p>As the field continues to evolve, Switch Transformer’s principles of sparsity and expert routing will likely influence the development of future large-scale neural networks. The model’s success demonstrates that efficiency and scale are not mutually exclusive, opening new possibilities for democratizing access to large-scale AI systems.</p>
<p>The ongoing research and development in this area suggest that sparse neural networks will play an increasingly important role in the future of artificial intelligence, making powerful models more accessible and efficient for a broader range of applications and organizations.</p>
</section>
<section id="references-and-further-reading" class="level2">
<h2 class="anchored" data-anchor-id="references-and-further-reading">References and Further Reading</h2>
<p>For those interested in diving deeper into Switch Transformer and related topics, the following resources provide comprehensive coverage:</p>
<ul>
<li>Original Switch Transformer paper: “Switch Transformer: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity”</li>
<li>Mixture of Experts literature for historical context</li>
<li>Pathways system architecture papers</li>
<li>JAX/Flax documentation for implementation details</li>
<li>Recent advances in sparse neural network research</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Looking Forward
</div>
</div>
<div class="callout-body-container callout-body">
<p>The Switch Transformer represents not just a technical achievement but a paradigm shift toward more efficient and scalable neural network architectures, paving the way for the next generation of AI systems.</p>
</div>
</div>



</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>© 2025 Krishnatheja Vanka</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>