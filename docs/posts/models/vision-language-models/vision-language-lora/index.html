<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Krishnatheja Vanka">
<meta name="dcterms.date" content="2025-08-02">

<title>LoRA for Vision-Language Models: A Comprehensive Guide – Krishnatheja Vanka’s Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<link href="../../../../favicon.ico" rel="icon">
<script src="../../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-dark-2fef5ea3f8957b3e4ecc936fc74692ca.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-62c28fcd870f55f61984f019219cbd7c.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../../site_libs/bootstrap/bootstrap-dark-5a86c4bd0c1f9981a70f893fdae069f2.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../../../site_libs/bootstrap/bootstrap-62c28fcd870f55f61984f019219cbd7c.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../../styles/styles.css">
</head>

<body class="floating nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../../index.html">
    <span class="navbar-title">Krishnatheja Vanka’s Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../about.html"> 
<span class="menu-text">About me</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/theja-vanka"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-page-right">
      <h1 class="title">LoRA for Vision-Language Models: A Comprehensive Guide</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">code</div>
                <div class="quarto-category">tutorial</div>
                <div class="quarto-category">intermediate</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta column-page-right">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Krishnatheja Vanka </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">August 2, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#lora-for-vision-language-models-a-comprehensive-guide" id="toc-lora-for-vision-language-models-a-comprehensive-guide" class="nav-link active" data-scroll-target="#lora-for-vision-language-models-a-comprehensive-guide">LoRA for Vision-Language Models: A Comprehensive Guide</a>
  <ul class="collapse">
  <li><a href="#abstract" id="toc-abstract" class="nav-link" data-scroll-target="#abstract">Abstract</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a>
  <ul class="collapse">
  <li><a href="#why-lora-for-vlms" id="toc-why-lora-for-vlms" class="nav-link" data-scroll-target="#why-lora-for-vlms">Why LoRA for VLMs?</a></li>
  </ul></li>
  <li><a href="#understanding-lora" id="toc-understanding-lora" class="nav-link" data-scroll-target="#understanding-lora">Understanding LoRA</a>
  <ul class="collapse">
  <li><a href="#core-principles" id="toc-core-principles" class="nav-link" data-scroll-target="#core-principles">Core Principles</a></li>
  <li><a href="#mathematical-foundation" id="toc-mathematical-foundation" class="nav-link" data-scroll-target="#mathematical-foundation">Mathematical Foundation</a></li>
  <li><a href="#key-advantages" id="toc-key-advantages" class="nav-link" data-scroll-target="#key-advantages">Key Advantages</a></li>
  </ul></li>
  <li><a href="#vision-language-models-overview" id="toc-vision-language-models-overview" class="nav-link" data-scroll-target="#vision-language-models-overview">Vision-Language Models Overview</a>
  <ul class="collapse">
  <li><a href="#architecture-components" id="toc-architecture-components" class="nav-link" data-scroll-target="#architecture-components">Architecture Components</a></li>
  <li><a href="#popular-vlm-architectures" id="toc-popular-vlm-architectures" class="nav-link" data-scroll-target="#popular-vlm-architectures">Popular VLM Architectures</a></li>
  </ul></li>
  <li><a href="#lora-architecture-for-vlms" id="toc-lora-architecture-for-vlms" class="nav-link" data-scroll-target="#lora-architecture-for-vlms">LoRA Architecture for VLMs</a>
  <ul class="collapse">
  <li><a href="#component-wise-application" id="toc-component-wise-application" class="nav-link" data-scroll-target="#component-wise-application">Component-wise Application</a></li>
  <li><a href="#layer-selection-strategy" id="toc-layer-selection-strategy" class="nav-link" data-scroll-target="#layer-selection-strategy">Layer Selection Strategy</a></li>
  <li><a href="#rank-selection-guidelines" id="toc-rank-selection-guidelines" class="nav-link" data-scroll-target="#rank-selection-guidelines">Rank Selection Guidelines</a></li>
  </ul></li>
  <li><a href="#configuration-management" id="toc-configuration-management" class="nav-link" data-scroll-target="#configuration-management">Configuration Management</a></li>
  <li><a href="#training-strategies" id="toc-training-strategies" class="nav-link" data-scroll-target="#training-strategies">Training Strategies</a>
  <ul class="collapse">
  <li><a href="#progressive-training" id="toc-progressive-training" class="nav-link" data-scroll-target="#progressive-training">1. Progressive Training</a></li>
  <li><a href="#multi-stage-training" id="toc-multi-stage-training" class="nav-link" data-scroll-target="#multi-stage-training">2. Multi-Stage Training</a></li>
  </ul></li>
  <li><a href="#advanced-techniques" id="toc-advanced-techniques" class="nav-link" data-scroll-target="#advanced-techniques">Advanced Techniques</a>
  <ul class="collapse">
  <li><a href="#adalora-adaptive-lora" id="toc-adalora-adaptive-lora" class="nav-link" data-scroll-target="#adalora-adaptive-lora">1. AdaLoRA (Adaptive LoRA)</a></li>
  <li><a href="#dora-weight-decomposed-lora" id="toc-dora-weight-decomposed-lora" class="nav-link" data-scroll-target="#dora-weight-decomposed-lora">2. DoRA (Weight-Decomposed LoRA)</a></li>
  <li><a href="#mixture-of-loras-molora" id="toc-mixture-of-loras-molora" class="nav-link" data-scroll-target="#mixture-of-loras-molora">3. Mixture of LoRAs (MoLoRA)</a></li>
  </ul></li>
  <li><a href="#performance-optimization" id="toc-performance-optimization" class="nav-link" data-scroll-target="#performance-optimization">Performance Optimization</a>
  <ul class="collapse">
  <li><a href="#memory-optimization" id="toc-memory-optimization" class="nav-link" data-scroll-target="#memory-optimization">Memory Optimization</a></li>
  <li><a href="#training-optimizations" id="toc-training-optimizations" class="nav-link" data-scroll-target="#training-optimizations">Training Optimizations</a></li>
  </ul></li>
  <li><a href="#use-cases-and-applications" id="toc-use-cases-and-applications" class="nav-link" data-scroll-target="#use-cases-and-applications">Use Cases and Applications</a>
  <ul class="collapse">
  <li><a href="#domain-adaptation" id="toc-domain-adaptation" class="nav-link" data-scroll-target="#domain-adaptation">1. Domain Adaptation</a></li>
  <li><a href="#multi-lingual-vision-language" id="toc-multi-lingual-vision-language" class="nav-link" data-scroll-target="#multi-lingual-vision-language">2. Multi-lingual Vision-Language</a></li>
  <li><a href="#few-shot-learning" id="toc-few-shot-learning" class="nav-link" data-scroll-target="#few-shot-learning">3. Few-Shot Learning</a></li>
  </ul></li>
  <li><a href="#best-practices" id="toc-best-practices" class="nav-link" data-scroll-target="#best-practices">Best Practices</a>
  <ul class="collapse">
  <li><a href="#hyperparameter-selection" id="toc-hyperparameter-selection" class="nav-link" data-scroll-target="#hyperparameter-selection">1. Hyperparameter Selection</a></li>
  <li><a href="#module-selection-strategy" id="toc-module-selection-strategy" class="nav-link" data-scroll-target="#module-selection-strategy">2. Module Selection Strategy</a></li>
  <li><a href="#training-best-practices" id="toc-training-best-practices" class="nav-link" data-scroll-target="#training-best-practices">3. Training Best Practices</a></li>
  </ul></li>
  <li><a href="#troubleshooting" id="toc-troubleshooting" class="nav-link" data-scroll-target="#troubleshooting">Troubleshooting</a>
  <ul class="collapse">
  <li><a href="#common-issues-and-solutions" id="toc-common-issues-and-solutions" class="nav-link" data-scroll-target="#common-issues-and-solutions">Common Issues and Solutions</a></li>
  <li><a href="#debugging-tools" id="toc-debugging-tools" class="nav-link" data-scroll-target="#debugging-tools">Debugging Tools</a></li>
  </ul></li>
  <li><a href="#production-deployment" id="toc-production-deployment" class="nav-link" data-scroll-target="#production-deployment">Production Deployment</a>
  <ul class="collapse">
  <li><a href="#model-management-system" id="toc-model-management-system" class="nav-link" data-scroll-target="#model-management-system">Model Management System</a></li>
  <li><a href="#api-server-implementation" id="toc-api-server-implementation" class="nav-link" data-scroll-target="#api-server-implementation">API Server Implementation</a></li>
  </ul></li>
  <li><a href="#monitoring-and-observability" id="toc-monitoring-and-observability" class="nav-link" data-scroll-target="#monitoring-and-observability">Monitoring and Observability</a>
  <ul class="collapse">
  <li><a href="#performance-monitoring" id="toc-performance-monitoring" class="nav-link" data-scroll-target="#performance-monitoring">Performance Monitoring</a></li>
  <li><a href="#visualization-and-dashboards" id="toc-visualization-and-dashboards" class="nav-link" data-scroll-target="#visualization-and-dashboards">Visualization and Dashboards</a></li>
  </ul></li>
  <li><a href="#future-directions" id="toc-future-directions" class="nav-link" data-scroll-target="#future-directions">Future Directions</a>
  <ul class="collapse">
  <li><a href="#emerging-techniques" id="toc-emerging-techniques" class="nav-link" data-scroll-target="#emerging-techniques">Emerging Techniques</a></li>
  <li><a href="#research-opportunities" id="toc-research-opportunities" class="nav-link" data-scroll-target="#research-opportunities">Research Opportunities</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a>
  <ul class="collapse">
  <li><a href="#summary-of-key-points" id="toc-summary-of-key-points" class="nav-link" data-scroll-target="#summary-of-key-points">Summary of Key Points</a></li>
  <li><a href="#future-outlook" id="toc-future-outlook" class="nav-link" data-scroll-target="#future-outlook">Future Outlook</a></li>
  <li><a href="#resources-for-further-learning" id="toc-resources-for-further-learning" class="nav-link" data-scroll-target="#resources-for-further-learning">Resources for Further Learning</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block column-page-right" id="quarto-document-content">






<section id="lora-for-vision-language-models-a-comprehensive-guide" class="level1">
<h1>LoRA for Vision-Language Models: A Comprehensive Guide</h1>
<p><img src="lora.png" class="img-fluid"></p>
<section id="abstract" class="level2">
<h2 class="anchored" data-anchor-id="abstract">Abstract</h2>
<p>Low-Rank Adaptation (LoRA) has emerged as a revolutionary technique for efficient fine-tuning of large language models, and its application to Vision-Language Models (VLMs) represents a significant advancement in multimodal AI. This comprehensive guide provides theoretical foundations, practical implementation strategies, and production deployment techniques for LoRA in VLMs, covering everything from basic concepts to advanced optimization methods.</p>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Vision-Language Models like CLIP, BLIP, LLaVA, and GPT-4V contain billions of parameters, making full fine-tuning computationally expensive and memory-intensive. LoRA addresses these challenges by:</p>
<ul>
<li><strong>Reducing memory requirements</strong> by up to 90%</li>
<li><strong>Accelerating training</strong> by 2-3x</li>
<li><strong>Maintaining model performance</strong> with minimal parameter overhead</li>
<li><strong>Enabling modular adaptation</strong> for different tasks and domains</li>
</ul>
<section id="why-lora-for-vlms" class="level3">
<h3 class="anchored" data-anchor-id="why-lora-for-vlms">Why LoRA for VLMs?</h3>
<div id="cell-fig-lora-benefits" class="cell" data-execution_count="1">
<div class="cell-output cell-output-display">
<div id="fig-lora-benefits" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-lora-benefits-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-lora-benefits-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-lora-benefits-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: LoRA Benefits Comparison
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="understanding-lora" class="level2">
<h2 class="anchored" data-anchor-id="understanding-lora">Understanding LoRA</h2>
<section id="core-principles" class="level3">
<h3 class="anchored" data-anchor-id="core-principles">Core Principles</h3>
<p>LoRA is based on the hypothesis that weight updates during fine-tuning have a low intrinsic rank. Instead of updating all parameters, LoRA decomposes the weight update matrix into two smaller matrices:</p>
<p><span class="math display">\[\Delta W = BA\]</span></p>
<p>Where: - <span class="math inline">\(W\)</span> is the original weight matrix (<span class="math inline">\(d \times d\)</span>) - <span class="math inline">\(B\)</span> is a learnable matrix (<span class="math inline">\(d \times r\)</span>)<br>
- <span class="math inline">\(A\)</span> is a learnable matrix (<span class="math inline">\(r \times d\)</span>) - <span class="math inline">\(r\)</span> is the rank (<span class="math inline">\(r \ll d\)</span>)</p>
</section>
<section id="mathematical-foundation" class="level3">
<h3 class="anchored" data-anchor-id="mathematical-foundation">Mathematical Foundation</h3>
<p>For a linear layer with weight matrix <span class="math inline">\(W_0\)</span>, the forward pass becomes:</p>
<p><span class="math display">\[h = W_0x + \Delta Wx = W_0x + BAx\]</span></p>
<p>The adapted weight matrix is: <span class="math display">\[W = W_0 + \alpha BA\]</span></p>
<p>Where <span class="math inline">\(\alpha\)</span> is a scaling factor that controls the magnitude of the adaptation.</p>
<div id="lora-implementation" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LoRALayer(nn.Module):</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_features, out_features, rank<span class="op">=</span><span class="dv">16</span>, alpha<span class="op">=</span><span class="dv">16</span>, dropout<span class="op">=</span><span class="fl">0.1</span>):</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.rank <span class="op">=</span> rank</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.alpha <span class="op">=</span> alpha</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.scaling <span class="op">=</span> alpha <span class="op">/</span> rank</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># LoRA matrices</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lora_A <span class="op">=</span> nn.Linear(in_features, rank, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lora_B <span class="op">=</span> nn.Linear(rank, out_features, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout <span class="op">=</span> nn.Dropout(dropout)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize weights</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>        nn.init.kaiming_uniform_(<span class="va">self</span>.lora_A.weight, a<span class="op">=</span>math.sqrt(<span class="dv">5</span>))</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>        nn.init.zeros_(<span class="va">self</span>.lora_B.weight)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> <span class="va">self</span>.lora_A(x)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> <span class="va">self</span>.dropout(result)</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> <span class="va">self</span>.lora_B(result)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> result <span class="op">*</span> <span class="va">self</span>.scaling</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LoRALinear(nn.Module):</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, original_layer, rank<span class="op">=</span><span class="dv">16</span>, alpha<span class="op">=</span><span class="dv">16</span>, dropout<span class="op">=</span><span class="fl">0.1</span>):</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.original_layer <span class="op">=</span> original_layer</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lora <span class="op">=</span> LoRALayer(</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>            original_layer.in_features,</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>            original_layer.out_features,</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>            rank, alpha, dropout</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Freeze original weights</span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> param <span class="kw">in</span> <span class="va">self</span>.original_layer.parameters():</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>            param.requires_grad <span class="op">=</span> <span class="va">False</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.original_layer(x) <span class="op">+</span> <span class="va">self</span>.lora(x)</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Example usage</span></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>original_linear <span class="op">=</span> nn.Linear(<span class="dv">768</span>, <span class="dv">768</span>)</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>lora_linear <span class="op">=</span> LoRALinear(original_linear, rank<span class="op">=</span><span class="dv">16</span>, alpha<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Original parameters: </span><span class="sc">{</span><span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> original_linear.parameters())<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"LoRA parameters: </span><span class="sc">{</span><span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> lora_linear.lora.parameters())<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Parameter reduction: </span><span class="sc">{</span>(<span class="dv">1</span> <span class="op">-</span> <span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> lora_linear.lora.parameters()) <span class="op">/</span> <span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> original_linear.parameters())) <span class="op">*</span> <span class="dv">100</span><span class="sc">:.1f}</span><span class="ss">%"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Original parameters: 590592
LoRA parameters: 24576
Parameter reduction: 95.8%</code></pre>
</div>
</div>
</section>
<section id="key-advantages" class="level3">
<h3 class="anchored" data-anchor-id="key-advantages">Key Advantages</h3>
<ol type="1">
<li><strong>Parameter Efficiency</strong>: Only trains ~0.1-1% of original parameters</li>
<li><strong>Memory Efficiency</strong>: Reduced GPU memory requirements</li>
<li><strong>Modularity</strong>: Multiple LoRA adapters can be stored and swapped</li>
<li><strong>Preservation</strong>: Original model weights remain unchanged</li>
<li><strong>Composability</strong>: Multiple LoRAs can be combined</li>
</ol>
</section>
</section>
<section id="vision-language-models-overview" class="level2">
<h2 class="anchored" data-anchor-id="vision-language-models-overview">Vision-Language Models Overview</h2>
<section id="architecture-components" class="level3">
<h3 class="anchored" data-anchor-id="architecture-components">Architecture Components</h3>
<p>Modern VLMs typically consist of:</p>
<ol type="1">
<li><strong>Vision Encoder</strong>: Processes visual inputs (e.g., Vision Transformer, ResNet)</li>
<li><strong>Text Encoder</strong>: Processes textual inputs (e.g., BERT, GPT)</li>
<li><strong>Multimodal Fusion</strong>: Combines visual and textual representations</li>
<li><strong>Output Head</strong>: Task-specific prediction layers</li>
</ol>
<div id="cell-vlm-architecture-diagram" class="cell" data-execution_count="3">
<div class="cell-output cell-output-display">
<div id="vlm-architecture-diagram" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="index_files/figure-html/vlm-architecture-diagram-output-1.png" class="img-fluid figure-img"></p>
<figcaption>Vision-Language Model Architecture</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="popular-vlm-architectures" class="level3">
<h3 class="anchored" data-anchor-id="popular-vlm-architectures">Popular VLM Architectures</h3>
<section id="clip-contrastive-language-image-pre-training" class="level4">
<h4 class="anchored" data-anchor-id="clip-contrastive-language-image-pre-training">CLIP (Contrastive Language-Image Pre-training)</h4>
<ul>
<li>Dual-encoder architecture</li>
<li>Contrastive learning objective</li>
<li>Strong zero-shot capabilities</li>
</ul>
</section>
<section id="blip-bootstrapping-language-image-pre-training" class="level4">
<h4 class="anchored" data-anchor-id="blip-bootstrapping-language-image-pre-training">BLIP (Bootstrapping Language-Image Pre-training)</h4>
<ul>
<li>Encoder-decoder architecture</li>
<li>Unified vision-language understanding and generation</li>
<li>Bootstrap learning from noisy web data</li>
</ul>
</section>
<section id="llava-large-language-and-vision-assistant" class="level4">
<h4 class="anchored" data-anchor-id="llava-large-language-and-vision-assistant">LLaVA (Large Language and Vision Assistant)</h4>
<ul>
<li>Combines vision encoder with large language model</li>
<li>Instruction tuning for conversational abilities</li>
<li>Strong multimodal reasoning</li>
</ul>
</section>
</section>
</section>
<section id="lora-architecture-for-vlms" class="level2">
<h2 class="anchored" data-anchor-id="lora-architecture-for-vlms">LoRA Architecture for VLMs</h2>
<section id="component-wise-application" class="level3">
<h3 class="anchored" data-anchor-id="component-wise-application">Component-wise Application</h3>
<p>LoRA can be applied to different components of VLMs:</p>
<div id="vlm-lora-adapter" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> VLMLoRAAdapter:</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, model, config):</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> model</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.config <span class="op">=</span> config</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lora_layers <span class="op">=</span> {}</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> add_lora_to_attention(<span class="va">self</span>, module_name, attention_layer):</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Add LoRA to attention mechanism"""</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Query, Key, Value projections</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">hasattr</span>(attention_layer, <span class="st">'q_proj'</span>):</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>            attention_layer.q_proj <span class="op">=</span> LoRALinear(</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>                attention_layer.q_proj, </span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>                rank<span class="op">=</span><span class="va">self</span>.config.rank,</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>                alpha<span class="op">=</span><span class="va">self</span>.config.alpha</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">hasattr</span>(attention_layer, <span class="st">'k_proj'</span>):</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>            attention_layer.k_proj <span class="op">=</span> LoRALinear(</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>                attention_layer.k_proj,</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>                rank<span class="op">=</span><span class="va">self</span>.config.rank,</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>                alpha<span class="op">=</span><span class="va">self</span>.config.alpha</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">hasattr</span>(attention_layer, <span class="st">'v_proj'</span>):</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>            attention_layer.v_proj <span class="op">=</span> LoRALinear(</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>                attention_layer.v_proj,</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>                rank<span class="op">=</span><span class="va">self</span>.config.rank,</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>                alpha<span class="op">=</span><span class="va">self</span>.config.alpha</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> add_lora_to_mlp(<span class="va">self</span>, module_name, mlp_layer):</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Add LoRA to feed-forward layers"""</span></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">hasattr</span>(mlp_layer, <span class="st">'fc1'</span>):</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>            mlp_layer.fc1 <span class="op">=</span> LoRALinear(</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>                mlp_layer.fc1,</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>                rank<span class="op">=</span><span class="va">self</span>.config.rank,</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>                alpha<span class="op">=</span><span class="va">self</span>.config.alpha</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">hasattr</span>(mlp_layer, <span class="st">'fc2'</span>):</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>            mlp_layer.fc2 <span class="op">=</span> LoRALinear(</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>                mlp_layer.fc2,</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>                rank<span class="op">=</span><span class="va">self</span>.config.rank,</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>                alpha<span class="op">=</span><span class="va">self</span>.config.alpha</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>            )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="layer-selection-strategy" class="level3">
<h3 class="anchored" data-anchor-id="layer-selection-strategy">Layer Selection Strategy</h3>
<p>Not all layers benefit equally from LoRA adaptation:</p>
<div id="tbl-layer-priority" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="5">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-layer-priority-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: LoRA Layer Selection Priority
</figcaption>
<div aria-describedby="tbl-layer-priority-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-stdout">
<pre><code>Priority                 Layer Type                             Reason
    High     Final attention layers Most task-specific representations
    High      Cross-modal attention     Critical for multimodal fusion
    High Task-specific output heads           Direct impact on outputs
  Medium  Middle transformer layers        Balanced feature extraction
  Medium      Feed-forward networks         Non-linear transformations
     Low       Early encoder layers         Generic low-level features
     Low           Embedding layers   Fixed vocabulary representations</code></pre>
</div>
</div>
</figure>
</div>
</section>
<section id="rank-selection-guidelines" class="level3">
<h3 class="anchored" data-anchor-id="rank-selection-guidelines">Rank Selection Guidelines</h3>
<p>The rank <span class="math inline">\(r\)</span> significantly impacts performance and efficiency:</p>
<div id="cell-fig-rank-comparison" class="cell" data-execution_count="6">
<div class="cell-output cell-output-display">
<div id="fig-rank-comparison" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-rank-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-rank-comparison-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rank-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: LoRA Rank vs Performance Trade-off
</figcaption>
</figure>
</div>
</div>
</div>
<p><strong>Rank Selection Guidelines:</strong> - <strong>r = 1-4</strong>: Minimal parameters, suitable for simple adaptations - <strong>r = 8-16</strong>: Balanced efficiency and performance for most tasks - <strong>r = 32-64</strong>: Higher capacity for complex domain adaptations - <strong>r = 128+</strong>: Approaching full fine-tuning, rarely needed</p>
</section>
</section>
<section id="configuration-management" class="level2">
<h2 class="anchored" data-anchor-id="configuration-management">Configuration Management</h2>
<div id="lora-config" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dataclasses <span class="im">import</span> dataclass</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> List, Optional</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="at">@dataclass</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LoRAConfig:</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Basic LoRA parameters</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    rank: <span class="bu">int</span> <span class="op">=</span> <span class="dv">16</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    alpha: <span class="bu">int</span> <span class="op">=</span> <span class="dv">16</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    dropout: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Target modules</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    target_modules: List[<span class="bu">str</span>] <span class="op">=</span> <span class="va">None</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    vision_target_modules: List[<span class="bu">str</span>] <span class="op">=</span> <span class="va">None</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    text_target_modules: List[<span class="bu">str</span>] <span class="op">=</span> <span class="va">None</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Training parameters</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    learning_rate: <span class="bu">float</span> <span class="op">=</span> <span class="fl">1e-4</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    weight_decay: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>    warmup_steps: <span class="bu">int</span> <span class="op">=</span> <span class="dv">500</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Advanced options</span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>    use_gradient_checkpointing: <span class="bu">bool</span> <span class="op">=</span> <span class="va">True</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>    mixed_precision: <span class="bu">bool</span> <span class="op">=</span> <span class="va">True</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>    task_type: <span class="bu">str</span> <span class="op">=</span> <span class="st">"multimodal_classification"</span></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> __post_init__(<span class="va">self</span>):</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.target_modules <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.target_modules <span class="op">=</span> [</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>                <span class="st">"q_proj"</span>, <span class="st">"k_proj"</span>, <span class="st">"v_proj"</span>, <span class="st">"o_proj"</span>,</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>                <span class="st">"gate_proj"</span>, <span class="st">"up_proj"</span>, <span class="st">"down_proj"</span></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>            ]</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.vision_target_modules <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.vision_target_modules <span class="op">=</span> [</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>                <span class="st">"qkv"</span>, <span class="st">"proj"</span>, <span class="st">"fc1"</span>, <span class="st">"fc2"</span></span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>            ]</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.text_target_modules <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.text_target_modules <span class="op">=</span> [</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>                <span class="st">"q_proj"</span>, <span class="st">"k_proj"</span>, <span class="st">"v_proj"</span>, <span class="st">"dense"</span></span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>            ]</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Example configurations for different tasks</span></span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>task_configs <span class="op">=</span> {</span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>    <span class="st">"image_captioning"</span>: LoRAConfig(</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>        rank<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>        alpha<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>        target_modules<span class="op">=</span>[<span class="st">"q_proj"</span>, <span class="st">"v_proj"</span>, <span class="st">"dense"</span>],</span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>        task_type<span class="op">=</span><span class="st">"image_captioning"</span></span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>    <span class="st">"visual_question_answering"</span>: LoRAConfig(</span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>        rank<span class="op">=</span><span class="dv">16</span>,</span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>        alpha<span class="op">=</span><span class="dv">16</span>,</span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>        target_modules<span class="op">=</span>[<span class="st">"q_proj"</span>, <span class="st">"k_proj"</span>, <span class="st">"v_proj"</span>],</span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a>        task_type<span class="op">=</span><span class="st">"visual_question_answering"</span></span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a>    <span class="st">"image_classification"</span>: LoRAConfig(</span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>        rank<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a>        alpha<span class="op">=</span><span class="dv">16</span>,</span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a>        target_modules<span class="op">=</span>[<span class="st">"qkv"</span>, <span class="st">"proj"</span>],</span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a>        task_type<span class="op">=</span><span class="st">"image_classification"</span></span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Available task configurations:"</span>)</span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> task, config <span class="kw">in</span> task_configs.items():</span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"- </span><span class="sc">{</span>task<span class="sc">}</span><span class="ss">: rank=</span><span class="sc">{</span>config<span class="sc">.</span>rank<span class="sc">}</span><span class="ss">, alpha=</span><span class="sc">{</span>config<span class="sc">.</span>alpha<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Available task configurations:
- image_captioning: rank=32, alpha=32
- visual_question_answering: rank=16, alpha=16
- image_classification: rank=8, alpha=16</code></pre>
</div>
</div>
</section>
<section id="training-strategies" class="level2">
<h2 class="anchored" data-anchor-id="training-strategies">Training Strategies</h2>
<section id="progressive-training" class="level3">
<h3 class="anchored" data-anchor-id="progressive-training">1. Progressive Training</h3>
<p>Start with lower ranks and gradually increase:</p>
<div id="progressive-training" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ProgressiveLoRATrainer:</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, model, initial_rank<span class="op">=</span><span class="dv">4</span>, max_rank<span class="op">=</span><span class="dv">32</span>):</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> model</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.current_rank <span class="op">=</span> initial_rank</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.max_rank <span class="op">=</span> max_rank</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> expand_rank(<span class="va">self</span>, new_rank):</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Expand LoRA rank while preserving learned weights"""</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> name, module <span class="kw">in</span> <span class="va">self</span>.model.named_modules():</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(module, LoRALinear):</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>                old_lora <span class="op">=</span> module.lora</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Create new LoRA layer</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>                new_lora <span class="op">=</span> LoRALayer(</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>                    old_lora.lora_A.in_features,</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>                    old_lora.lora_B.out_features,</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>                    rank<span class="op">=</span>new_rank</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Copy existing weights</span></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>                <span class="cf">with</span> torch.no_grad():</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>                    new_lora.lora_A.weight[:old_lora.rank] <span class="op">=</span> old_lora.lora_A.weight</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>                    new_lora.lora_B.weight[:, :old_lora.rank] <span class="op">=</span> old_lora.lora_B.weight</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>                module.lora <span class="op">=</span> new_lora</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> progressive_training_schedule(<span class="va">self</span>, num_epochs):</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Generate progressive training schedule"""</span></span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>        schedule <span class="op">=</span> []</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>        epochs_per_stage <span class="op">=</span> num_epochs <span class="op">//</span> <span class="dv">3</span></span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Stage 1: Small rank</span></span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>        schedule.append({</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>            <span class="st">'epochs'</span>: epochs_per_stage,</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>            <span class="st">'rank'</span>: <span class="dv">4</span>,</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>            <span class="st">'lr'</span>: <span class="fl">1e-3</span>,</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>            <span class="st">'description'</span>: <span class="st">'Initial adaptation with small rank'</span></span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Stage 2: Medium rank</span></span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>        schedule.append({</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>            <span class="st">'epochs'</span>: epochs_per_stage,</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a>            <span class="st">'rank'</span>: <span class="dv">16</span>,</span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>            <span class="st">'lr'</span>: <span class="fl">5e-4</span>,</span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>            <span class="st">'description'</span>: <span class="st">'Expand capacity with medium rank'</span></span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Stage 3: Full rank</span></span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a>        schedule.append({</span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>            <span class="st">'epochs'</span>: num_epochs <span class="op">-</span> <span class="dv">2</span> <span class="op">*</span> epochs_per_stage,</span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a>            <span class="st">'rank'</span>: <span class="dv">32</span>,</span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a>            <span class="st">'lr'</span>: <span class="fl">1e-4</span>,</span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a>            <span class="st">'description'</span>: <span class="st">'Fine-tune with full rank'</span></span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> schedule</span>
<span id="cb7-57"><a href="#cb7-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-58"><a href="#cb7-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Example usage</span></span>
<span id="cb7-59"><a href="#cb7-59" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> ProgressiveLoRATrainer(<span class="va">None</span>)  <span class="co"># Would pass actual model</span></span>
<span id="cb7-60"><a href="#cb7-60" aria-hidden="true" tabindex="-1"></a>schedule <span class="op">=</span> trainer.progressive_training_schedule(<span class="dv">12</span>)</span>
<span id="cb7-61"><a href="#cb7-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-62"><a href="#cb7-62" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Progressive Training Schedule:"</span>)</span>
<span id="cb7-63"><a href="#cb7-63" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, stage <span class="kw">in</span> <span class="bu">enumerate</span>(schedule, <span class="dv">1</span>):</span>
<span id="cb7-64"><a href="#cb7-64" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Stage </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>stage[<span class="st">'description'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-65"><a href="#cb7-65" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  - Epochs: </span><span class="sc">{</span>stage[<span class="st">'epochs'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-66"><a href="#cb7-66" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  - Rank: </span><span class="sc">{</span>stage[<span class="st">'rank'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-67"><a href="#cb7-67" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  - Learning Rate: </span><span class="sc">{</span>stage[<span class="st">'lr'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-68"><a href="#cb7-68" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Progressive Training Schedule:
Stage 1: Initial adaptation with small rank
  - Epochs: 4
  - Rank: 4
  - Learning Rate: 0.001

Stage 2: Expand capacity with medium rank
  - Epochs: 4
  - Rank: 16
  - Learning Rate: 0.0005

Stage 3: Fine-tune with full rank
  - Epochs: 4
  - Rank: 32
  - Learning Rate: 0.0001
</code></pre>
</div>
</div>
</section>
<section id="multi-stage-training" class="level3">
<h3 class="anchored" data-anchor-id="multi-stage-training">2. Multi-Stage Training</h3>
<div id="multistage-training" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> multi_stage_training(model, train_loader, config):</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Multi-stage training strategy:</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co">    1. Stage 1: Freeze vision encoder, train text components</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co">    2. Stage 2: Freeze text encoder, train vision components  </span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co">    3. Stage 3: Joint training with reduced learning rate</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Multi-Stage Training Strategy"</span>)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">40</span>)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Stage 1: Text-only training</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Stage 1: Text-only training"</span>)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"- Freezing vision encoder"</span>)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"- Training text LoRA components"</span>)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> name, param <span class="kw">in</span> model.named_parameters():</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">'vision'</span> <span class="kw">in</span> name:</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>            param.requires_grad <span class="op">=</span> <span class="va">False</span></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="st">'lora'</span> <span class="kw">in</span> name <span class="kw">and</span> <span class="st">'text'</span> <span class="kw">in</span> name:</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>            param.requires_grad <span class="op">=</span> <span class="va">True</span></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>    trainable_params_stage1 <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> model.parameters() <span class="cf">if</span> p.requires_grad)</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"- Trainable parameters: </span><span class="sc">{</span>trainable_params_stage1<span class="sc">:,}</span><span class="ss">"</span>)</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># train_stage(model, train_loader, epochs=config.stage1_epochs)</span></span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Stage 2: Vision-only training</span></span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Stage 2: Vision-only training"</span>)</span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"- Freezing text encoder"</span>)</span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"- Training vision LoRA components"</span>)</span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> name, param <span class="kw">in</span> model.named_parameters():</span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">'text'</span> <span class="kw">in</span> name:</span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>            param.requires_grad <span class="op">=</span> <span class="va">False</span></span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="st">'lora'</span> <span class="kw">in</span> name <span class="kw">and</span> <span class="st">'vision'</span> <span class="kw">in</span> name:</span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a>            param.requires_grad <span class="op">=</span> <span class="va">True</span></span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a>    trainable_params_stage2 <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> model.parameters() <span class="cf">if</span> p.requires_grad)</span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"- Trainable parameters: </span><span class="sc">{</span>trainable_params_stage2<span class="sc">:,}</span><span class="ss">"</span>)</span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># train_stage(model, train_loader, epochs=config.stage2_epochs)</span></span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Stage 3: Joint training</span></span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Stage 3: Joint training"</span>)</span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"- Training all LoRA components"</span>)</span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"- Reduced learning rate for stability"</span>)</span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> name, param <span class="kw">in</span> model.named_parameters():</span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">'lora'</span> <span class="kw">in</span> name:</span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a>            param.requires_grad <span class="op">=</span> <span class="va">True</span></span>
<span id="cb9-52"><a href="#cb9-52" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-53"><a href="#cb9-53" aria-hidden="true" tabindex="-1"></a>    trainable_params_stage3 <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> model.parameters() <span class="cf">if</span> p.requires_grad)</span>
<span id="cb9-54"><a href="#cb9-54" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"- Trainable parameters: </span><span class="sc">{</span>trainable_params_stage3<span class="sc">:,}</span><span class="ss">"</span>)</span>
<span id="cb9-55"><a href="#cb9-55" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-56"><a href="#cb9-56" aria-hidden="true" tabindex="-1"></a>    <span class="co"># train_stage(model, train_loader, epochs=config.stage3_epochs, lr=config.lr * 0.1)</span></span>
<span id="cb9-57"><a href="#cb9-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-58"><a href="#cb9-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Example configuration</span></span>
<span id="cb9-59"><a href="#cb9-59" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MultiStageConfig:</span>
<span id="cb9-60"><a href="#cb9-60" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb9-61"><a href="#cb9-61" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.stage1_epochs <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb9-62"><a href="#cb9-62" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.stage2_epochs <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb9-63"><a href="#cb9-63" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.stage3_epochs <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb9-64"><a href="#cb9-64" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lr <span class="op">=</span> <span class="fl">1e-4</span></span>
<span id="cb9-65"><a href="#cb9-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-66"><a href="#cb9-66" aria-hidden="true" tabindex="-1"></a>config <span class="op">=</span> MultiStageConfig()</span>
<span id="cb9-67"><a href="#cb9-67" aria-hidden="true" tabindex="-1"></a><span class="co"># multi_stage_training(None, None, config)  # Would pass actual model and data</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
<section id="advanced-techniques" class="level2">
<h2 class="anchored" data-anchor-id="advanced-techniques">Advanced Techniques</h2>
<section id="adalora-adaptive-lora" class="level3">
<h3 class="anchored" data-anchor-id="adalora-adaptive-lora">1. AdaLoRA (Adaptive LoRA)</h3>
<p>Dynamically adjusts rank based on importance:</p>
<div id="adalora" class="cell" data-execution_count="10">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> AdaLoRALayer(nn.Module):</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_features, out_features, max_rank<span class="op">=</span><span class="dv">64</span>, init_rank<span class="op">=</span><span class="dv">16</span>):</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.max_rank <span class="op">=</span> max_rank</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.current_rank <span class="op">=</span> init_rank</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Full-rank matrices for potential expansion</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lora_A <span class="op">=</span> nn.Parameter(torch.zeros(max_rank, in_features))</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lora_B <span class="op">=</span> nn.Parameter(torch.zeros(out_features, max_rank))</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Importance scores</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.importance_scores <span class="op">=</span> nn.Parameter(torch.ones(max_rank))</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize only active components</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.reset_parameters()</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> reset_parameters(<span class="va">self</span>):</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Initialize parameters"""</span></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>        nn.init.kaiming_uniform_(<span class="va">self</span>.lora_A[:<span class="va">self</span>.current_rank], a<span class="op">=</span>math.sqrt(<span class="dv">5</span>))</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>        nn.init.zeros_(<span class="va">self</span>.lora_B[:, :<span class="va">self</span>.current_rank])</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply importance-weighted LoRA</span></span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>        active_A <span class="op">=</span> <span class="va">self</span>.lora_A[:<span class="va">self</span>.current_rank] <span class="op">*</span> <span class="va">self</span>.importance_scores[:<span class="va">self</span>.current_rank, <span class="va">None</span>]</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>        active_B <span class="op">=</span> <span class="va">self</span>.lora_B[:, :<span class="va">self</span>.current_rank] <span class="op">*</span> <span class="va">self</span>.importance_scores[<span class="va">None</span>, :<span class="va">self</span>.current_rank]</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x <span class="op">@</span> active_A.T <span class="op">@</span> active_B.T</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> update_rank(<span class="va">self</span>, budget_ratio<span class="op">=</span><span class="fl">0.7</span>):</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Update rank based on importance scores"""</span></span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>        scores <span class="op">=</span> <span class="va">self</span>.importance_scores.<span class="bu">abs</span>()</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>        threshold <span class="op">=</span> torch.quantile(scores, <span class="dv">1</span> <span class="op">-</span> budget_ratio)</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>        new_rank <span class="op">=</span> (scores <span class="op">&gt;=</span> threshold).<span class="bu">sum</span>().item()</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> new_rank <span class="op">!=</span> <span class="va">self</span>.current_rank:</span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Rank updated: </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>current_rank<span class="sc">}</span><span class="ss"> -&gt; </span><span class="sc">{</span>new_rank<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.current_rank <span class="op">=</span> new_rank</span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> new_rank</span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Demonstration of AdaLoRA rank adaptation</span></span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a>adalora_layer <span class="op">=</span> AdaLoRALayer(<span class="dv">768</span>, <span class="dv">768</span>, max_rank<span class="op">=</span><span class="dv">64</span>, init_rank<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"AdaLoRA Rank Adaptation Demo:"</span>)</span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Initial rank: </span><span class="sc">{</span>adalora_layer<span class="sc">.</span>current_rank<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-47"><a href="#cb10-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate importance score changes</span></span>
<span id="cb10-48"><a href="#cb10-48" aria-hidden="true" tabindex="-1"></a>adalora_layer.importance_scores.data <span class="op">=</span> torch.rand(<span class="dv">64</span>)  <span class="co"># Random importance scores</span></span>
<span id="cb10-49"><a href="#cb10-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-50"><a href="#cb10-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Update rank based on importance</span></span>
<span id="cb10-51"><a href="#cb10-51" aria-hidden="true" tabindex="-1"></a>new_rank <span class="op">=</span> adalora_layer.update_rank(budget_ratio<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb10-52"><a href="#cb10-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"New rank after adaptation: </span><span class="sc">{</span>new_rank<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>AdaLoRA Rank Adaptation Demo:
Initial rank: 16
Rank updated: 16 -&gt; 32
New rank after adaptation: 32</code></pre>
</div>
</div>
</section>
<section id="dora-weight-decomposed-lora" class="level3">
<h3 class="anchored" data-anchor-id="dora-weight-decomposed-lora">2. DoRA (Weight-Decomposed LoRA)</h3>
<p>Separates magnitude and direction updates:</p>
<div id="dora" class="cell" data-execution_count="11">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DoRALayer(nn.Module):</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_features, out_features, rank<span class="op">=</span><span class="dv">16</span>):</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.rank <span class="op">=</span> rank</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Standard LoRA components</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lora_A <span class="op">=</span> nn.Linear(in_features, rank, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lora_B <span class="op">=</span> nn.Linear(rank, out_features, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Magnitude component</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.magnitude <span class="op">=</span> nn.Parameter(torch.ones(out_features))</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize LoRA weights</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>        nn.init.kaiming_uniform_(<span class="va">self</span>.lora_A.weight, a<span class="op">=</span>math.sqrt(<span class="dv">5</span>))</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>        nn.init.zeros_(<span class="va">self</span>.lora_B.weight)</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, original_weight):</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># LoRA adaptation</span></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>        lora_result <span class="op">=</span> <span class="va">self</span>.lora_B(<span class="va">self</span>.lora_A(x))</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Direction component (normalized)</span></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>        adapted_weight <span class="op">=</span> original_weight <span class="op">+</span> lora_result</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>        direction <span class="op">=</span> F.normalize(adapted_weight, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply magnitude scaling</span></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> direction <span class="op">*</span> <span class="va">self</span>.magnitude.unsqueeze(<span class="dv">0</span>)</span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Compare LoRA vs DoRA</span></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>original_weight <span class="op">=</span> torch.randn(<span class="dv">32</span>, <span class="dv">768</span>)</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn(<span class="dv">32</span>, <span class="dv">768</span>)</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Standard LoRA</span></span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>lora_layer <span class="op">=</span> LoRALayer(<span class="dv">768</span>, <span class="dv">768</span>, rank<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>lora_output <span class="op">=</span> lora_layer(x)</span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a><span class="co"># DoRA</span></span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a>dora_layer <span class="op">=</span> DoRALayer(<span class="dv">768</span>, <span class="dv">768</span>, rank<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>dora_output <span class="op">=</span> dora_layer(x, original_weight)</span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"LoRA vs DoRA Comparison:"</span>)</span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"LoRA output shape: </span><span class="sc">{</span>lora_output<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"DoRA output shape: </span><span class="sc">{</span>dora_output<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"LoRA output norm: </span><span class="sc">{</span>lora_output<span class="sc">.</span>norm()<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"DoRA output norm: </span><span class="sc">{</span>dora_output<span class="sc">.</span>norm()<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>LoRA vs DoRA Comparison:
LoRA output shape: torch.Size([32, 768])
DoRA output shape: torch.Size([32, 768])
LoRA output norm: 0.0000
DoRA output norm: 5.6569</code></pre>
</div>
</div>
</section>
<section id="mixture-of-loras-molora" class="level3">
<h3 class="anchored" data-anchor-id="mixture-of-loras-molora">3. Mixture of LoRAs (MoLoRA)</h3>
<p>Multiple LoRA experts for different aspects:</p>
<div id="molora" class="cell" data-execution_count="12">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MoLoRALayer(nn.Module):</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_features, out_features, num_experts<span class="op">=</span><span class="dv">4</span>, rank<span class="op">=</span><span class="dv">16</span>):</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_experts <span class="op">=</span> num_experts</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Multiple LoRA experts</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.experts <span class="op">=</span> nn.ModuleList([</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>            LoRALayer(in_features, out_features, rank)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(num_experts)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Gating network</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.gate <span class="op">=</span> nn.Linear(in_features, num_experts)</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute gating weights</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>        gate_input <span class="op">=</span> x.mean(dim<span class="op">=</span><span class="dv">1</span>) <span class="cf">if</span> x.dim() <span class="op">&gt;</span> <span class="dv">2</span> <span class="cf">else</span> x</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>        gate_weights <span class="op">=</span> F.softmax(<span class="va">self</span>.gate(gate_input), dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Combine expert outputs</span></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>        expert_outputs <span class="op">=</span> torch.stack([expert(x) <span class="cf">for</span> expert <span class="kw">in</span> <span class="va">self</span>.experts], dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Weighted combination</span></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> gate_weights.dim() <span class="op">==</span> <span class="dv">2</span>:  <span class="co"># Batch of inputs</span></span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>            gate_weights <span class="op">=</span> gate_weights.T.unsqueeze(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> torch.<span class="bu">sum</span>(gate_weights <span class="op">*</span> expert_outputs, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:  <span class="co"># Single input</span></span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> torch.<span class="bu">sum</span>(gate_weights[:, <span class="va">None</span>] <span class="op">*</span> expert_outputs, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output</span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Demonstration of MoLoRA</span></span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>molora_layer <span class="op">=</span> MoLoRALayer(<span class="dv">768</span>, <span class="dv">768</span>, num_experts<span class="op">=</span><span class="dv">4</span>, rank<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn(<span class="dv">32</span>, <span class="dv">768</span>)</span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>output <span class="op">=</span> molora_layer(x)</span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Mixture of LoRAs (MoLoRA) Demo:"</span>)</span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Input shape: </span><span class="sc">{</span>x<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Output shape: </span><span class="sc">{</span>output<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of experts: </span><span class="sc">{</span>molora_layer<span class="sc">.</span>num_experts<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Show expert utilization</span></span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a>    gate_weights <span class="op">=</span> F.softmax(molora_layer.gate(x), dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a>    expert_utilization <span class="op">=</span> gate_weights.mean(dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb14-46"><a href="#cb14-46" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-47"><a href="#cb14-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Expert utilization:"</span>)</span>
<span id="cb14-48"><a href="#cb14-48" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, util <span class="kw">in</span> <span class="bu">enumerate</span>(expert_utilization):</span>
<span id="cb14-49"><a href="#cb14-49" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Expert </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>util<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Mixture of LoRAs (MoLoRA) Demo:
Input shape: torch.Size([32, 768])
Output shape: torch.Size([32, 768])
Number of experts: 4
Expert utilization:
  Expert 1: 0.255
  Expert 2: 0.246
  Expert 3: 0.254
  Expert 4: 0.246</code></pre>
</div>
</div>
</section>
</section>
<section id="performance-optimization" class="level2">
<h2 class="anchored" data-anchor-id="performance-optimization">Performance Optimization</h2>
<section id="memory-optimization" class="level3">
<h3 class="anchored" data-anchor-id="memory-optimization">Memory Optimization</h3>
<div id="memory-optimization" class="cell" data-execution_count="13">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MemoryEfficientLoRA:</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> gradient_checkpointing_forward(module, <span class="op">*</span>args):</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Custom gradient checkpointing for LoRA layers"""</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> create_custom_forward(module):</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>            <span class="kw">def</span> custom_forward(<span class="op">*</span>inputs):</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span> module(<span class="op">*</span>inputs)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> custom_forward</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.utils.checkpoint.checkpoint(</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>            create_custom_forward(module), <span class="op">*</span>args</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> merge_lora_weights(model):</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Merge LoRA weights into base model for inference"""</span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>        merged_count <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> name, module <span class="kw">in</span> model.named_modules():</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(module, LoRALinear):</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Compute merged weight</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>                lora_weight <span class="op">=</span> module.lora.lora_B.weight <span class="op">@</span> module.lora.lora_A.weight</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>                merged_weight <span class="op">=</span> module.original_layer.weight <span class="op">+</span> lora_weight <span class="op">*</span> module.lora.scaling</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Create merged layer</span></span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>                merged_layer <span class="op">=</span> nn.Linear(</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>                    module.original_layer.in_features,</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>                    module.original_layer.out_features,</span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>                    bias<span class="op">=</span>module.original_layer.bias <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>                merged_layer.weight.data <span class="op">=</span> merged_weight</span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> module.original_layer.bias <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>                    merged_layer.bias.data <span class="op">=</span> module.original_layer.bias</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>                merged_count <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> merged_count</span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> compute_memory_savings(model):</span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Compute memory savings from LoRA"""</span></span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a>        total_params <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a>        lora_params <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> name, param <span class="kw">in</span> model.named_parameters():</span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a>            total_params <span class="op">+=</span> param.numel()</span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="st">'lora'</span> <span class="kw">in</span> name:</span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a>                lora_params <span class="op">+=</span> param.numel()</span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a>        savings_ratio <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> (lora_params <span class="op">/</span> total_params)</span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-52"><a href="#cb16-52" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {</span>
<span id="cb16-53"><a href="#cb16-53" aria-hidden="true" tabindex="-1"></a>            <span class="st">'total_parameters'</span>: total_params,</span>
<span id="cb16-54"><a href="#cb16-54" aria-hidden="true" tabindex="-1"></a>            <span class="st">'lora_parameters'</span>: lora_params,</span>
<span id="cb16-55"><a href="#cb16-55" aria-hidden="true" tabindex="-1"></a>            <span class="st">'base_parameters'</span>: total_params <span class="op">-</span> lora_params,</span>
<span id="cb16-56"><a href="#cb16-56" aria-hidden="true" tabindex="-1"></a>            <span class="st">'memory_savings'</span>: savings_ratio,</span>
<span id="cb16-57"><a href="#cb16-57" aria-hidden="true" tabindex="-1"></a>            <span class="st">'compression_ratio'</span>: total_params <span class="op">/</span> lora_params <span class="cf">if</span> lora_params <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb16-58"><a href="#cb16-58" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb16-59"><a href="#cb16-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-60"><a href="#cb16-60" aria-hidden="true" tabindex="-1"></a><span class="co"># Demonstrate memory optimization</span></span>
<span id="cb16-61"><a href="#cb16-61" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> MemoryEfficientLoRA()</span>
<span id="cb16-62"><a href="#cb16-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-63"><a href="#cb16-63" aria-hidden="true" tabindex="-1"></a><span class="co"># Example memory analysis (would use real model)</span></span>
<span id="cb16-64"><a href="#cb16-64" aria-hidden="true" tabindex="-1"></a>example_stats <span class="op">=</span> {</span>
<span id="cb16-65"><a href="#cb16-65" aria-hidden="true" tabindex="-1"></a>    <span class="st">'total_parameters'</span>: <span class="dv">175_000_000</span>,</span>
<span id="cb16-66"><a href="#cb16-66" aria-hidden="true" tabindex="-1"></a>    <span class="st">'lora_parameters'</span>: <span class="dv">1_750_000</span>,</span>
<span id="cb16-67"><a href="#cb16-67" aria-hidden="true" tabindex="-1"></a>    <span class="st">'base_parameters'</span>: <span class="dv">173_250_000</span>,</span>
<span id="cb16-68"><a href="#cb16-68" aria-hidden="true" tabindex="-1"></a>    <span class="st">'memory_savings'</span>: <span class="fl">0.99</span>,</span>
<span id="cb16-69"><a href="#cb16-69" aria-hidden="true" tabindex="-1"></a>    <span class="st">'compression_ratio'</span>: <span class="dv">100</span></span>
<span id="cb16-70"><a href="#cb16-70" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb16-71"><a href="#cb16-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-72"><a href="#cb16-72" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Memory Optimization Analysis:"</span>)</span>
<span id="cb16-73"><a href="#cb16-73" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Total parameters: </span><span class="sc">{</span>example_stats[<span class="st">'total_parameters'</span>]<span class="sc">:,}</span><span class="ss">"</span>)</span>
<span id="cb16-74"><a href="#cb16-74" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"LoRA parameters: </span><span class="sc">{</span>example_stats[<span class="st">'lora_parameters'</span>]<span class="sc">:,}</span><span class="ss">"</span>)</span>
<span id="cb16-75"><a href="#cb16-75" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Memory savings: </span><span class="sc">{</span>example_stats[<span class="st">'memory_savings'</span>]<span class="sc">:.1%}</span><span class="ss">"</span>)</span>
<span id="cb16-76"><a href="#cb16-76" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Compression ratio: </span><span class="sc">{</span>example_stats[<span class="st">'compression_ratio'</span>]<span class="sc">:.1f}</span><span class="ss">x"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Memory Optimization Analysis:
Total parameters: 175,000,000
LoRA parameters: 1,750,000
Memory savings: 99.0%
Compression ratio: 100.0x</code></pre>
</div>
</div>
</section>
<section id="training-optimizations" class="level3">
<h3 class="anchored" data-anchor-id="training-optimizations">Training Optimizations</h3>
<div id="training-optimization" class="cell" data-execution_count="14">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> OptimizedLoRATrainer:</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, model, config):</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> model</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.config <span class="op">=</span> config</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Separate parameter groups</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.setup_parameter_groups()</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Mixed precision training</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> torch.cuda.is_available():</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.scaler <span class="op">=</span> torch.cuda.amp.GradScaler()</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.scaler <span class="op">=</span> <span class="va">None</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> setup_parameter_groups(<span class="va">self</span>):</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Separate LoRA and non-LoRA parameters"""</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>        lora_params <span class="op">=</span> []</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>        other_params <span class="op">=</span> []</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> name, param <span class="kw">in</span> <span class="va">self</span>.model.named_parameters():</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> param.requires_grad:</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> <span class="st">'lora'</span> <span class="kw">in</span> name:</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>                    lora_params.append(param)</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>                    other_params.append(param)</span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.param_groups <span class="op">=</span> [</span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>            {</span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>                <span class="st">'params'</span>: lora_params, </span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a>                <span class="st">'lr'</span>: <span class="bu">getattr</span>(<span class="va">self</span>.config, <span class="st">'lora_lr'</span>, <span class="fl">1e-4</span>), </span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>                <span class="st">'weight_decay'</span>: <span class="fl">0.01</span>,</span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>                <span class="st">'name'</span>: <span class="st">'lora_params'</span></span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>            {</span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>                <span class="st">'params'</span>: other_params, </span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>                <span class="st">'lr'</span>: <span class="bu">getattr</span>(<span class="va">self</span>.config, <span class="st">'base_lr'</span>, <span class="fl">1e-5</span>), </span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a>                <span class="st">'weight_decay'</span>: <span class="fl">0.1</span>,</span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a>                <span class="st">'name'</span>: <span class="st">'base_params'</span></span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a>        ]</span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Parameter Groups Setup:"</span>)</span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> group <span class="kw">in</span> <span class="va">self</span>.param_groups:</span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a>            param_count <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> group[<span class="st">'params'</span>])</span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>group[<span class="st">'name'</span>]<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>param_count<span class="sc">:,}</span><span class="ss"> parameters, lr=</span><span class="sc">{</span>group[<span class="st">'lr'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> training_step(<span class="va">self</span>, batch, optimizer):</span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Optimized training step with mixed precision"""</span></span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.scaler <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Mixed precision training</span></span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> torch.cuda.amp.autocast():</span>
<span id="cb18-52"><a href="#cb18-52" aria-hidden="true" tabindex="-1"></a>                outputs <span class="op">=</span> <span class="va">self</span>.model(<span class="op">**</span>batch)</span>
<span id="cb18-53"><a href="#cb18-53" aria-hidden="true" tabindex="-1"></a>                loss <span class="op">=</span> outputs.loss <span class="cf">if</span> <span class="bu">hasattr</span>(outputs, <span class="st">'loss'</span>) <span class="cf">else</span> outputs</span>
<span id="cb18-54"><a href="#cb18-54" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb18-55"><a href="#cb18-55" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Scaled backward pass</span></span>
<span id="cb18-56"><a href="#cb18-56" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.scaler.scale(loss).backward()</span>
<span id="cb18-57"><a href="#cb18-57" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb18-58"><a href="#cb18-58" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Gradient clipping for LoRA parameters only</span></span>
<span id="cb18-59"><a href="#cb18-59" aria-hidden="true" tabindex="-1"></a>            lora_params <span class="op">=</span> [p <span class="cf">for</span> group <span class="kw">in</span> <span class="va">self</span>.param_groups </span>
<span id="cb18-60"><a href="#cb18-60" aria-hidden="true" tabindex="-1"></a>                          <span class="cf">for</span> p <span class="kw">in</span> group[<span class="st">'params'</span>] <span class="cf">if</span> group[<span class="st">'name'</span>] <span class="op">==</span> <span class="st">'lora_params'</span>]</span>
<span id="cb18-61"><a href="#cb18-61" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb18-62"><a href="#cb18-62" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.scaler.unscale_(optimizer)</span>
<span id="cb18-63"><a href="#cb18-63" aria-hidden="true" tabindex="-1"></a>            torch.nn.utils.clip_grad_norm_(lora_params, max_norm<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb18-64"><a href="#cb18-64" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb18-65"><a href="#cb18-65" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.scaler.step(optimizer)</span>
<span id="cb18-66"><a href="#cb18-66" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.scaler.update()</span>
<span id="cb18-67"><a href="#cb18-67" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb18-68"><a href="#cb18-68" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Regular training</span></span>
<span id="cb18-69"><a href="#cb18-69" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> <span class="va">self</span>.model(<span class="op">**</span>batch)</span>
<span id="cb18-70"><a href="#cb18-70" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> outputs.loss <span class="cf">if</span> <span class="bu">hasattr</span>(outputs, <span class="st">'loss'</span>) <span class="cf">else</span> outputs</span>
<span id="cb18-71"><a href="#cb18-71" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb18-72"><a href="#cb18-72" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb18-73"><a href="#cb18-73" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb18-74"><a href="#cb18-74" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Gradient clipping</span></span>
<span id="cb18-75"><a href="#cb18-75" aria-hidden="true" tabindex="-1"></a>            lora_params <span class="op">=</span> [p <span class="cf">for</span> group <span class="kw">in</span> <span class="va">self</span>.param_groups </span>
<span id="cb18-76"><a href="#cb18-76" aria-hidden="true" tabindex="-1"></a>                          <span class="cf">for</span> p <span class="kw">in</span> group[<span class="st">'params'</span>] <span class="cf">if</span> group[<span class="st">'name'</span>] <span class="op">==</span> <span class="st">'lora_params'</span>]</span>
<span id="cb18-77"><a href="#cb18-77" aria-hidden="true" tabindex="-1"></a>            torch.nn.utils.clip_grad_norm_(lora_params, max_norm<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb18-78"><a href="#cb18-78" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb18-79"><a href="#cb18-79" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb18-80"><a href="#cb18-80" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-81"><a href="#cb18-81" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb18-82"><a href="#cb18-82" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> loss.item() <span class="cf">if</span> <span class="bu">hasattr</span>(loss, <span class="st">'item'</span>) <span class="cf">else</span> loss</span>
<span id="cb18-83"><a href="#cb18-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-84"><a href="#cb18-84" aria-hidden="true" tabindex="-1"></a><span class="co"># Example configuration</span></span>
<span id="cb18-85"><a href="#cb18-85" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TrainingConfig:</span>
<span id="cb18-86"><a href="#cb18-86" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb18-87"><a href="#cb18-87" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lora_lr <span class="op">=</span> <span class="fl">1e-4</span></span>
<span id="cb18-88"><a href="#cb18-88" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.base_lr <span class="op">=</span> <span class="fl">1e-5</span></span>
<span id="cb18-89"><a href="#cb18-89" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mixed_precision <span class="op">=</span> <span class="va">True</span></span>
<span id="cb18-90"><a href="#cb18-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-91"><a href="#cb18-91" aria-hidden="true" tabindex="-1"></a>config <span class="op">=</span> TrainingConfig()</span>
<span id="cb18-92"><a href="#cb18-92" aria-hidden="true" tabindex="-1"></a><span class="co"># trainer = OptimizedLoRATrainer(model, config)  # Would use real model</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
<section id="use-cases-and-applications" class="level2">
<h2 class="anchored" data-anchor-id="use-cases-and-applications">Use Cases and Applications</h2>
<section id="domain-adaptation" class="level3">
<h3 class="anchored" data-anchor-id="domain-adaptation">1. Domain Adaptation</h3>
<div id="domain-adaptation" class="cell" data-execution_count="15">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Domain-specific LoRA configurations</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>domain_configs <span class="op">=</span> {</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"medical_imaging"</span>: {</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">"config"</span>: LoRAConfig(</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>            rank<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>            alpha<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>            target_modules<span class="op">=</span>[<span class="st">"q_proj"</span>, <span class="st">"v_proj"</span>, <span class="st">"fc1"</span>, <span class="st">"fc2"</span>],</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>            task_type<span class="op">=</span><span class="st">"medical_vqa"</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>        ),</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">"description"</span>: <span class="st">"Optimized for medical image analysis"</span>,</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">"key_features"</span>: [</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Higher rank for complex medical patterns"</span>,</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Focus on attention and MLP layers"</span>,</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Enhanced feature extraction capabilities"</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>        ]</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">"satellite_imagery"</span>: {</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>        <span class="st">"config"</span>: LoRAConfig(</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>            rank<span class="op">=</span><span class="dv">16</span>,</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>            alpha<span class="op">=</span><span class="dv">16</span>,</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>            target_modules<span class="op">=</span>[<span class="st">"qkv"</span>, <span class="st">"proj"</span>],</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>            task_type<span class="op">=</span><span class="st">"remote_sensing"</span></span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>        ),</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>        <span class="st">"description"</span>: <span class="st">"Adapted for satellite and aerial imagery"</span>,</span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>        <span class="st">"key_features"</span>: [</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Balanced rank for efficiency"</span>,</span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Vision-focused adaptations"</span>,</span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Spatial relationship modeling"</span></span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a>        ]</span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>    <span class="st">"autonomous_driving"</span>: {</span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>        <span class="st">"config"</span>: LoRAConfig(</span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a>            rank<span class="op">=</span><span class="dv">24</span>,</span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a>            alpha<span class="op">=</span><span class="dv">24</span>,</span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a>            target_modules<span class="op">=</span>[<span class="st">"q_proj"</span>, <span class="st">"k_proj"</span>, <span class="st">"v_proj"</span>, <span class="st">"dense"</span>],</span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a>            task_type<span class="op">=</span><span class="st">"scene_understanding"</span></span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a>        ),</span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a>        <span class="st">"description"</span>: <span class="st">"Designed for autonomous vehicle perception"</span>,</span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a>        <span class="st">"key_features"</span>: [</span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Real-time inference requirements"</span>,</span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Multi-object detection focus"</span>,</span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Safety-critical applications"</span></span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a>        ]</span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb19-47"><a href="#cb19-47" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb19-48"><a href="#cb19-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-49"><a href="#cb19-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Domain Adaptation Configurations:"</span>)</span>
<span id="cb19-50"><a href="#cb19-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">50</span>)</span>
<span id="cb19-51"><a href="#cb19-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-52"><a href="#cb19-52" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> domain, info <span class="kw">in</span> domain_configs.items():</span>
<span id="cb19-53"><a href="#cb19-53" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span>domain<span class="sc">.</span>replace(<span class="st">'_'</span>, <span class="st">' '</span>)<span class="sc">.</span>title()<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb19-54"><a href="#cb19-54" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Description: </span><span class="sc">{</span>info[<span class="st">'description'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-55"><a href="#cb19-55" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Rank: </span><span class="sc">{</span>info[<span class="st">'config'</span>]<span class="sc">.</span>rank<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-56"><a href="#cb19-56" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Alpha: </span><span class="sc">{</span>info[<span class="st">'config'</span>]<span class="sc">.</span>alpha<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-57"><a href="#cb19-57" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Target modules: </span><span class="sc">{</span><span class="st">', '</span><span class="sc">.</span>join(info[<span class="st">'config'</span>].target_modules)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-58"><a href="#cb19-58" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"  Key features:"</span>)</span>
<span id="cb19-59"><a href="#cb19-59" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> feature <span class="kw">in</span> info[<span class="st">'key_features'</span>]:</span>
<span id="cb19-60"><a href="#cb19-60" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"    • </span><span class="sc">{</span>feature<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Domain Adaptation Configurations:
==================================================

Medical Imaging:
  Description: Optimized for medical image analysis
  Rank: 32
  Alpha: 32
  Target modules: q_proj, v_proj, fc1, fc2
  Key features:
    • Higher rank for complex medical patterns
    • Focus on attention and MLP layers
    • Enhanced feature extraction capabilities

Satellite Imagery:
  Description: Adapted for satellite and aerial imagery
  Rank: 16
  Alpha: 16
  Target modules: qkv, proj
  Key features:
    • Balanced rank for efficiency
    • Vision-focused adaptations
    • Spatial relationship modeling

Autonomous Driving:
  Description: Designed for autonomous vehicle perception
  Rank: 24
  Alpha: 24
  Target modules: q_proj, k_proj, v_proj, dense
  Key features:
    • Real-time inference requirements
    • Multi-object detection focus
    • Safety-critical applications</code></pre>
</div>
</div>
</section>
<section id="multi-lingual-vision-language" class="level3">
<h3 class="anchored" data-anchor-id="multi-lingual-vision-language">2. Multi-lingual Vision-Language</h3>
<div id="multilingual-lora" class="cell" data-execution_count="16">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MultilingualLoRA:</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, base_model, languages):</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.base_model <span class="op">=</span> base_model</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.languages <span class="op">=</span> languages</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.language_adapters <span class="op">=</span> {}</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> lang <span class="kw">in</span> languages:</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.language_adapters[lang] <span class="op">=</span> <span class="va">self</span>.create_language_adapter(lang)</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> create_language_adapter(<span class="va">self</span>, language):</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Create language-specific LoRA adapter"""</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Language-specific configurations</span></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>        lang_configs <span class="op">=</span> {</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>            <span class="st">"english"</span>: {<span class="st">"rank"</span>: <span class="dv">16</span>, <span class="st">"alpha"</span>: <span class="dv">16</span>},</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>            <span class="st">"chinese"</span>: {<span class="st">"rank"</span>: <span class="dv">20</span>, <span class="st">"alpha"</span>: <span class="dv">20</span>},  <span class="co"># More complex script</span></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>            <span class="st">"arabic"</span>: {<span class="st">"rank"</span>: <span class="dv">18</span>, <span class="st">"alpha"</span>: <span class="dv">18</span>},   <span class="co"># RTL language</span></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>            <span class="st">"hindi"</span>: {<span class="st">"rank"</span>: <span class="dv">22</span>, <span class="st">"alpha"</span>: <span class="dv">22</span>},    <span class="co"># Complex script</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>            <span class="st">"spanish"</span>: {<span class="st">"rank"</span>: <span class="dv">14</span>, <span class="st">"alpha"</span>: <span class="dv">14</span>},  <span class="co"># Similar to English</span></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>        config <span class="op">=</span> lang_configs.get(language, {<span class="st">"rank"</span>: <span class="dv">16</span>, <span class="st">"alpha"</span>: <span class="dv">16</span>})</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> LoRAConfig(</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>            rank<span class="op">=</span>config[<span class="st">"rank"</span>],</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>            alpha<span class="op">=</span>config[<span class="st">"alpha"</span>],</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>            target_modules<span class="op">=</span>[<span class="st">"q_proj"</span>, <span class="st">"k_proj"</span>, <span class="st">"v_proj"</span>],</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>            task_type<span class="op">=</span><span class="ss">f"vlm_</span><span class="sc">{</span>language<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_adapter_stats(<span class="va">self</span>):</span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Get statistics about language adapters"""</span></span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>        stats <span class="op">=</span> {}</span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> lang, adapter <span class="kw">in</span> <span class="va">self</span>.language_adapters.items():</span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a>            stats[lang] <span class="op">=</span> {</span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a>                <span class="st">"rank"</span>: adapter.rank,</span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a>                <span class="st">"alpha"</span>: adapter.alpha,</span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a>                <span class="st">"parameters"</span>: adapter.rank <span class="op">*</span> <span class="dv">768</span> <span class="op">*</span> <span class="dv">2</span>,  <span class="co"># Approximate</span></span>
<span id="cb21-39"><a href="#cb21-39" aria-hidden="true" tabindex="-1"></a>                <span class="st">"target_modules"</span>: <span class="bu">len</span>(adapter.target_modules)</span>
<span id="cb21-40"><a href="#cb21-40" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb21-41"><a href="#cb21-41" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-42"><a href="#cb21-42" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> stats</span>
<span id="cb21-43"><a href="#cb21-43" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-44"><a href="#cb21-44" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, images, texts, language):</span>
<span id="cb21-45"><a href="#cb21-45" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Forward pass with language-specific adapter"""</span></span>
<span id="cb21-46"><a href="#cb21-46" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> language <span class="kw">not</span> <span class="kw">in</span> <span class="va">self</span>.language_adapters:</span>
<span id="cb21-47"><a href="#cb21-47" aria-hidden="true" tabindex="-1"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"Language '</span><span class="sc">{</span>language<span class="sc">}</span><span class="ss">' not supported"</span>)</span>
<span id="cb21-48"><a href="#cb21-48" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-49"><a href="#cb21-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Would activate language-specific adapter</span></span>
<span id="cb21-50"><a href="#cb21-50" aria-hidden="true" tabindex="-1"></a>        adapter_config <span class="op">=</span> <span class="va">self</span>.language_adapters[language]</span>
<span id="cb21-51"><a href="#cb21-51" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-52"><a href="#cb21-52" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Return placeholder for demonstration</span></span>
<span id="cb21-53"><a href="#cb21-53" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {</span>
<span id="cb21-54"><a href="#cb21-54" aria-hidden="true" tabindex="-1"></a>            <span class="st">"language"</span>: language,</span>
<span id="cb21-55"><a href="#cb21-55" aria-hidden="true" tabindex="-1"></a>            <span class="st">"adapter_config"</span>: adapter_config,</span>
<span id="cb21-56"><a href="#cb21-56" aria-hidden="true" tabindex="-1"></a>            <span class="st">"message"</span>: <span class="ss">f"Processing with </span><span class="sc">{</span>language<span class="sc">}</span><span class="ss"> adapter"</span></span>
<span id="cb21-57"><a href="#cb21-57" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb21-58"><a href="#cb21-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-59"><a href="#cb21-59" aria-hidden="true" tabindex="-1"></a><span class="co"># Demonstration</span></span>
<span id="cb21-60"><a href="#cb21-60" aria-hidden="true" tabindex="-1"></a>languages <span class="op">=</span> [<span class="st">"english"</span>, <span class="st">"chinese"</span>, <span class="st">"arabic"</span>, <span class="st">"hindi"</span>, <span class="st">"spanish"</span>]</span>
<span id="cb21-61"><a href="#cb21-61" aria-hidden="true" tabindex="-1"></a>multilingual_model <span class="op">=</span> MultilingualLoRA(<span class="va">None</span>, languages)</span>
<span id="cb21-62"><a href="#cb21-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-63"><a href="#cb21-63" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Multilingual LoRA Configuration:"</span>)</span>
<span id="cb21-64"><a href="#cb21-64" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">40</span>)</span>
<span id="cb21-65"><a href="#cb21-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-66"><a href="#cb21-66" aria-hidden="true" tabindex="-1"></a>adapter_stats <span class="op">=</span> multilingual_model.get_adapter_stats()</span>
<span id="cb21-67"><a href="#cb21-67" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> lang, stats <span class="kw">in</span> adapter_stats.items():</span>
<span id="cb21-68"><a href="#cb21-68" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span>lang<span class="sc">.</span>title()<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb21-69"><a href="#cb21-69" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Rank: </span><span class="sc">{</span>stats[<span class="st">'rank'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-70"><a href="#cb21-70" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Alpha: </span><span class="sc">{</span>stats[<span class="st">'alpha'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-71"><a href="#cb21-71" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Parameters: ~</span><span class="sc">{</span>stats[<span class="st">'parameters'</span>]<span class="sc">:,}</span><span class="ss">"</span>)</span>
<span id="cb21-72"><a href="#cb21-72" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Target modules: </span><span class="sc">{</span>stats[<span class="st">'target_modules'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-73"><a href="#cb21-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-74"><a href="#cb21-74" aria-hidden="true" tabindex="-1"></a><span class="co"># Example usage</span></span>
<span id="cb21-75"><a href="#cb21-75" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> multilingual_model.forward(<span class="va">None</span>, <span class="va">None</span>, <span class="st">"chinese"</span>)</span>
<span id="cb21-76"><a href="#cb21-76" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Example usage: </span><span class="sc">{</span>result[<span class="st">'message'</span>]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Multilingual LoRA Configuration:
========================================

English:
  Rank: 16
  Alpha: 16
  Parameters: ~24,576
  Target modules: 3

Chinese:
  Rank: 20
  Alpha: 20
  Parameters: ~30,720
  Target modules: 3

Arabic:
  Rank: 18
  Alpha: 18
  Parameters: ~27,648
  Target modules: 3

Hindi:
  Rank: 22
  Alpha: 22
  Parameters: ~33,792
  Target modules: 3

Spanish:
  Rank: 14
  Alpha: 14
  Parameters: ~21,504
  Target modules: 3

Example usage: Processing with chinese adapter</code></pre>
</div>
</div>
</section>
<section id="few-shot-learning" class="level3">
<h3 class="anchored" data-anchor-id="few-shot-learning">3. Few-Shot Learning</h3>
<div id="few-shot-learning" class="cell" data-execution_count="17">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> FewShotLoRALearner:</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, base_model, config):</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.base_model <span class="op">=</span> base_model</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.config <span class="op">=</span> config</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.task_adapters <span class="op">=</span> {}</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> create_task_adapter(<span class="va">self</span>, task_name, rank<span class="op">=</span><span class="dv">8</span>, alpha<span class="op">=</span><span class="dv">16</span>):</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Create a lightweight adapter for few-shot learning"""</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> LoRAConfig(</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>            rank<span class="op">=</span>rank,</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>            alpha<span class="op">=</span>alpha,</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>            target_modules<span class="op">=</span>[<span class="st">"q_proj"</span>, <span class="st">"v_proj"</span>],  <span class="co"># Minimal modules for efficiency</span></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>            task_type<span class="op">=</span><span class="ss">f"few_shot_</span><span class="sc">{</span>task_name<span class="sc">}</span><span class="ss">"</span>,</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>            learning_rate<span class="op">=</span><span class="fl">1e-3</span>,  <span class="co"># Higher LR for fast adaptation</span></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>            dropout<span class="op">=</span><span class="fl">0.0</span>  <span class="co"># No dropout for few-shot</span></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> adapt_to_task(<span class="va">self</span>, task_name, support_examples, num_steps<span class="op">=</span><span class="dv">100</span>):</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Quick adaptation using few examples"""</span></span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Adapting to task: </span><span class="sc">{</span>task_name<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Support examples: </span><span class="sc">{</span><span class="bu">len</span>(support_examples)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Adaptation steps: </span><span class="sc">{</span>num_steps<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create task-specific adapter</span></span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>        adapter_config <span class="op">=</span> <span class="va">self</span>.create_task_adapter(task_name)</span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.task_adapters[task_name] <span class="op">=</span> adapter_config</span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Simulate adaptation process</span></span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a>        adaptation_progress <span class="op">=</span> []</span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> step <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, num_steps <span class="op">+</span> <span class="dv">1</span>, <span class="dv">20</span>):</span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Simulate decreasing loss</span></span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> <span class="fl">2.0</span> <span class="op">*</span> np.exp(<span class="op">-</span>step <span class="op">/</span> <span class="dv">50</span>) <span class="op">+</span> <span class="fl">0.1</span></span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a>            accuracy <span class="op">=</span> <span class="bu">min</span>(<span class="fl">0.95</span>, <span class="fl">0.3</span> <span class="op">+</span> <span class="fl">0.65</span> <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> np.exp(<span class="op">-</span>step <span class="op">/</span> <span class="dv">30</span>)))</span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a>            adaptation_progress.append({</span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a>                <span class="st">'step'</span>: step,</span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a>                <span class="st">'loss'</span>: loss,</span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a>                <span class="st">'accuracy'</span>: accuracy</span>
<span id="cb23-39"><a href="#cb23-39" aria-hidden="true" tabindex="-1"></a>            })</span>
<span id="cb23-40"><a href="#cb23-40" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-41"><a href="#cb23-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> adaptation_progress</span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-43"><a href="#cb23-43" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> evaluate_adaptation(<span class="va">self</span>, task_name, test_examples):</span>
<span id="cb23-44"><a href="#cb23-44" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Evaluate adapted model on test examples"""</span></span>
<span id="cb23-45"><a href="#cb23-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> task_name <span class="kw">not</span> <span class="kw">in</span> <span class="va">self</span>.task_adapters:</span>
<span id="cb23-46"><a href="#cb23-46" aria-hidden="true" tabindex="-1"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"No adapter found for task: </span><span class="sc">{</span>task_name<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-47"><a href="#cb23-47" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-48"><a href="#cb23-48" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Simulate evaluation results</span></span>
<span id="cb23-49"><a href="#cb23-49" aria-hidden="true" tabindex="-1"></a>        performance <span class="op">=</span> {</span>
<span id="cb23-50"><a href="#cb23-50" aria-hidden="true" tabindex="-1"></a>            <span class="st">'accuracy'</span>: <span class="fl">0.87</span>,</span>
<span id="cb23-51"><a href="#cb23-51" aria-hidden="true" tabindex="-1"></a>            <span class="st">'precision'</span>: <span class="fl">0.89</span>,</span>
<span id="cb23-52"><a href="#cb23-52" aria-hidden="true" tabindex="-1"></a>            <span class="st">'recall'</span>: <span class="fl">0.85</span>,</span>
<span id="cb23-53"><a href="#cb23-53" aria-hidden="true" tabindex="-1"></a>            <span class="st">'f1_score'</span>: <span class="fl">0.87</span>,</span>
<span id="cb23-54"><a href="#cb23-54" aria-hidden="true" tabindex="-1"></a>            <span class="st">'test_examples'</span>: <span class="bu">len</span>(test_examples)</span>
<span id="cb23-55"><a href="#cb23-55" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb23-56"><a href="#cb23-56" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-57"><a href="#cb23-57" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> performance</span>
<span id="cb23-58"><a href="#cb23-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-59"><a href="#cb23-59" aria-hidden="true" tabindex="-1"></a><span class="co"># Demonstration of few-shot learning</span></span>
<span id="cb23-60"><a href="#cb23-60" aria-hidden="true" tabindex="-1"></a>few_shot_learner <span class="op">=</span> FewShotLoRALearner(<span class="va">None</span>, <span class="va">None</span>)</span>
<span id="cb23-61"><a href="#cb23-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-62"><a href="#cb23-62" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate different tasks</span></span>
<span id="cb23-63"><a href="#cb23-63" aria-hidden="true" tabindex="-1"></a>tasks <span class="op">=</span> {</span>
<span id="cb23-64"><a href="#cb23-64" aria-hidden="true" tabindex="-1"></a>    <span class="st">"bird_classification"</span>: <span class="dv">16</span>,  <span class="co"># 16 support examples</span></span>
<span id="cb23-65"><a href="#cb23-65" aria-hidden="true" tabindex="-1"></a>    <span class="st">"medical_diagnosis"</span>: <span class="dv">8</span>,     <span class="co"># 8 support examples  </span></span>
<span id="cb23-66"><a href="#cb23-66" aria-hidden="true" tabindex="-1"></a>    <span class="st">"product_recognition"</span>: <span class="dv">32</span>   <span class="co"># 32 support examples</span></span>
<span id="cb23-67"><a href="#cb23-67" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb23-68"><a href="#cb23-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-69"><a href="#cb23-69" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Few-Shot Learning with LoRA:"</span>)</span>
<span id="cb23-70"><a href="#cb23-70" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">35</span>)</span>
<span id="cb23-71"><a href="#cb23-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-72"><a href="#cb23-72" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> task_name, num_examples <span class="kw">in</span> tasks.items():</span>
<span id="cb23-73"><a href="#cb23-73" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Task: </span><span class="sc">{</span>task_name<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-74"><a href="#cb23-74" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-75"><a href="#cb23-75" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Adapt to task</span></span>
<span id="cb23-76"><a href="#cb23-76" aria-hidden="true" tabindex="-1"></a>    support_examples <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(num_examples))  <span class="co"># Mock examples</span></span>
<span id="cb23-77"><a href="#cb23-77" aria-hidden="true" tabindex="-1"></a>    progress <span class="op">=</span> few_shot_learner.adapt_to_task(task_name, support_examples)</span>
<span id="cb23-78"><a href="#cb23-78" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-79"><a href="#cb23-79" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Show adaptation progress</span></span>
<span id="cb23-80"><a href="#cb23-80" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Adaptation progress:"</span>)</span>
<span id="cb23-81"><a href="#cb23-81" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> point <span class="kw">in</span> progress[<span class="op">-</span><span class="dv">3</span>:]:  <span class="co"># Show last 3 points</span></span>
<span id="cb23-82"><a href="#cb23-82" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Step </span><span class="sc">{</span>point[<span class="st">'step'</span>]<span class="sc">:3d}</span><span class="ss">: Loss=</span><span class="sc">{</span>point[<span class="st">'loss'</span>]<span class="sc">:.3f}</span><span class="ss">, Acc=</span><span class="sc">{</span>point[<span class="st">'accuracy'</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb23-83"><a href="#cb23-83" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-84"><a href="#cb23-84" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Evaluate</span></span>
<span id="cb23-85"><a href="#cb23-85" aria-hidden="true" tabindex="-1"></a>    test_examples <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">50</span>))  <span class="co"># Mock test set</span></span>
<span id="cb23-86"><a href="#cb23-86" aria-hidden="true" tabindex="-1"></a>    performance <span class="op">=</span> few_shot_learner.evaluate_adaptation(task_name, test_examples)</span>
<span id="cb23-87"><a href="#cb23-87" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Final performance: </span><span class="sc">{</span>performance[<span class="st">'accuracy'</span>]<span class="sc">:.3f}</span><span class="ss"> accuracy"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Few-Shot Learning with LoRA:
===================================

Task: bird_classification
Adapting to task: bird_classification
Support examples: 16
Adaptation steps: 100
Adaptation progress:
  Step  60: Loss=0.702, Acc=0.862
  Step  80: Loss=0.504, Acc=0.905
  Step 100: Loss=0.371, Acc=0.927
Final performance: 0.870 accuracy

Task: medical_diagnosis
Adapting to task: medical_diagnosis
Support examples: 8
Adaptation steps: 100
Adaptation progress:
  Step  60: Loss=0.702, Acc=0.862
  Step  80: Loss=0.504, Acc=0.905
  Step 100: Loss=0.371, Acc=0.927
Final performance: 0.870 accuracy

Task: product_recognition
Adapting to task: product_recognition
Support examples: 32
Adaptation steps: 100
Adaptation progress:
  Step  60: Loss=0.702, Acc=0.862
  Step  80: Loss=0.504, Acc=0.905
  Step 100: Loss=0.371, Acc=0.927
Final performance: 0.870 accuracy</code></pre>
</div>
</div>
</section>
</section>
<section id="best-practices" class="level2">
<h2 class="anchored" data-anchor-id="best-practices">Best Practices</h2>
<section id="hyperparameter-selection" class="level3">
<h3 class="anchored" data-anchor-id="hyperparameter-selection">1. Hyperparameter Selection</h3>
<div id="hyperparameter-guidelines" class="cell" data-execution_count="18">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LoRAHyperparameterGuide:</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.guidelines <span class="op">=</span> {</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>            <span class="st">"rank_selection"</span>: {</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>                <span class="st">"simple_adaptation"</span>: {<span class="st">"min"</span>: <span class="dv">1</span>, <span class="st">"max"</span>: <span class="dv">8</span>, <span class="st">"recommended"</span>: <span class="dv">4</span>},</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>                <span class="st">"balanced_performance"</span>: {<span class="st">"min"</span>: <span class="dv">8</span>, <span class="st">"max"</span>: <span class="dv">32</span>, <span class="st">"recommended"</span>: <span class="dv">16</span>},</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>                <span class="st">"complex_domains"</span>: {<span class="st">"min"</span>: <span class="dv">32</span>, <span class="st">"max"</span>: <span class="dv">128</span>, <span class="st">"recommended"</span>: <span class="dv">64</span>},</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>                <span class="st">"high_capacity"</span>: {<span class="st">"min"</span>: <span class="dv">128</span>, <span class="st">"max"</span>: <span class="dv">256</span>, <span class="st">"recommended"</span>: <span class="dv">128</span>}</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>            <span class="st">"alpha_selection"</span>: {</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>                <span class="st">"conservative"</span>: <span class="st">"alpha = rank"</span>,</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>                <span class="st">"aggressive"</span>: <span class="st">"alpha = 2 * rank"</span>, </span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>                <span class="st">"very_aggressive"</span>: <span class="st">"alpha = 4 * rank"</span>,</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>                <span class="st">"typical_range"</span>: (<span class="dv">8</span>, <span class="dv">64</span>)</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>            <span class="st">"learning_rates"</span>: {</span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a>                <span class="st">"lora_parameters"</span>: {<span class="st">"min"</span>: <span class="fl">1e-5</span>, <span class="st">"max"</span>: <span class="fl">1e-3</span>, <span class="st">"recommended"</span>: <span class="fl">1e-4</span>},</span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>                <span class="st">"base_parameters"</span>: {<span class="st">"min"</span>: <span class="fl">1e-6</span>, <span class="st">"max"</span>: <span class="fl">1e-4</span>, <span class="st">"recommended"</span>: <span class="fl">1e-5</span>},</span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>                <span class="st">"warmup_ratio"</span>: <span class="fl">0.1</span></span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_recommendations(<span class="va">self</span>, task_complexity<span class="op">=</span><span class="st">"balanced"</span>, domain_shift<span class="op">=</span><span class="st">"moderate"</span>):</span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Get hyperparameter recommendations based on task characteristics"""</span></span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Rank recommendations</span></span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> task_complexity <span class="op">==</span> <span class="st">"simple"</span>:</span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a>            rank_category <span class="op">=</span> <span class="st">"simple_adaptation"</span></span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> task_complexity <span class="op">==</span> <span class="st">"complex"</span>:</span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a>            rank_category <span class="op">=</span> <span class="st">"complex_domains"</span>  </span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a>            rank_category <span class="op">=</span> <span class="st">"balanced_performance"</span></span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb25-34"><a href="#cb25-34" aria-hidden="true" tabindex="-1"></a>        rank_info <span class="op">=</span> <span class="va">self</span>.guidelines[<span class="st">"rank_selection"</span>][rank_category]</span>
<span id="cb25-35"><a href="#cb25-35" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb25-36"><a href="#cb25-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Alpha based on domain shift</span></span>
<span id="cb25-37"><a href="#cb25-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> domain_shift <span class="op">==</span> <span class="st">"small"</span>:</span>
<span id="cb25-38"><a href="#cb25-38" aria-hidden="true" tabindex="-1"></a>            alpha_multiplier <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb25-39"><a href="#cb25-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> domain_shift <span class="op">==</span> <span class="st">"large"</span>:</span>
<span id="cb25-40"><a href="#cb25-40" aria-hidden="true" tabindex="-1"></a>            alpha_multiplier <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb25-41"><a href="#cb25-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb25-42"><a href="#cb25-42" aria-hidden="true" tabindex="-1"></a>            alpha_multiplier <span class="op">=</span> <span class="fl">1.5</span></span>
<span id="cb25-43"><a href="#cb25-43" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb25-44"><a href="#cb25-44" aria-hidden="true" tabindex="-1"></a>        recommended_rank <span class="op">=</span> rank_info[<span class="st">"recommended"</span>]</span>
<span id="cb25-45"><a href="#cb25-45" aria-hidden="true" tabindex="-1"></a>        recommended_alpha <span class="op">=</span> <span class="bu">int</span>(recommended_rank <span class="op">*</span> alpha_multiplier)</span>
<span id="cb25-46"><a href="#cb25-46" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb25-47"><a href="#cb25-47" aria-hidden="true" tabindex="-1"></a>        recommendations <span class="op">=</span> {</span>
<span id="cb25-48"><a href="#cb25-48" aria-hidden="true" tabindex="-1"></a>            <span class="st">"rank"</span>: recommended_rank,</span>
<span id="cb25-49"><a href="#cb25-49" aria-hidden="true" tabindex="-1"></a>            <span class="st">"alpha"</span>: recommended_alpha,</span>
<span id="cb25-50"><a href="#cb25-50" aria-hidden="true" tabindex="-1"></a>            <span class="st">"lora_lr"</span>: <span class="va">self</span>.guidelines[<span class="st">"learning_rates"</span>][<span class="st">"lora_parameters"</span>][<span class="st">"recommended"</span>],</span>
<span id="cb25-51"><a href="#cb25-51" aria-hidden="true" tabindex="-1"></a>            <span class="st">"base_lr"</span>: <span class="va">self</span>.guidelines[<span class="st">"learning_rates"</span>][<span class="st">"base_parameters"</span>][<span class="st">"recommended"</span>],</span>
<span id="cb25-52"><a href="#cb25-52" aria-hidden="true" tabindex="-1"></a>            <span class="st">"reasoning"</span>: {</span>
<span id="cb25-53"><a href="#cb25-53" aria-hidden="true" tabindex="-1"></a>                <span class="st">"rank"</span>: <span class="ss">f"Selected </span><span class="sc">{</span>recommended_rank<span class="sc">}</span><span class="ss"> for </span><span class="sc">{</span>task_complexity<span class="sc">}</span><span class="ss"> task complexity"</span>,</span>
<span id="cb25-54"><a href="#cb25-54" aria-hidden="true" tabindex="-1"></a>                <span class="st">"alpha"</span>: <span class="ss">f"Alpha=</span><span class="sc">{</span>recommended_alpha<span class="sc">}</span><span class="ss"> for </span><span class="sc">{</span>domain_shift<span class="sc">}</span><span class="ss"> domain shift"</span>,</span>
<span id="cb25-55"><a href="#cb25-55" aria-hidden="true" tabindex="-1"></a>                <span class="st">"learning_rate"</span>: <span class="st">"Standard rates for stable training"</span></span>
<span id="cb25-56"><a href="#cb25-56" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb25-57"><a href="#cb25-57" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb25-58"><a href="#cb25-58" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb25-59"><a href="#cb25-59" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> recommendations</span>
<span id="cb25-60"><a href="#cb25-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-61"><a href="#cb25-61" aria-hidden="true" tabindex="-1"></a><span class="co"># Hyperparameter recommendation system</span></span>
<span id="cb25-62"><a href="#cb25-62" aria-hidden="true" tabindex="-1"></a>guide <span class="op">=</span> LoRAHyperparameterGuide()</span>
<span id="cb25-63"><a href="#cb25-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-64"><a href="#cb25-64" aria-hidden="true" tabindex="-1"></a><span class="co"># Example scenarios</span></span>
<span id="cb25-65"><a href="#cb25-65" aria-hidden="true" tabindex="-1"></a>scenarios <span class="op">=</span> [</span>
<span id="cb25-66"><a href="#cb25-66" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"task"</span>: <span class="st">"Simple classification"</span>, <span class="st">"complexity"</span>: <span class="st">"simple"</span>, <span class="st">"domain"</span>: <span class="st">"small"</span>},</span>
<span id="cb25-67"><a href="#cb25-67" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"task"</span>: <span class="st">"Medical VQA"</span>, <span class="st">"complexity"</span>: <span class="st">"complex"</span>, <span class="st">"domain"</span>: <span class="st">"large"</span>},</span>
<span id="cb25-68"><a href="#cb25-68" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"task"</span>: <span class="st">"General captioning"</span>, <span class="st">"complexity"</span>: <span class="st">"balanced"</span>, <span class="st">"domain"</span>: <span class="st">"moderate"</span>}</span>
<span id="cb25-69"><a href="#cb25-69" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb25-70"><a href="#cb25-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-71"><a href="#cb25-71" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"LoRA Hyperparameter Recommendations:"</span>)</span>
<span id="cb25-72"><a href="#cb25-72" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">45</span>)</span>
<span id="cb25-73"><a href="#cb25-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-74"><a href="#cb25-74" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> scenario <span class="kw">in</span> scenarios:</span>
<span id="cb25-75"><a href="#cb25-75" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Scenario: </span><span class="sc">{</span>scenario[<span class="st">'task'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb25-76"><a href="#cb25-76" aria-hidden="true" tabindex="-1"></a>    recommendations <span class="op">=</span> guide.get_recommendations(</span>
<span id="cb25-77"><a href="#cb25-77" aria-hidden="true" tabindex="-1"></a>        scenario[<span class="st">'complexity'</span>], </span>
<span id="cb25-78"><a href="#cb25-78" aria-hidden="true" tabindex="-1"></a>        scenario[<span class="st">'domain'</span>]</span>
<span id="cb25-79"><a href="#cb25-79" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb25-80"><a href="#cb25-80" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-81"><a href="#cb25-81" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Rank: </span><span class="sc">{</span>recommendations[<span class="st">'rank'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb25-82"><a href="#cb25-82" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Alpha: </span><span class="sc">{</span>recommendations[<span class="st">'alpha'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb25-83"><a href="#cb25-83" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  LoRA LR: </span><span class="sc">{</span>recommendations[<span class="st">'lora_lr'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb25-84"><a href="#cb25-84" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Base LR: </span><span class="sc">{</span>recommendations[<span class="st">'base_lr'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb25-85"><a href="#cb25-85" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Reasoning: </span><span class="sc">{</span>recommendations[<span class="st">'reasoning'</span>][<span class="st">'rank'</span>]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>LoRA Hyperparameter Recommendations:
=============================================

Scenario: Simple classification
  Rank: 4
  Alpha: 4
  LoRA LR: 0.0001
  Base LR: 1e-05
  Reasoning: Selected 4 for simple task complexity

Scenario: Medical VQA
  Rank: 64
  Alpha: 128
  LoRA LR: 0.0001
  Base LR: 1e-05
  Reasoning: Selected 64 for complex task complexity

Scenario: General captioning
  Rank: 16
  Alpha: 24
  LoRA LR: 0.0001
  Base LR: 1e-05
  Reasoning: Selected 16 for balanced task complexity</code></pre>
</div>
</div>
</section>
<section id="module-selection-strategy" class="level3">
<h3 class="anchored" data-anchor-id="module-selection-strategy">2. Module Selection Strategy</h3>
<div id="cell-fig-module-selection" class="cell" data-execution_count="19">
<div class="cell-output cell-output-display">
<div id="fig-module-selection" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-module-selection-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-module-selection-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-module-selection-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: LoRA Module Selection Impact Analysis
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="training-best-practices" class="level3">
<h3 class="anchored" data-anchor-id="training-best-practices">3. Training Best Practices</h3>
<div id="training-best-practices" class="cell" data-execution_count="20">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LoRATrainingBestPractices:</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.practices <span class="op">=</span> {</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>            <span class="st">"gradient_handling"</span>: {</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>                <span class="st">"use_gradient_accumulation"</span>: <span class="va">True</span>,</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>                <span class="st">"accumulation_steps"</span>: <span class="dv">4</span>,</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>                <span class="st">"apply_gradient_clipping"</span>: <span class="va">True</span>,</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>                <span class="st">"max_grad_norm"</span>: <span class="fl">1.0</span>,</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>                <span class="st">"clip_lora_only"</span>: <span class="va">True</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>            <span class="st">"monitoring"</span>: {</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>                <span class="st">"track_adapter_weights"</span>: <span class="va">True</span>,</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>                <span class="st">"monitor_rank_utilization"</span>: <span class="va">True</span>,</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>                <span class="st">"log_training_metrics"</span>: <span class="va">True</span>,</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>                <span class="st">"use_early_stopping"</span>: <span class="va">True</span>,</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>                <span class="st">"patience"</span>: <span class="dv">3</span></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>            <span class="st">"checkpointing"</span>: {</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>                <span class="st">"save_best_model"</span>: <span class="va">True</span>,</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>                <span class="st">"save_regular_checkpoints"</span>: <span class="va">True</span>,</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>                <span class="st">"checkpoint_frequency"</span>: <span class="dv">1</span>,  <span class="co"># epochs</span></span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a>                <span class="st">"keep_top_k"</span>: <span class="dv">3</span></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>            <span class="st">"optimization"</span>: {</span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a>                <span class="st">"use_mixed_precision"</span>: <span class="va">True</span>,</span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>                <span class="st">"enable_gradient_checkpointing"</span>: <span class="va">True</span>,</span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a>                <span class="st">"separate_parameter_groups"</span>: <span class="va">True</span>,</span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a>                <span class="st">"use_warmup"</span>: <span class="va">True</span>,</span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a>                <span class="st">"warmup_ratio"</span>: <span class="fl">0.1</span></span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_training_checklist(<span class="va">self</span>):</span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Generate training checklist"""</span></span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a>        checklist <span class="op">=</span> []</span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a>        checklist.append(<span class="st">"🔧 Setup Phase:"</span>)</span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a>        checklist.append(<span class="st">"  ✓ Configure separate learning rates for LoRA and base parameters"</span>)</span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a>        checklist.append(<span class="st">"  ✓ Enable mixed precision training"</span>)</span>
<span id="cb27-40"><a href="#cb27-40" aria-hidden="true" tabindex="-1"></a>        checklist.append(<span class="st">"  ✓ Set up gradient accumulation"</span>)</span>
<span id="cb27-41"><a href="#cb27-41" aria-hidden="true" tabindex="-1"></a>        checklist.append(<span class="st">"  ✓ Configure gradient clipping"</span>)</span>
<span id="cb27-42"><a href="#cb27-42" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb27-43"><a href="#cb27-43" aria-hidden="true" tabindex="-1"></a>        checklist.append(<span class="st">"</span><span class="ch">\n</span><span class="st">📊 Monitoring Phase:"</span>)</span>
<span id="cb27-44"><a href="#cb27-44" aria-hidden="true" tabindex="-1"></a>        checklist.append(<span class="st">"  ✓ Track LoRA weight norms"</span>)</span>
<span id="cb27-45"><a href="#cb27-45" aria-hidden="true" tabindex="-1"></a>        checklist.append(<span class="st">"  ✓ Monitor validation metrics"</span>)</span>
<span id="cb27-46"><a href="#cb27-46" aria-hidden="true" tabindex="-1"></a>        checklist.append(<span class="st">"  ✓ Check for overfitting signs"</span>)</span>
<span id="cb27-47"><a href="#cb27-47" aria-hidden="true" tabindex="-1"></a>        checklist.append(<span class="st">"  ✓ Validate rank utilization"</span>)</span>
<span id="cb27-48"><a href="#cb27-48" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb27-49"><a href="#cb27-49" aria-hidden="true" tabindex="-1"></a>        checklist.append(<span class="st">"</span><span class="ch">\n</span><span class="st">💾 Checkpointing Phase:"</span>)</span>
<span id="cb27-50"><a href="#cb27-50" aria-hidden="true" tabindex="-1"></a>        checklist.append(<span class="st">"  ✓ Save model at regular intervals"</span>)</span>
<span id="cb27-51"><a href="#cb27-51" aria-hidden="true" tabindex="-1"></a>        checklist.append(<span class="st">"  ✓ Keep best performing checkpoint"</span>)</span>
<span id="cb27-52"><a href="#cb27-52" aria-hidden="true" tabindex="-1"></a>        checklist.append(<span class="st">"  ✓ Save LoRA adapters separately"</span>)</span>
<span id="cb27-53"><a href="#cb27-53" aria-hidden="true" tabindex="-1"></a>        checklist.append(<span class="st">"  ✓ Document hyperparameters"</span>)</span>
<span id="cb27-54"><a href="#cb27-54" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb27-55"><a href="#cb27-55" aria-hidden="true" tabindex="-1"></a>        checklist.append(<span class="st">"</span><span class="ch">\n</span><span class="st">🎯 Evaluation Phase:"</span>)</span>
<span id="cb27-56"><a href="#cb27-56" aria-hidden="true" tabindex="-1"></a>        checklist.append(<span class="st">"  ✓ Test on multiple datasets"</span>)</span>
<span id="cb27-57"><a href="#cb27-57" aria-hidden="true" tabindex="-1"></a>        checklist.append(<span class="st">"  ✓ Measure parameter efficiency"</span>)</span>
<span id="cb27-58"><a href="#cb27-58" aria-hidden="true" tabindex="-1"></a>        checklist.append(<span class="st">"  ✓ Check inference speed"</span>)</span>
<span id="cb27-59"><a href="#cb27-59" aria-hidden="true" tabindex="-1"></a>        checklist.append(<span class="st">"  ✓ Validate robustness"</span>)</span>
<span id="cb27-60"><a href="#cb27-60" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb27-61"><a href="#cb27-61" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> checklist</span>
<span id="cb27-62"><a href="#cb27-62" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-63"><a href="#cb27-63" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> validate_configuration(<span class="va">self</span>, config):</span>
<span id="cb27-64"><a href="#cb27-64" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Validate training configuration"""</span></span>
<span id="cb27-65"><a href="#cb27-65" aria-hidden="true" tabindex="-1"></a>        issues <span class="op">=</span> []</span>
<span id="cb27-66"><a href="#cb27-66" aria-hidden="true" tabindex="-1"></a>        warnings <span class="op">=</span> []</span>
<span id="cb27-67"><a href="#cb27-67" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb27-68"><a href="#cb27-68" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check rank settings</span></span>
<span id="cb27-69"><a href="#cb27-69" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">hasattr</span>(config, <span class="st">'rank'</span>):</span>
<span id="cb27-70"><a href="#cb27-70" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> config.rank <span class="op">&lt;</span> <span class="dv">1</span>:</span>
<span id="cb27-71"><a href="#cb27-71" aria-hidden="true" tabindex="-1"></a>                issues.append(<span class="st">"Rank must be &gt;= 1"</span>)</span>
<span id="cb27-72"><a href="#cb27-72" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> config.rank <span class="op">&gt;</span> <span class="dv">128</span>:</span>
<span id="cb27-73"><a href="#cb27-73" aria-hidden="true" tabindex="-1"></a>                warnings.append(<span class="st">"Very high rank may reduce efficiency benefits"</span>)</span>
<span id="cb27-74"><a href="#cb27-74" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb27-75"><a href="#cb27-75" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check alpha settings</span></span>
<span id="cb27-76"><a href="#cb27-76" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">hasattr</span>(config, <span class="st">'alpha'</span>) <span class="kw">and</span> <span class="bu">hasattr</span>(config, <span class="st">'rank'</span>):</span>
<span id="cb27-77"><a href="#cb27-77" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> config.alpha <span class="op">&lt;</span> config.rank <span class="op">/</span> <span class="dv">4</span>:</span>
<span id="cb27-78"><a href="#cb27-78" aria-hidden="true" tabindex="-1"></a>                warnings.append(<span class="st">"Very low alpha may limit adaptation strength"</span>)</span>
<span id="cb27-79"><a href="#cb27-79" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> config.alpha <span class="op">&gt;</span> config.rank <span class="op">*</span> <span class="dv">4</span>:</span>
<span id="cb27-80"><a href="#cb27-80" aria-hidden="true" tabindex="-1"></a>                warnings.append(<span class="st">"Very high alpha may cause instability"</span>)</span>
<span id="cb27-81"><a href="#cb27-81" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb27-82"><a href="#cb27-82" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check learning rates</span></span>
<span id="cb27-83"><a href="#cb27-83" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">hasattr</span>(config, <span class="st">'learning_rate'</span>):</span>
<span id="cb27-84"><a href="#cb27-84" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> config.learning_rate <span class="op">&gt;</span> <span class="fl">1e-2</span>:</span>
<span id="cb27-85"><a href="#cb27-85" aria-hidden="true" tabindex="-1"></a>                warnings.append(<span class="st">"High learning rate may cause instability"</span>)</span>
<span id="cb27-86"><a href="#cb27-86" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> config.learning_rate <span class="op">&lt;</span> <span class="fl">1e-6</span>:</span>
<span id="cb27-87"><a href="#cb27-87" aria-hidden="true" tabindex="-1"></a>                warnings.append(<span class="st">"Very low learning rate may slow convergence"</span>)</span>
<span id="cb27-88"><a href="#cb27-88" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb27-89"><a href="#cb27-89" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {</span>
<span id="cb27-90"><a href="#cb27-90" aria-hidden="true" tabindex="-1"></a>            <span class="st">"issues"</span>: issues,</span>
<span id="cb27-91"><a href="#cb27-91" aria-hidden="true" tabindex="-1"></a>            <span class="st">"warnings"</span>: warnings,</span>
<span id="cb27-92"><a href="#cb27-92" aria-hidden="true" tabindex="-1"></a>            <span class="st">"valid"</span>: <span class="bu">len</span>(issues) <span class="op">==</span> <span class="dv">0</span></span>
<span id="cb27-93"><a href="#cb27-93" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb27-94"><a href="#cb27-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-95"><a href="#cb27-95" aria-hidden="true" tabindex="-1"></a><span class="co"># Best practices demonstration</span></span>
<span id="cb27-96"><a href="#cb27-96" aria-hidden="true" tabindex="-1"></a>practices <span class="op">=</span> LoRATrainingBestPractices()</span>
<span id="cb27-97"><a href="#cb27-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-98"><a href="#cb27-98" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"LoRA Training Best Practices:"</span>)</span>
<span id="cb27-99"><a href="#cb27-99" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">35</span>)</span>
<span id="cb27-100"><a href="#cb27-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-101"><a href="#cb27-101" aria-hidden="true" tabindex="-1"></a><span class="co"># Show checklist</span></span>
<span id="cb27-102"><a href="#cb27-102" aria-hidden="true" tabindex="-1"></a>checklist <span class="op">=</span> practices.get_training_checklist()</span>
<span id="cb27-103"><a href="#cb27-103" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> item <span class="kw">in</span> checklist:</span>
<span id="cb27-104"><a href="#cb27-104" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(item)</span>
<span id="cb27-105"><a href="#cb27-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-106"><a href="#cb27-106" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">35</span>)</span>
<span id="cb27-107"><a href="#cb27-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-108"><a href="#cb27-108" aria-hidden="true" tabindex="-1"></a><span class="co"># Validate example configurations</span></span>
<span id="cb27-109"><a href="#cb27-109" aria-hidden="true" tabindex="-1"></a>example_configs <span class="op">=</span> [</span>
<span id="cb27-110"><a href="#cb27-110" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"name"</span>: <span class="st">"Good Config"</span>, <span class="st">"rank"</span>: <span class="dv">16</span>, <span class="st">"alpha"</span>: <span class="dv">16</span>, <span class="st">"learning_rate"</span>: <span class="fl">1e-4</span>},</span>
<span id="cb27-111"><a href="#cb27-111" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"name"</span>: <span class="st">"High Rank"</span>, <span class="st">"rank"</span>: <span class="dv">256</span>, <span class="st">"alpha"</span>: <span class="dv">256</span>, <span class="st">"learning_rate"</span>: <span class="fl">1e-4</span>},</span>
<span id="cb27-112"><a href="#cb27-112" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"name"</span>: <span class="st">"Low Alpha"</span>, <span class="st">"rank"</span>: <span class="dv">16</span>, <span class="st">"alpha"</span>: <span class="dv">2</span>, <span class="st">"learning_rate"</span>: <span class="fl">1e-4</span>}</span>
<span id="cb27-113"><a href="#cb27-113" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb27-114"><a href="#cb27-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-115"><a href="#cb27-115" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Configuration Validation:"</span>)</span>
<span id="cb27-116"><a href="#cb27-116" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> config_dict <span class="kw">in</span> example_configs:</span>
<span id="cb27-117"><a href="#cb27-117" aria-hidden="true" tabindex="-1"></a>    config <span class="op">=</span> <span class="bu">type</span>(<span class="st">'Config'</span>, (), config_dict)()</span>
<span id="cb27-118"><a href="#cb27-118" aria-hidden="true" tabindex="-1"></a>    validation <span class="op">=</span> practices.validate_configuration(config)</span>
<span id="cb27-119"><a href="#cb27-119" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-120"><a href="#cb27-120" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span>config_dict[<span class="st">'name'</span>]<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb27-121"><a href="#cb27-121" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Valid: </span><span class="sc">{</span><span class="st">'✓'</span> <span class="cf">if</span> validation[<span class="st">'valid'</span>] <span class="cf">else</span> <span class="st">'✗'</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb27-122"><a href="#cb27-122" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-123"><a href="#cb27-123" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> validation[<span class="st">'issues'</span>]:</span>
<span id="cb27-124"><a href="#cb27-124" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"  Issues:"</span>)</span>
<span id="cb27-125"><a href="#cb27-125" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> issue <span class="kw">in</span> validation[<span class="st">'issues'</span>]:</span>
<span id="cb27-126"><a href="#cb27-126" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"    ❌ </span><span class="sc">{</span>issue<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb27-127"><a href="#cb27-127" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-128"><a href="#cb27-128" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> validation[<span class="st">'warnings'</span>]:</span>
<span id="cb27-129"><a href="#cb27-129" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"  Warnings:"</span>)</span>
<span id="cb27-130"><a href="#cb27-130" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> warning <span class="kw">in</span> validation[<span class="st">'warnings'</span>]:</span>
<span id="cb27-131"><a href="#cb27-131" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"    ⚠️  </span><span class="sc">{</span>warning<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>LoRA Training Best Practices:
===================================
🔧 Setup Phase:
  ✓ Configure separate learning rates for LoRA and base parameters
  ✓ Enable mixed precision training
  ✓ Set up gradient accumulation
  ✓ Configure gradient clipping

📊 Monitoring Phase:
  ✓ Track LoRA weight norms
  ✓ Monitor validation metrics
  ✓ Check for overfitting signs
  ✓ Validate rank utilization

💾 Checkpointing Phase:
  ✓ Save model at regular intervals
  ✓ Keep best performing checkpoint
  ✓ Save LoRA adapters separately
  ✓ Document hyperparameters

🎯 Evaluation Phase:
  ✓ Test on multiple datasets
  ✓ Measure parameter efficiency
  ✓ Check inference speed
  ✓ Validate robustness

===================================

Configuration Validation:

Good Config:
  Valid: ✓

High Rank:
  Valid: ✓
  Warnings:
    ⚠️  Very high rank may reduce efficiency benefits

Low Alpha:
  Valid: ✓
  Warnings:
    ⚠️  Very low alpha may limit adaptation strength</code></pre>
</div>
</div>
</section>
</section>
<section id="troubleshooting" class="level2">
<h2 class="anchored" data-anchor-id="troubleshooting">Troubleshooting</h2>
<section id="common-issues-and-solutions" class="level3">
<h3 class="anchored" data-anchor-id="common-issues-and-solutions">Common Issues and Solutions</h3>
<div id="troubleshooting-guide" class="cell" data-execution_count="21">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LoRATroubleshootingGuide:</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.issues <span class="op">=</span> {</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>            <span class="st">"training_instability"</span>: {</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>                <span class="st">"symptoms"</span>: [</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Loss spikes or NaN values"</span>,</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Gradient explosion"</span>, </span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Poor convergence"</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>                ],</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>                <span class="st">"solutions"</span>: [</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Apply gradient clipping (max_norm=1.0)"</span>,</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Use learning rate scheduling"</span>,</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Enable gradient accumulation"</span>,</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Reduce learning rate"</span>,</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Check data preprocessing"</span></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>                ],</span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>                <span class="st">"code_example"</span>: <span class="st">"""</span></span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a><span class="st"># Gradient clipping</span></span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a><span class="st">torch.nn.utils.clip_grad_norm_(lora_parameters, max_norm=1.0)</span></span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a><span class="st"># Learning rate scheduling</span></span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a><span class="st">scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(</span></span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a><span class="st">    optimizer, mode='min', factor=0.5, patience=3</span></span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a><span class="st">)"""</span></span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a>            <span class="st">"overfitting"</span>: {</span>
<span id="cb29-28"><a href="#cb29-28" aria-hidden="true" tabindex="-1"></a>                <span class="st">"symptoms"</span>: [</span>
<span id="cb29-29"><a href="#cb29-29" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Large gap between train/validation performance"</span>,</span>
<span id="cb29-30"><a href="#cb29-30" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"High LoRA weight magnitudes"</span>,</span>
<span id="cb29-31"><a href="#cb29-31" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Perfect training accuracy"</span></span>
<span id="cb29-32"><a href="#cb29-32" aria-hidden="true" tabindex="-1"></a>                ],</span>
<span id="cb29-33"><a href="#cb29-33" aria-hidden="true" tabindex="-1"></a>                <span class="st">"solutions"</span>: [</span>
<span id="cb29-34"><a href="#cb29-34" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Add dropout to LoRA layers"</span>,</span>
<span id="cb29-35"><a href="#cb29-35" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Apply weight decay to LoRA parameters"</span>,</span>
<span id="cb29-36"><a href="#cb29-36" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Use early stopping"</span>,</span>
<span id="cb29-37"><a href="#cb29-37" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Reduce rank or alpha"</span>,</span>
<span id="cb29-38"><a href="#cb29-38" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Increase dataset size"</span></span>
<span id="cb29-39"><a href="#cb29-39" aria-hidden="true" tabindex="-1"></a>                ],</span>
<span id="cb29-40"><a href="#cb29-40" aria-hidden="true" tabindex="-1"></a>                <span class="st">"code_example"</span>: <span class="st">"""</span></span>
<span id="cb29-41"><a href="#cb29-41" aria-hidden="true" tabindex="-1"></a><span class="st"># Dropout in LoRA layers</span></span>
<span id="cb29-42"><a href="#cb29-42" aria-hidden="true" tabindex="-1"></a><span class="st">lora_layer = LoRALayer(dropout=0.2)</span></span>
<span id="cb29-43"><a href="#cb29-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-44"><a href="#cb29-44" aria-hidden="true" tabindex="-1"></a><span class="st"># Weight decay for LoRA parameters  </span></span>
<span id="cb29-45"><a href="#cb29-45" aria-hidden="true" tabindex="-1"></a><span class="st">optimizer = torch.optim.AdamW(lora_params, weight_decay=0.01)"""</span></span>
<span id="cb29-46"><a href="#cb29-46" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb29-47"><a href="#cb29-47" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb29-48"><a href="#cb29-48" aria-hidden="true" tabindex="-1"></a>            <span class="st">"memory_issues"</span>: {</span>
<span id="cb29-49"><a href="#cb29-49" aria-hidden="true" tabindex="-1"></a>                <span class="st">"symptoms"</span>: [</span>
<span id="cb29-50"><a href="#cb29-50" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"CUDA out of memory errors"</span>,</span>
<span id="cb29-51"><a href="#cb29-51" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Slow training speed"</span>,</span>
<span id="cb29-52"><a href="#cb29-52" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"System crashes"</span></span>
<span id="cb29-53"><a href="#cb29-53" aria-hidden="true" tabindex="-1"></a>                ],</span>
<span id="cb29-54"><a href="#cb29-54" aria-hidden="true" tabindex="-1"></a>                <span class="st">"solutions"</span>: [</span>
<span id="cb29-55"><a href="#cb29-55" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Enable gradient checkpointing"</span>,</span>
<span id="cb29-56"><a href="#cb29-56" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Reduce batch size and use gradient accumulation"</span>,</span>
<span id="cb29-57"><a href="#cb29-57" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Use mixed precision training"</span>,</span>
<span id="cb29-58"><a href="#cb29-58" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Merge LoRA weights for inference"</span>,</span>
<span id="cb29-59"><a href="#cb29-59" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Clear unused variables"</span></span>
<span id="cb29-60"><a href="#cb29-60" aria-hidden="true" tabindex="-1"></a>                ],</span>
<span id="cb29-61"><a href="#cb29-61" aria-hidden="true" tabindex="-1"></a>                <span class="st">"code_example"</span>: <span class="st">"""</span></span>
<span id="cb29-62"><a href="#cb29-62" aria-hidden="true" tabindex="-1"></a><span class="st"># Gradient checkpointing</span></span>
<span id="cb29-63"><a href="#cb29-63" aria-hidden="true" tabindex="-1"></a><span class="st">model.gradient_checkpointing_enable()</span></span>
<span id="cb29-64"><a href="#cb29-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-65"><a href="#cb29-65" aria-hidden="true" tabindex="-1"></a><span class="st"># Mixed precision training</span></span>
<span id="cb29-66"><a href="#cb29-66" aria-hidden="true" tabindex="-1"></a><span class="st">with torch.cuda.amp.autocast():</span></span>
<span id="cb29-67"><a href="#cb29-67" aria-hidden="true" tabindex="-1"></a><span class="st">    outputs = model(**batch)"""</span></span>
<span id="cb29-68"><a href="#cb29-68" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb29-69"><a href="#cb29-69" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb29-70"><a href="#cb29-70" aria-hidden="true" tabindex="-1"></a>            <span class="st">"poor_performance"</span>: {</span>
<span id="cb29-71"><a href="#cb29-71" aria-hidden="true" tabindex="-1"></a>                <span class="st">"symptoms"</span>: [</span>
<span id="cb29-72"><a href="#cb29-72" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Lower accuracy than expected"</span>,</span>
<span id="cb29-73"><a href="#cb29-73" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Slow convergence"</span>,</span>
<span id="cb29-74"><a href="#cb29-74" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Inconsistent results"</span></span>
<span id="cb29-75"><a href="#cb29-75" aria-hidden="true" tabindex="-1"></a>                ],</span>
<span id="cb29-76"><a href="#cb29-76" aria-hidden="true" tabindex="-1"></a>                <span class="st">"solutions"</span>: [</span>
<span id="cb29-77"><a href="#cb29-77" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Increase rank gradually"</span>,</span>
<span id="cb29-78"><a href="#cb29-78" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Target more modules"</span>, </span>
<span id="cb29-79"><a href="#cb29-79" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Adjust learning rates"</span>,</span>
<span id="cb29-80"><a href="#cb29-80" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Check data quality"</span>,</span>
<span id="cb29-81"><a href="#cb29-81" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Validate preprocessing"</span></span>
<span id="cb29-82"><a href="#cb29-82" aria-hidden="true" tabindex="-1"></a>                ],</span>
<span id="cb29-83"><a href="#cb29-83" aria-hidden="true" tabindex="-1"></a>                <span class="st">"code_example"</span>: <span class="st">"""</span></span>
<span id="cb29-84"><a href="#cb29-84" aria-hidden="true" tabindex="-1"></a><span class="st"># Progressive rank increase</span></span>
<span id="cb29-85"><a href="#cb29-85" aria-hidden="true" tabindex="-1"></a><span class="st">def increase_rank(model, new_rank):</span></span>
<span id="cb29-86"><a href="#cb29-86" aria-hidden="true" tabindex="-1"></a><span class="st">    for module in model.modules():</span></span>
<span id="cb29-87"><a href="#cb29-87" aria-hidden="true" tabindex="-1"></a><span class="st">        if isinstance(module, LoRALinear):</span></span>
<span id="cb29-88"><a href="#cb29-88" aria-hidden="true" tabindex="-1"></a><span class="st">            expand_lora_rank(module, new_rank)"""</span></span>
<span id="cb29-89"><a href="#cb29-89" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb29-90"><a href="#cb29-90" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb29-91"><a href="#cb29-91" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb29-92"><a href="#cb29-92" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> diagnose_issue(<span class="va">self</span>, symptoms):</span>
<span id="cb29-93"><a href="#cb29-93" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Diagnose issues based on symptoms"""</span></span>
<span id="cb29-94"><a href="#cb29-94" aria-hidden="true" tabindex="-1"></a>        matches <span class="op">=</span> []</span>
<span id="cb29-95"><a href="#cb29-95" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb29-96"><a href="#cb29-96" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> issue_name, issue_info <span class="kw">in</span> <span class="va">self</span>.issues.items():</span>
<span id="cb29-97"><a href="#cb29-97" aria-hidden="true" tabindex="-1"></a>            symptom_matches <span class="op">=</span> <span class="bu">sum</span>(<span class="dv">1</span> <span class="cf">for</span> symptom <span class="kw">in</span> symptoms </span>
<span id="cb29-98"><a href="#cb29-98" aria-hidden="true" tabindex="-1"></a>                                <span class="cf">if</span> <span class="bu">any</span>(s.lower() <span class="kw">in</span> symptom.lower() </span>
<span id="cb29-99"><a href="#cb29-99" aria-hidden="true" tabindex="-1"></a>                                      <span class="cf">for</span> s <span class="kw">in</span> issue_info[<span class="st">"symptoms"</span>]))</span>
<span id="cb29-100"><a href="#cb29-100" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb29-101"><a href="#cb29-101" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> symptom_matches <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb29-102"><a href="#cb29-102" aria-hidden="true" tabindex="-1"></a>                matches.append({</span>
<span id="cb29-103"><a href="#cb29-103" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"issue"</span>: issue_name,</span>
<span id="cb29-104"><a href="#cb29-104" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"confidence"</span>: symptom_matches <span class="op">/</span> <span class="bu">len</span>(issue_info[<span class="st">"symptoms"</span>]),</span>
<span id="cb29-105"><a href="#cb29-105" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"solutions"</span>: issue_info[<span class="st">"solutions"</span>],</span>
<span id="cb29-106"><a href="#cb29-106" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"code_example"</span>: issue_info[<span class="st">"code_example"</span>]</span>
<span id="cb29-107"><a href="#cb29-107" aria-hidden="true" tabindex="-1"></a>                })</span>
<span id="cb29-108"><a href="#cb29-108" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb29-109"><a href="#cb29-109" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Sort by confidence</span></span>
<span id="cb29-110"><a href="#cb29-110" aria-hidden="true" tabindex="-1"></a>        matches.sort(key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="st">"confidence"</span>], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb29-111"><a href="#cb29-111" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> matches</span>
<span id="cb29-112"><a href="#cb29-112" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb29-113"><a href="#cb29-113" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_debugging_checklist(<span class="va">self</span>):</span>
<span id="cb29-114"><a href="#cb29-114" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Get debugging checklist"""</span></span>
<span id="cb29-115"><a href="#cb29-115" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> [</span>
<span id="cb29-116"><a href="#cb29-116" aria-hidden="true" tabindex="-1"></a>            <span class="st">"📊 Check Data Quality:"</span>,</span>
<span id="cb29-117"><a href="#cb29-117" aria-hidden="true" tabindex="-1"></a>            <span class="st">"  • Validate input preprocessing"</span>,</span>
<span id="cb29-118"><a href="#cb29-118" aria-hidden="true" tabindex="-1"></a>            <span class="st">"  • Check label distribution"</span>, </span>
<span id="cb29-119"><a href="#cb29-119" aria-hidden="true" tabindex="-1"></a>            <span class="st">"  • Verify data augmentation"</span>,</span>
<span id="cb29-120"><a href="#cb29-120" aria-hidden="true" tabindex="-1"></a>            <span class="st">"  • Ensure proper batching"</span>,</span>
<span id="cb29-121"><a href="#cb29-121" aria-hidden="true" tabindex="-1"></a>            <span class="st">""</span>,</span>
<span id="cb29-122"><a href="#cb29-122" aria-hidden="true" tabindex="-1"></a>            <span class="st">"🔧 Verify Model Configuration:"</span>,</span>
<span id="cb29-123"><a href="#cb29-123" aria-hidden="true" tabindex="-1"></a>            <span class="st">"  • Confirm LoRA target modules"</span>,</span>
<span id="cb29-124"><a href="#cb29-124" aria-hidden="true" tabindex="-1"></a>            <span class="st">"  • Check rank and alpha values"</span>,</span>
<span id="cb29-125"><a href="#cb29-125" aria-hidden="true" tabindex="-1"></a>            <span class="st">"  • Validate learning rates"</span>,</span>
<span id="cb29-126"><a href="#cb29-126" aria-hidden="true" tabindex="-1"></a>            <span class="st">"  • Ensure proper initialization"</span>,</span>
<span id="cb29-127"><a href="#cb29-127" aria-hidden="true" tabindex="-1"></a>            <span class="st">""</span>,</span>
<span id="cb29-128"><a href="#cb29-128" aria-hidden="true" tabindex="-1"></a>            <span class="st">"📈 Monitor Training Metrics:"</span>,</span>
<span id="cb29-129"><a href="#cb29-129" aria-hidden="true" tabindex="-1"></a>            <span class="st">"  • Track loss curves"</span>,</span>
<span id="cb29-130"><a href="#cb29-130" aria-hidden="true" tabindex="-1"></a>            <span class="st">"  • Monitor gradient norms"</span>,</span>
<span id="cb29-131"><a href="#cb29-131" aria-hidden="true" tabindex="-1"></a>            <span class="st">"  • Check weight magnitudes"</span>,</span>
<span id="cb29-132"><a href="#cb29-132" aria-hidden="true" tabindex="-1"></a>            <span class="st">"  • Validate learning rate schedule"</span>,</span>
<span id="cb29-133"><a href="#cb29-133" aria-hidden="true" tabindex="-1"></a>            <span class="st">""</span>,</span>
<span id="cb29-134"><a href="#cb29-134" aria-hidden="true" tabindex="-1"></a>            <span class="st">"💾 System Resources:"</span>,</span>
<span id="cb29-135"><a href="#cb29-135" aria-hidden="true" tabindex="-1"></a>            <span class="st">"  • Monitor GPU memory usage"</span>,</span>
<span id="cb29-136"><a href="#cb29-136" aria-hidden="true" tabindex="-1"></a>            <span class="st">"  • Check system RAM"</span>,</span>
<span id="cb29-137"><a href="#cb29-137" aria-hidden="true" tabindex="-1"></a>            <span class="st">"  • Verify disk space"</span>,</span>
<span id="cb29-138"><a href="#cb29-138" aria-hidden="true" tabindex="-1"></a>            <span class="st">"  • Monitor temperature/throttling"</span></span>
<span id="cb29-139"><a href="#cb29-139" aria-hidden="true" tabindex="-1"></a>        ]</span>
<span id="cb29-140"><a href="#cb29-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-141"><a href="#cb29-141" aria-hidden="true" tabindex="-1"></a><span class="co"># Troubleshooting demonstration</span></span>
<span id="cb29-142"><a href="#cb29-142" aria-hidden="true" tabindex="-1"></a>troubleshooter <span class="op">=</span> LoRATroubleshootingGuide()</span>
<span id="cb29-143"><a href="#cb29-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-144"><a href="#cb29-144" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"LoRA Troubleshooting Guide:"</span>)</span>
<span id="cb29-145"><a href="#cb29-145" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">30</span>)</span>
<span id="cb29-146"><a href="#cb29-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-147"><a href="#cb29-147" aria-hidden="true" tabindex="-1"></a><span class="co"># Example issue diagnosis</span></span>
<span id="cb29-148"><a href="#cb29-148" aria-hidden="true" tabindex="-1"></a>example_symptoms <span class="op">=</span> [</span>
<span id="cb29-149"><a href="#cb29-149" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Loss spikes during training"</span>,</span>
<span id="cb29-150"><a href="#cb29-150" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Gradient explosion detected"</span>, </span>
<span id="cb29-151"><a href="#cb29-151" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Poor convergence after many epochs"</span></span>
<span id="cb29-152"><a href="#cb29-152" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb29-153"><a href="#cb29-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-154"><a href="#cb29-154" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Example Issue Diagnosis:"</span>)</span>
<span id="cb29-155"><a href="#cb29-155" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Symptoms: </span><span class="sc">{</span><span class="st">', '</span><span class="sc">.</span>join(example_symptoms)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb29-156"><a href="#cb29-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-157"><a href="#cb29-157" aria-hidden="true" tabindex="-1"></a>matches <span class="op">=</span> troubleshooter.diagnose_issue(example_symptoms)</span>
<span id="cb29-158"><a href="#cb29-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-159"><a href="#cb29-159" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> match <span class="kw">in</span> matches[:<span class="dv">2</span>]:  <span class="co"># Show top 2 matches</span></span>
<span id="cb29-160"><a href="#cb29-160" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Likely Issue: </span><span class="sc">{</span>match[<span class="st">'issue'</span>]<span class="sc">.</span>replace(<span class="st">'_'</span>, <span class="st">' '</span>)<span class="sc">.</span>title()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb29-161"><a href="#cb29-161" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Confidence: </span><span class="sc">{</span>match[<span class="st">'confidence'</span>]<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb29-162"><a href="#cb29-162" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Recommended Solutions:"</span>)</span>
<span id="cb29-163"><a href="#cb29-163" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> solution <span class="kw">in</span> match[<span class="st">'solutions'</span>][:<span class="dv">3</span>]:  <span class="co"># Show top 3 solutions</span></span>
<span id="cb29-164"><a href="#cb29-164" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  • </span><span class="sc">{</span>solution<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb29-165"><a href="#cb29-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-166"><a href="#cb29-166" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">30</span>)</span>
<span id="cb29-167"><a href="#cb29-167" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Debugging Checklist:"</span>)</span>
<span id="cb29-168"><a href="#cb29-168" aria-hidden="true" tabindex="-1"></a>checklist <span class="op">=</span> troubleshooter.get_debugging_checklist()</span>
<span id="cb29-169"><a href="#cb29-169" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> item <span class="kw">in</span> checklist:</span>
<span id="cb29-170"><a href="#cb29-170" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(item)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>LoRA Troubleshooting Guide:
==============================
Example Issue Diagnosis:
Symptoms: Loss spikes during training, Gradient explosion detected, Poor convergence after many epochs

Likely Issue: Training Instability
Confidence: 0.67
Recommended Solutions:
  • Apply gradient clipping (max_norm=1.0)
  • Use learning rate scheduling
  • Enable gradient accumulation

==============================
Debugging Checklist:
📊 Check Data Quality:
  • Validate input preprocessing
  • Check label distribution
  • Verify data augmentation
  • Ensure proper batching

🔧 Verify Model Configuration:
  • Confirm LoRA target modules
  • Check rank and alpha values
  • Validate learning rates
  • Ensure proper initialization

📈 Monitor Training Metrics:
  • Track loss curves
  • Monitor gradient norms
  • Check weight magnitudes
  • Validate learning rate schedule

💾 System Resources:
  • Monitor GPU memory usage
  • Check system RAM
  • Verify disk space
  • Monitor temperature/throttling</code></pre>
</div>
</div>
</section>
<section id="debugging-tools" class="level3">
<h3 class="anchored" data-anchor-id="debugging-tools">Debugging Tools</h3>
<div id="debugging-tools" class="cell" data-execution_count="22">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LoRADebugger:</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, model, adapter_name<span class="op">=</span><span class="st">"default"</span>):</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> model</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.adapter_name <span class="op">=</span> adapter_name</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.analysis_cache <span class="op">=</span> {}</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> analyze_lora_weights(<span class="va">self</span>):</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Analyze LoRA weight distributions"""</span></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">'weight_analysis'</span> <span class="kw">in</span> <span class="va">self</span>.analysis_cache:</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.analysis_cache[<span class="st">'weight_analysis'</span>]</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>        stats <span class="op">=</span> {}</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Simulate analysis for demonstration</span></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>        module_names <span class="op">=</span> [<span class="st">"attention.q_proj"</span>, <span class="st">"attention.k_proj"</span>, <span class="st">"attention.v_proj"</span>, </span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>                       <span class="st">"mlp.fc1"</span>, <span class="st">"mlp.fc2"</span>]</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> name <span class="kw">in</span> module_names:</span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Simulate weight statistics</span></span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>            lora_A_norm <span class="op">=</span> np.random.uniform(<span class="fl">0.1</span>, <span class="fl">2.0</span>)</span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a>            lora_B_norm <span class="op">=</span> np.random.uniform(<span class="fl">0.1</span>, <span class="fl">2.0</span>)</span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>            effective_rank <span class="op">=</span> np.random.randint(<span class="dv">4</span>, <span class="dv">16</span>)</span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>            stats[name] <span class="op">=</span> {</span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>                <span class="st">"lora_A_norm"</span>: lora_A_norm,</span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>                <span class="st">"lora_B_norm"</span>: lora_B_norm,</span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a>                <span class="st">"effective_rank"</span>: effective_rank,</span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a>                <span class="st">"rank_utilization"</span>: effective_rank <span class="op">/</span> <span class="fl">16.0</span></span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.analysis_cache[<span class="st">'weight_analysis'</span>] <span class="op">=</span> stats</span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> stats</span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> compute_rank_utilization(<span class="va">self</span>, threshold<span class="op">=</span><span class="fl">0.01</span>):</span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Compute rank utilization across modules"""</span></span>
<span id="cb31-36"><a href="#cb31-36" aria-hidden="true" tabindex="-1"></a>        weight_stats <span class="op">=</span> <span class="va">self</span>.analyze_lora_weights()</span>
<span id="cb31-37"><a href="#cb31-37" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-38"><a href="#cb31-38" aria-hidden="true" tabindex="-1"></a>        utilizations <span class="op">=</span> []</span>
<span id="cb31-39"><a href="#cb31-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> module_name, stats <span class="kw">in</span> weight_stats.items():</span>
<span id="cb31-40"><a href="#cb31-40" aria-hidden="true" tabindex="-1"></a>            utilizations.append(stats[<span class="st">"rank_utilization"</span>])</span>
<span id="cb31-41"><a href="#cb31-41" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-42"><a href="#cb31-42" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {</span>
<span id="cb31-43"><a href="#cb31-43" aria-hidden="true" tabindex="-1"></a>            <span class="st">"mean_utilization"</span>: np.mean(utilizations),</span>
<span id="cb31-44"><a href="#cb31-44" aria-hidden="true" tabindex="-1"></a>            <span class="st">"std_utilization"</span>: np.std(utilizations),</span>
<span id="cb31-45"><a href="#cb31-45" aria-hidden="true" tabindex="-1"></a>            <span class="st">"min_utilization"</span>: np.<span class="bu">min</span>(utilizations),</span>
<span id="cb31-46"><a href="#cb31-46" aria-hidden="true" tabindex="-1"></a>            <span class="st">"max_utilization"</span>: np.<span class="bu">max</span>(utilizations),</span>
<span id="cb31-47"><a href="#cb31-47" aria-hidden="true" tabindex="-1"></a>            <span class="st">"per_module"</span>: {name: stats[<span class="st">"rank_utilization"</span>] </span>
<span id="cb31-48"><a href="#cb31-48" aria-hidden="true" tabindex="-1"></a>                          <span class="cf">for</span> name, stats <span class="kw">in</span> weight_stats.items()}</span>
<span id="cb31-49"><a href="#cb31-49" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb31-50"><a href="#cb31-50" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-51"><a href="#cb31-51" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> generate_health_report(<span class="va">self</span>):</span>
<span id="cb31-52"><a href="#cb31-52" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Generate comprehensive health report"""</span></span>
<span id="cb31-53"><a href="#cb31-53" aria-hidden="true" tabindex="-1"></a>        weight_analysis <span class="op">=</span> <span class="va">self</span>.analyze_lora_weights()</span>
<span id="cb31-54"><a href="#cb31-54" aria-hidden="true" tabindex="-1"></a>        rank_utilization <span class="op">=</span> <span class="va">self</span>.compute_rank_utilization()</span>
<span id="cb31-55"><a href="#cb31-55" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-56"><a href="#cb31-56" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Identify potential issues</span></span>
<span id="cb31-57"><a href="#cb31-57" aria-hidden="true" tabindex="-1"></a>        issues <span class="op">=</span> []</span>
<span id="cb31-58"><a href="#cb31-58" aria-hidden="true" tabindex="-1"></a>        warnings <span class="op">=</span> []</span>
<span id="cb31-59"><a href="#cb31-59" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-60"><a href="#cb31-60" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check for very low rank utilization</span></span>
<span id="cb31-61"><a href="#cb31-61" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> rank_utilization[<span class="st">"mean_utilization"</span>] <span class="op">&lt;</span> <span class="fl">0.3</span>:</span>
<span id="cb31-62"><a href="#cb31-62" aria-hidden="true" tabindex="-1"></a>            issues.append(<span class="st">"Low average rank utilization - consider reducing rank"</span>)</span>
<span id="cb31-63"><a href="#cb31-63" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-64"><a href="#cb31-64" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check for very high weight norms</span></span>
<span id="cb31-65"><a href="#cb31-65" aria-hidden="true" tabindex="-1"></a>        high_norm_modules <span class="op">=</span> [name <span class="cf">for</span> name, stats <span class="kw">in</span> weight_analysis.items() </span>
<span id="cb31-66"><a href="#cb31-66" aria-hidden="true" tabindex="-1"></a>                           <span class="cf">if</span> stats[<span class="st">"lora_A_norm"</span>] <span class="op">&gt;</span> <span class="fl">5.0</span> <span class="kw">or</span> stats[<span class="st">"lora_B_norm"</span>] <span class="op">&gt;</span> <span class="fl">5.0</span>]</span>
<span id="cb31-67"><a href="#cb31-67" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> high_norm_modules:</span>
<span id="cb31-68"><a href="#cb31-68" aria-hidden="true" tabindex="-1"></a>            warnings.append(<span class="ss">f"High weight norms in modules: </span><span class="sc">{</span><span class="st">', '</span><span class="sc">.</span>join(high_norm_modules)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb31-69"><a href="#cb31-69" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-70"><a href="#cb31-70" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check for rank imbalance</span></span>
<span id="cb31-71"><a href="#cb31-71" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> rank_utilization[<span class="st">"std_utilization"</span>] <span class="op">&gt;</span> <span class="fl">0.3</span>:</span>
<span id="cb31-72"><a href="#cb31-72" aria-hidden="true" tabindex="-1"></a>            warnings.append(<span class="st">"High variance in rank utilization across modules"</span>)</span>
<span id="cb31-73"><a href="#cb31-73" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-74"><a href="#cb31-74" aria-hidden="true" tabindex="-1"></a>        report <span class="op">=</span> {</span>
<span id="cb31-75"><a href="#cb31-75" aria-hidden="true" tabindex="-1"></a>            <span class="st">"adapter_name"</span>: <span class="va">self</span>.adapter_name,</span>
<span id="cb31-76"><a href="#cb31-76" aria-hidden="true" tabindex="-1"></a>            <span class="st">"weight_analysis"</span>: weight_analysis,</span>
<span id="cb31-77"><a href="#cb31-77" aria-hidden="true" tabindex="-1"></a>            <span class="st">"rank_utilization"</span>: rank_utilization,</span>
<span id="cb31-78"><a href="#cb31-78" aria-hidden="true" tabindex="-1"></a>            <span class="st">"health_status"</span>: <span class="st">"healthy"</span> <span class="cf">if</span> <span class="kw">not</span> issues <span class="cf">else</span> <span class="st">"needs_attention"</span>,</span>
<span id="cb31-79"><a href="#cb31-79" aria-hidden="true" tabindex="-1"></a>            <span class="st">"issues"</span>: issues,</span>
<span id="cb31-80"><a href="#cb31-80" aria-hidden="true" tabindex="-1"></a>            <span class="st">"warnings"</span>: warnings,</span>
<span id="cb31-81"><a href="#cb31-81" aria-hidden="true" tabindex="-1"></a>            <span class="st">"recommendations"</span>: <span class="va">self</span>._generate_recommendations(issues, warnings)</span>
<span id="cb31-82"><a href="#cb31-82" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb31-83"><a href="#cb31-83" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-84"><a href="#cb31-84" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> report</span>
<span id="cb31-85"><a href="#cb31-85" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-86"><a href="#cb31-86" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _generate_recommendations(<span class="va">self</span>, issues, warnings):</span>
<span id="cb31-87"><a href="#cb31-87" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Generate recommendations based on analysis"""</span></span>
<span id="cb31-88"><a href="#cb31-88" aria-hidden="true" tabindex="-1"></a>        recommendations <span class="op">=</span> []</span>
<span id="cb31-89"><a href="#cb31-89" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-90"><a href="#cb31-90" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">any</span>(<span class="st">"rank utilization"</span> <span class="kw">in</span> issue <span class="cf">for</span> issue <span class="kw">in</span> issues):</span>
<span id="cb31-91"><a href="#cb31-91" aria-hidden="true" tabindex="-1"></a>            recommendations.append(<span class="st">"Consider reducing LoRA rank to improve efficiency"</span>)</span>
<span id="cb31-92"><a href="#cb31-92" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-93"><a href="#cb31-93" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">any</span>(<span class="st">"weight norms"</span> <span class="kw">in</span> warning <span class="cf">for</span> warning <span class="kw">in</span> warnings):</span>
<span id="cb31-94"><a href="#cb31-94" aria-hidden="true" tabindex="-1"></a>            recommendations.append(<span class="st">"Apply stronger weight regularization or gradient clipping"</span>)</span>
<span id="cb31-95"><a href="#cb31-95" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-96"><a href="#cb31-96" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">any</span>(<span class="st">"variance"</span> <span class="kw">in</span> warning <span class="cf">for</span> warning <span class="kw">in</span> warnings):</span>
<span id="cb31-97"><a href="#cb31-97" aria-hidden="true" tabindex="-1"></a>            recommendations.append(<span class="st">"Use different ranks for different module types"</span>)</span>
<span id="cb31-98"><a href="#cb31-98" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-99"><a href="#cb31-99" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> issues <span class="kw">and</span> <span class="kw">not</span> warnings:</span>
<span id="cb31-100"><a href="#cb31-100" aria-hidden="true" tabindex="-1"></a>            recommendations.append(<span class="st">"LoRA configuration appears optimal"</span>)</span>
<span id="cb31-101"><a href="#cb31-101" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-102"><a href="#cb31-102" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> recommendations</span>
<span id="cb31-103"><a href="#cb31-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-104"><a href="#cb31-104" aria-hidden="true" tabindex="-1"></a><span class="co"># Debugging demonstration</span></span>
<span id="cb31-105"><a href="#cb31-105" aria-hidden="true" tabindex="-1"></a>debugger <span class="op">=</span> LoRADebugger(<span class="va">None</span>, <span class="st">"medical_vqa_adapter"</span>)  <span class="co"># Would use real model</span></span>
<span id="cb31-106"><a href="#cb31-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-107"><a href="#cb31-107" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"LoRA Debugging Analysis:"</span>)</span>
<span id="cb31-108"><a href="#cb31-108" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">25</span>)</span>
<span id="cb31-109"><a href="#cb31-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-110"><a href="#cb31-110" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate health report</span></span>
<span id="cb31-111"><a href="#cb31-111" aria-hidden="true" tabindex="-1"></a>health_report <span class="op">=</span> debugger.generate_health_report()</span>
<span id="cb31-112"><a href="#cb31-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-113"><a href="#cb31-113" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Adapter: </span><span class="sc">{</span>health_report[<span class="st">'adapter_name'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb31-114"><a href="#cb31-114" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Health Status: </span><span class="sc">{</span>health_report[<span class="st">'health_status'</span>]<span class="sc">.</span>title()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb31-115"><a href="#cb31-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-116"><a href="#cb31-116" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Rank Utilization Summary:"</span>)</span>
<span id="cb31-117"><a href="#cb31-117" aria-hidden="true" tabindex="-1"></a>rank_util <span class="op">=</span> health_report[<span class="st">'rank_utilization'</span>]</span>
<span id="cb31-118"><a href="#cb31-118" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Mean: </span><span class="sc">{</span>rank_util[<span class="st">'mean_utilization'</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb31-119"><a href="#cb31-119" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Std:  </span><span class="sc">{</span>rank_util[<span class="st">'std_utilization'</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb31-120"><a href="#cb31-120" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Range: </span><span class="sc">{</span>rank_util[<span class="st">'min_utilization'</span>]<span class="sc">:.3f}</span><span class="ss"> - </span><span class="sc">{</span>rank_util[<span class="st">'max_utilization'</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb31-121"><a href="#cb31-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-122"><a href="#cb31-122" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> health_report[<span class="st">'issues'</span>]:</span>
<span id="cb31-123"><a href="#cb31-123" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Issues Found:"</span>)</span>
<span id="cb31-124"><a href="#cb31-124" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> issue <span class="kw">in</span> health_report[<span class="st">'issues'</span>]:</span>
<span id="cb31-125"><a href="#cb31-125" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  ❌ </span><span class="sc">{</span>issue<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb31-126"><a href="#cb31-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-127"><a href="#cb31-127" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> health_report[<span class="st">'warnings'</span>]:</span>
<span id="cb31-128"><a href="#cb31-128" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Warnings:"</span>)</span>
<span id="cb31-129"><a href="#cb31-129" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> warning <span class="kw">in</span> health_report[<span class="st">'warnings'</span>]:</span>
<span id="cb31-130"><a href="#cb31-130" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  ⚠️  </span><span class="sc">{</span>warning<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb31-131"><a href="#cb31-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-132"><a href="#cb31-132" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Recommendations:"</span>)</span>
<span id="cb31-133"><a href="#cb31-133" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> rec <span class="kw">in</span> health_report[<span class="st">'recommendations'</span>]:</span>
<span id="cb31-134"><a href="#cb31-134" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  💡 </span><span class="sc">{</span>rec<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>LoRA Debugging Analysis:
=========================
Adapter: medical_vqa_adapter
Health Status: Healthy

Rank Utilization Summary:
  Mean: 0.738
  Std:  0.218
  Range: 0.312 - 0.938

Recommendations:
  💡 LoRA configuration appears optimal</code></pre>
</div>
</div>
</section>
</section>
<section id="production-deployment" class="level2">
<h2 class="anchored" data-anchor-id="production-deployment">Production Deployment</h2>
<section id="model-management-system" class="level3">
<h3 class="anchored" data-anchor-id="model-management-system">Model Management System</h3>
<div id="production-deployment" class="cell" data-execution_count="23">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Dict, Any, Optional, Union</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> contextlib <span class="im">import</span> contextmanager</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> logging</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LoRAModelManager:</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Production-ready LoRA model management system"""</span></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, base_model_path: <span class="bu">str</span>, device: <span class="bu">str</span> <span class="op">=</span> <span class="st">"auto"</span>):</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.base_model_path <span class="op">=</span> base_model_path</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.device <span class="op">=</span> <span class="va">self</span>._setup_device(device)</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.base_model <span class="op">=</span> <span class="va">None</span></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.active_adapters <span class="op">=</span> {}</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.adapter_configs <span class="op">=</span> {}</span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Performance monitoring</span></span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.request_count <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.total_inference_time <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.error_count <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Setup logging</span></span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>        logging.basicConfig(level<span class="op">=</span>logging.INFO)</span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.logger <span class="op">=</span> logging.getLogger(<span class="va">__name__</span>)</span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"LoRA Model Manager initialized"</span>)</span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Device: </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>device<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _setup_device(<span class="va">self</span>, device: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Setup compute device"""</span></span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> device <span class="op">==</span> <span class="st">"auto"</span>:</span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> torch.cuda.is_available():</span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span> <span class="st">"cuda"</span></span>
<span id="cb33-33"><a href="#cb33-33" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb33-34"><a href="#cb33-34" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span> <span class="st">"cpu"</span></span>
<span id="cb33-35"><a href="#cb33-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> device</span>
<span id="cb33-36"><a href="#cb33-36" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-37"><a href="#cb33-37" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> load_adapter(<span class="va">self</span>, adapter_name: <span class="bu">str</span>, adapter_path: <span class="bu">str</span>, config: Optional[Dict] <span class="op">=</span> <span class="va">None</span>):</span>
<span id="cb33-38"><a href="#cb33-38" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Load a LoRA adapter"""</span></span>
<span id="cb33-39"><a href="#cb33-39" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.logger.info(<span class="ss">f"Loading adapter '</span><span class="sc">{</span>adapter_name<span class="sc">}</span><span class="ss">' from </span><span class="sc">{</span>adapter_path<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-40"><a href="#cb33-40" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-41"><a href="#cb33-41" aria-hidden="true" tabindex="-1"></a>        default_config <span class="op">=</span> {</span>
<span id="cb33-42"><a href="#cb33-42" aria-hidden="true" tabindex="-1"></a>            <span class="st">"rank"</span>: <span class="dv">16</span>,</span>
<span id="cb33-43"><a href="#cb33-43" aria-hidden="true" tabindex="-1"></a>            <span class="st">"alpha"</span>: <span class="dv">16</span>,</span>
<span id="cb33-44"><a href="#cb33-44" aria-hidden="true" tabindex="-1"></a>            <span class="st">"target_modules"</span>: [<span class="st">"q_proj"</span>, <span class="st">"k_proj"</span>, <span class="st">"v_proj"</span>],</span>
<span id="cb33-45"><a href="#cb33-45" aria-hidden="true" tabindex="-1"></a>            <span class="st">"task_type"</span>: <span class="st">"multimodal"</span></span>
<span id="cb33-46"><a href="#cb33-46" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb33-47"><a href="#cb33-47" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-48"><a href="#cb33-48" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Merge defaults with provided config</span></span>
<span id="cb33-49"><a href="#cb33-49" aria-hidden="true" tabindex="-1"></a>        adapter_config <span class="op">=</span> {<span class="op">**</span>default_config, <span class="op">**</span>(config <span class="kw">or</span> {})}</span>
<span id="cb33-50"><a href="#cb33-50" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-51"><a href="#cb33-51" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Store adapter (in real implementation, would load actual weights)</span></span>
<span id="cb33-52"><a href="#cb33-52" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.active_adapters[adapter_name] <span class="op">=</span> {</span>
<span id="cb33-53"><a href="#cb33-53" aria-hidden="true" tabindex="-1"></a>            <span class="st">"path"</span>: adapter_path,</span>
<span id="cb33-54"><a href="#cb33-54" aria-hidden="true" tabindex="-1"></a>            <span class="st">"loaded_at"</span>: time.time(),</span>
<span id="cb33-55"><a href="#cb33-55" aria-hidden="true" tabindex="-1"></a>            <span class="st">"parameters"</span>: adapter_config[<span class="st">"rank"</span>] <span class="op">*</span> <span class="dv">768</span> <span class="op">*</span> <span class="dv">2</span> <span class="op">*</span> <span class="bu">len</span>(adapter_config[<span class="st">"target_modules"</span>])</span>
<span id="cb33-56"><a href="#cb33-56" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb33-57"><a href="#cb33-57" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.adapter_configs[adapter_name] <span class="op">=</span> adapter_config</span>
<span id="cb33-58"><a href="#cb33-58" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-59"><a href="#cb33-59" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.logger.info(<span class="ss">f"Adapter '</span><span class="sc">{</span>adapter_name<span class="sc">}</span><span class="ss">' loaded successfully"</span>)</span>
<span id="cb33-60"><a href="#cb33-60" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">True</span></span>
<span id="cb33-61"><a href="#cb33-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-62"><a href="#cb33-62" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-63"><a href="#cb33-63" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> unload_adapter(<span class="va">self</span>, adapter_name: <span class="bu">str</span>):</span>
<span id="cb33-64"><a href="#cb33-64" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Unload a LoRA adapter to free memory"""</span></span>
<span id="cb33-65"><a href="#cb33-65" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> adapter_name <span class="kw">in</span> <span class="va">self</span>.active_adapters:</span>
<span id="cb33-66"><a href="#cb33-66" aria-hidden="true" tabindex="-1"></a>            <span class="kw">del</span> <span class="va">self</span>.active_adapters[adapter_name]</span>
<span id="cb33-67"><a href="#cb33-67" aria-hidden="true" tabindex="-1"></a>            <span class="kw">del</span> <span class="va">self</span>.adapter_configs[adapter_name]</span>
<span id="cb33-68"><a href="#cb33-68" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.logger.info(<span class="ss">f"Adapter '</span><span class="sc">{</span>adapter_name<span class="sc">}</span><span class="ss">' unloaded"</span>)</span>
<span id="cb33-69"><a href="#cb33-69" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">True</span></span>
<span id="cb33-70"><a href="#cb33-70" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb33-71"><a href="#cb33-71" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.logger.warning(<span class="ss">f"Adapter '</span><span class="sc">{</span>adapter_name<span class="sc">}</span><span class="ss">' not found"</span>)</span>
<span id="cb33-72"><a href="#cb33-72" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">False</span></span>
<span id="cb33-73"><a href="#cb33-73" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-74"><a href="#cb33-74" aria-hidden="true" tabindex="-1"></a>    <span class="at">@contextmanager</span></span>
<span id="cb33-75"><a href="#cb33-75" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> use_adapter(<span class="va">self</span>, adapter_name: <span class="bu">str</span>):</span>
<span id="cb33-76"><a href="#cb33-76" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Context manager for temporarily using an adapter"""</span></span>
<span id="cb33-77"><a href="#cb33-77" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> adapter_name <span class="kw">not</span> <span class="kw">in</span> <span class="va">self</span>.active_adapters:</span>
<span id="cb33-78"><a href="#cb33-78" aria-hidden="true" tabindex="-1"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"Adapter '</span><span class="sc">{</span>adapter_name<span class="sc">}</span><span class="ss">' not loaded"</span>)</span>
<span id="cb33-79"><a href="#cb33-79" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-80"><a href="#cb33-80" aria-hidden="true" tabindex="-1"></a>        <span class="co"># In real implementation, would apply adapter weights</span></span>
<span id="cb33-81"><a href="#cb33-81" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.logger.debug(<span class="ss">f"Applying adapter '</span><span class="sc">{</span>adapter_name<span class="sc">}</span><span class="ss">'"</span>)</span>
<span id="cb33-82"><a href="#cb33-82" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-83"><a href="#cb33-83" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb33-84"><a href="#cb33-84" aria-hidden="true" tabindex="-1"></a>            <span class="cf">yield</span> adapter_name</span>
<span id="cb33-85"><a href="#cb33-85" aria-hidden="true" tabindex="-1"></a>        <span class="cf">finally</span>:</span>
<span id="cb33-86"><a href="#cb33-86" aria-hidden="true" tabindex="-1"></a>            <span class="co"># In real implementation, would restore original weights</span></span>
<span id="cb33-87"><a href="#cb33-87" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.logger.debug(<span class="ss">f"Restored from adapter '</span><span class="sc">{</span>adapter_name<span class="sc">}</span><span class="ss">'"</span>)</span>
<span id="cb33-88"><a href="#cb33-88" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-89"><a href="#cb33-89" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> inference(<span class="va">self</span>, inputs: Dict[<span class="bu">str</span>, Any], adapter_name: Optional[<span class="bu">str</span>] <span class="op">=</span> <span class="va">None</span>) <span class="op">-&gt;</span> Dict[<span class="bu">str</span>, Any]:</span>
<span id="cb33-90"><a href="#cb33-90" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Perform inference with optional adapter"""</span></span>
<span id="cb33-91"><a href="#cb33-91" aria-hidden="true" tabindex="-1"></a>        start_time <span class="op">=</span> time.time()</span>
<span id="cb33-92"><a href="#cb33-92" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-93"><a href="#cb33-93" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb33-94"><a href="#cb33-94" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> adapter_name:</span>
<span id="cb33-95"><a href="#cb33-95" aria-hidden="true" tabindex="-1"></a>                <span class="cf">with</span> <span class="va">self</span>.use_adapter(adapter_name):</span>
<span id="cb33-96"><a href="#cb33-96" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># Simulate inference with adapter</span></span>
<span id="cb33-97"><a href="#cb33-97" aria-hidden="true" tabindex="-1"></a>                    time.sleep(<span class="fl">0.01</span>)  <span class="co"># Simulate processing time</span></span>
<span id="cb33-98"><a href="#cb33-98" aria-hidden="true" tabindex="-1"></a>                    outputs <span class="op">=</span> {<span class="st">"prediction"</span>: <span class="st">"sample_output"</span>, <span class="st">"confidence"</span>: <span class="fl">0.95</span>}</span>
<span id="cb33-99"><a href="#cb33-99" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb33-100"><a href="#cb33-100" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Simulate base model inference</span></span>
<span id="cb33-101"><a href="#cb33-101" aria-hidden="true" tabindex="-1"></a>                time.sleep(<span class="fl">0.008</span>)  <span class="co"># Slightly faster without adapter</span></span>
<span id="cb33-102"><a href="#cb33-102" aria-hidden="true" tabindex="-1"></a>                outputs <span class="op">=</span> {<span class="st">"prediction"</span>: <span class="st">"base_output"</span>, <span class="st">"confidence"</span>: <span class="fl">0.85</span>}</span>
<span id="cb33-103"><a href="#cb33-103" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb33-104"><a href="#cb33-104" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Update performance metrics</span></span>
<span id="cb33-105"><a href="#cb33-105" aria-hidden="true" tabindex="-1"></a>            inference_time <span class="op">=</span> time.time() <span class="op">-</span> start_time</span>
<span id="cb33-106"><a href="#cb33-106" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.request_count <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb33-107"><a href="#cb33-107" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.total_inference_time <span class="op">+=</span> inference_time</span>
<span id="cb33-108"><a href="#cb33-108" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb33-109"><a href="#cb33-109" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> {</span>
<span id="cb33-110"><a href="#cb33-110" aria-hidden="true" tabindex="-1"></a>                <span class="st">'outputs'</span>: outputs,</span>
<span id="cb33-111"><a href="#cb33-111" aria-hidden="true" tabindex="-1"></a>                <span class="st">'inference_time'</span>: inference_time,</span>
<span id="cb33-112"><a href="#cb33-112" aria-hidden="true" tabindex="-1"></a>                <span class="st">'adapter_used'</span>: adapter_name,</span>
<span id="cb33-113"><a href="#cb33-113" aria-hidden="true" tabindex="-1"></a>                <span class="st">'request_id'</span>: <span class="va">self</span>.request_count</span>
<span id="cb33-114"><a href="#cb33-114" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb33-115"><a href="#cb33-115" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb33-116"><a href="#cb33-116" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb33-117"><a href="#cb33-117" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.error_count <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb33-118"><a href="#cb33-118" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.logger.error(<span class="ss">f"Inference failed: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-119"><a href="#cb33-119" aria-hidden="true" tabindex="-1"></a>            <span class="cf">raise</span></span>
<span id="cb33-120"><a href="#cb33-120" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-121"><a href="#cb33-121" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_performance_stats(<span class="va">self</span>) <span class="op">-&gt;</span> Dict[<span class="bu">str</span>, <span class="bu">float</span>]:</span>
<span id="cb33-122"><a href="#cb33-122" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Get performance statistics"""</span></span>
<span id="cb33-123"><a href="#cb33-123" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.request_count <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb33-124"><a href="#cb33-124" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> {<span class="st">'requests'</span>: <span class="dv">0</span>, <span class="st">'avg_time'</span>: <span class="dv">0</span>, <span class="st">'total_time'</span>: <span class="dv">0</span>, <span class="st">'error_rate'</span>: <span class="dv">0</span>}</span>
<span id="cb33-125"><a href="#cb33-125" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-126"><a href="#cb33-126" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {</span>
<span id="cb33-127"><a href="#cb33-127" aria-hidden="true" tabindex="-1"></a>            <span class="st">'requests'</span>: <span class="va">self</span>.request_count,</span>
<span id="cb33-128"><a href="#cb33-128" aria-hidden="true" tabindex="-1"></a>            <span class="st">'avg_time'</span>: <span class="va">self</span>.total_inference_time <span class="op">/</span> <span class="va">self</span>.request_count,</span>
<span id="cb33-129"><a href="#cb33-129" aria-hidden="true" tabindex="-1"></a>            <span class="st">'total_time'</span>: <span class="va">self</span>.total_inference_time,</span>
<span id="cb33-130"><a href="#cb33-130" aria-hidden="true" tabindex="-1"></a>            <span class="st">'requests_per_second'</span>: <span class="va">self</span>.request_count <span class="op">/</span> <span class="va">self</span>.total_inference_time <span class="cf">if</span> <span class="va">self</span>.total_inference_time <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="dv">0</span>,</span>
<span id="cb33-131"><a href="#cb33-131" aria-hidden="true" tabindex="-1"></a>            <span class="st">'error_rate'</span>: <span class="va">self</span>.error_count <span class="op">/</span> <span class="va">self</span>.request_count,</span>
<span id="cb33-132"><a href="#cb33-132" aria-hidden="true" tabindex="-1"></a>            <span class="st">'error_count'</span>: <span class="va">self</span>.error_count</span>
<span id="cb33-133"><a href="#cb33-133" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb33-134"><a href="#cb33-134" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-135"><a href="#cb33-135" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> health_check(<span class="va">self</span>) <span class="op">-&gt;</span> Dict[<span class="bu">str</span>, Any]:</span>
<span id="cb33-136"><a href="#cb33-136" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Perform system health check"""</span></span>
<span id="cb33-137"><a href="#cb33-137" aria-hidden="true" tabindex="-1"></a>        health_status <span class="op">=</span> {</span>
<span id="cb33-138"><a href="#cb33-138" aria-hidden="true" tabindex="-1"></a>            <span class="st">'status'</span>: <span class="st">'healthy'</span>,</span>
<span id="cb33-139"><a href="#cb33-139" aria-hidden="true" tabindex="-1"></a>            <span class="st">'active_adapters'</span>: <span class="bu">list</span>(<span class="va">self</span>.active_adapters.keys()),</span>
<span id="cb33-140"><a href="#cb33-140" aria-hidden="true" tabindex="-1"></a>            <span class="st">'device'</span>: <span class="bu">str</span>(<span class="va">self</span>.device),</span>
<span id="cb33-141"><a href="#cb33-141" aria-hidden="true" tabindex="-1"></a>            <span class="st">'performance'</span>: <span class="va">self</span>.get_performance_stats(),</span>
<span id="cb33-142"><a href="#cb33-142" aria-hidden="true" tabindex="-1"></a>            <span class="st">'memory_usage'</span>: <span class="va">self</span>._get_memory_usage()</span>
<span id="cb33-143"><a href="#cb33-143" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb33-144"><a href="#cb33-144" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-145"><a href="#cb33-145" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check for issues</span></span>
<span id="cb33-146"><a href="#cb33-146" aria-hidden="true" tabindex="-1"></a>        perf_stats <span class="op">=</span> health_status[<span class="st">'performance'</span>]</span>
<span id="cb33-147"><a href="#cb33-147" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> perf_stats[<span class="st">'error_rate'</span>] <span class="op">&gt;</span> <span class="fl">0.05</span>:  <span class="co"># 5% error threshold</span></span>
<span id="cb33-148"><a href="#cb33-148" aria-hidden="true" tabindex="-1"></a>            health_status[<span class="st">'status'</span>] <span class="op">=</span> <span class="st">'degraded'</span></span>
<span id="cb33-149"><a href="#cb33-149" aria-hidden="true" tabindex="-1"></a>            health_status[<span class="st">'issues'</span>] <span class="op">=</span> [<span class="st">'High error rate detected'</span>]</span>
<span id="cb33-150"><a href="#cb33-150" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-151"><a href="#cb33-151" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> perf_stats[<span class="st">'avg_time'</span>] <span class="op">&gt;</span> <span class="fl">1.0</span>:  <span class="co"># 1 second threshold</span></span>
<span id="cb33-152"><a href="#cb33-152" aria-hidden="true" tabindex="-1"></a>            health_status[<span class="st">'status'</span>] <span class="op">=</span> <span class="st">'degraded'</span></span>
<span id="cb33-153"><a href="#cb33-153" aria-hidden="true" tabindex="-1"></a>            health_status.setdefault(<span class="st">'issues'</span>, []).append(<span class="st">'High latency detected'</span>)</span>
<span id="cb33-154"><a href="#cb33-154" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-155"><a href="#cb33-155" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> health_status</span>
<span id="cb33-156"><a href="#cb33-156" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-157"><a href="#cb33-157" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _get_memory_usage(<span class="va">self</span>):</span>
<span id="cb33-158"><a href="#cb33-158" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Get memory usage statistics"""</span></span>
<span id="cb33-159"><a href="#cb33-159" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Simulate memory usage</span></span>
<span id="cb33-160"><a href="#cb33-160" aria-hidden="true" tabindex="-1"></a>        total_adapters <span class="op">=</span> <span class="bu">len</span>(<span class="va">self</span>.active_adapters)</span>
<span id="cb33-161"><a href="#cb33-161" aria-hidden="true" tabindex="-1"></a>        estimated_memory <span class="op">=</span> total_adapters <span class="op">*</span> <span class="fl">0.1</span>  <span class="co"># GB per adapter</span></span>
<span id="cb33-162"><a href="#cb33-162" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-163"><a href="#cb33-163" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {</span>
<span id="cb33-164"><a href="#cb33-164" aria-hidden="true" tabindex="-1"></a>            <span class="st">'estimated_adapter_memory_gb'</span>: estimated_memory,</span>
<span id="cb33-165"><a href="#cb33-165" aria-hidden="true" tabindex="-1"></a>            <span class="st">'active_adapters'</span>: total_adapters</span>
<span id="cb33-166"><a href="#cb33-166" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb33-167"><a href="#cb33-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-168"><a href="#cb33-168" aria-hidden="true" tabindex="-1"></a><span class="co"># Production deployment demonstration</span></span>
<span id="cb33-169"><a href="#cb33-169" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Production LoRA Deployment Demo:"</span>)</span>
<span id="cb33-170"><a href="#cb33-170" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">35</span>)</span>
<span id="cb33-171"><a href="#cb33-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-172"><a href="#cb33-172" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize model manager</span></span>
<span id="cb33-173"><a href="#cb33-173" aria-hidden="true" tabindex="-1"></a>manager <span class="op">=</span> LoRAModelManager(<span class="st">"path/to/base/model"</span>, device<span class="op">=</span><span class="st">"cuda"</span>)</span>
<span id="cb33-174"><a href="#cb33-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-175"><a href="#cb33-175" aria-hidden="true" tabindex="-1"></a><span class="co"># Load multiple adapters</span></span>
<span id="cb33-176"><a href="#cb33-176" aria-hidden="true" tabindex="-1"></a>adapters_to_load <span class="op">=</span> [</span>
<span id="cb33-177"><a href="#cb33-177" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"name"</span>: <span class="st">"medical_adapter"</span>, <span class="st">"path"</span>: <span class="st">"adapters/medical"</span>, <span class="st">"config"</span>: {<span class="st">"rank"</span>: <span class="dv">32</span>, <span class="st">"task"</span>: <span class="st">"medical_vqa"</span>}},</span>
<span id="cb33-178"><a href="#cb33-178" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"name"</span>: <span class="st">"general_adapter"</span>, <span class="st">"path"</span>: <span class="st">"adapters/general"</span>, <span class="st">"config"</span>: {<span class="st">"rank"</span>: <span class="dv">16</span>, <span class="st">"task"</span>: <span class="st">"general_vqa"</span>}},</span>
<span id="cb33-179"><a href="#cb33-179" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"name"</span>: <span class="st">"multilingual_adapter"</span>, <span class="st">"path"</span>: <span class="st">"adapters/multilingual"</span>, <span class="st">"config"</span>: {<span class="st">"rank"</span>: <span class="dv">24</span>, <span class="st">"task"</span>: <span class="st">"multilingual"</span>}}</span>
<span id="cb33-180"><a href="#cb33-180" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb33-181"><a href="#cb33-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-182"><a href="#cb33-182" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> adapter <span class="kw">in</span> adapters_to_load:</span>
<span id="cb33-183"><a href="#cb33-183" aria-hidden="true" tabindex="-1"></a>    manager.load_adapter(adapter[<span class="st">"name"</span>], adapter[<span class="st">"path"</span>], adapter[<span class="st">"config"</span>])</span>
<span id="cb33-184"><a href="#cb33-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-185"><a href="#cb33-185" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Loaded </span><span class="sc">{</span><span class="bu">len</span>(manager.active_adapters)<span class="sc">}</span><span class="ss"> adapters"</span>)</span>
<span id="cb33-186"><a href="#cb33-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-187"><a href="#cb33-187" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate inference requests</span></span>
<span id="cb33-188"><a href="#cb33-188" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Simulating inference requests..."</span>)</span>
<span id="cb33-189"><a href="#cb33-189" aria-hidden="true" tabindex="-1"></a>test_inputs <span class="op">=</span> {<span class="st">"image"</span>: <span class="st">"test_image.jpg"</span>, <span class="st">"text"</span>: <span class="st">"What is in this image?"</span>}</span>
<span id="cb33-190"><a href="#cb33-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-191"><a href="#cb33-191" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb33-192"><a href="#cb33-192" aria-hidden="true" tabindex="-1"></a>    adapter <span class="op">=</span> [<span class="st">"medical_adapter"</span>, <span class="st">"general_adapter"</span>, <span class="va">None</span>][i <span class="op">%</span> <span class="dv">3</span>]</span>
<span id="cb33-193"><a href="#cb33-193" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> manager.inference(test_inputs, adapter)</span>
<span id="cb33-194"><a href="#cb33-194" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Request </span><span class="sc">{</span>result[<span class="st">'request_id'</span>]<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>result[<span class="st">'inference_time'</span>]<span class="sc">:.3f}</span><span class="ss">s (</span><span class="sc">{</span><span class="st">'with '</span> <span class="op">+</span> result[<span class="st">'adapter_used'</span>] <span class="cf">if</span> result[<span class="st">'adapter_used'</span>] <span class="cf">else</span> <span class="st">'base model'</span><span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb33-195"><a href="#cb33-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-196"><a href="#cb33-196" aria-hidden="true" tabindex="-1"></a><span class="co"># Check system health</span></span>
<span id="cb33-197"><a href="#cb33-197" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">System Health Check:"</span>)</span>
<span id="cb33-198"><a href="#cb33-198" aria-hidden="true" tabindex="-1"></a>health <span class="op">=</span> manager.health_check()</span>
<span id="cb33-199"><a href="#cb33-199" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Status: </span><span class="sc">{</span>health[<span class="st">'status'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-200"><a href="#cb33-200" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Active adapters: </span><span class="sc">{</span><span class="bu">len</span>(health[<span class="st">'active_adapters'</span>])<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-201"><a href="#cb33-201" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Average latency: </span><span class="sc">{</span>health[<span class="st">'performance'</span>][<span class="st">'avg_time'</span>]<span class="sc">:.3f}</span><span class="ss">s"</span>)</span>
<span id="cb33-202"><a href="#cb33-202" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Error rate: </span><span class="sc">{</span>health[<span class="st">'performance'</span>][<span class="st">'error_rate'</span>]<span class="sc">:.1%}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>INFO:__main__:Loading adapter 'medical_adapter' from adapters/medical
INFO:__main__:Adapter 'medical_adapter' loaded successfully
INFO:__main__:Loading adapter 'general_adapter' from adapters/general
INFO:__main__:Adapter 'general_adapter' loaded successfully
INFO:__main__:Loading adapter 'multilingual_adapter' from adapters/multilingual
INFO:__main__:Adapter 'multilingual_adapter' loaded successfully</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Production LoRA Deployment Demo:
===================================
LoRA Model Manager initialized
Device: cuda

Loaded 3 adapters

Simulating inference requests...
Request 1: 0.013s (with medical_adapter)
Request 2: 0.013s (with general_adapter)
Request 3: 0.008s (base model)
Request 4: 0.011s (with medical_adapter)
Request 5: 0.010s (with general_adapter)

System Health Check:
Status: healthy
Active adapters: 3
Average latency: 0.011s
Error rate: 0.0%</code></pre>
</div>
</div>
</section>
<section id="api-server-implementation" class="level3">
<h3 class="anchored" data-anchor-id="api-server-implementation">API Server Implementation</h3>
<div id="api-server" class="cell" data-execution_count="24">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LoRAAPIServer:</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""FastAPI-style server for LoRA model serving"""</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, model_manager: LoRAModelManager):</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model_manager <span class="op">=</span> model_manager</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.request_history <span class="op">=</span> []</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"LoRA API Server initialized"</span>)</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Available endpoints:"</span>)</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"  POST /inference - Perform inference"</span>)</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"  POST /load_adapter - Load new adapter"</span>)</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"  DELETE /adapter/</span><span class="sc">{name}</span><span class="st"> - Unload adapter"</span>)</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"  GET /health - Health check"</span>)</span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"  GET /adapters - List adapters"</span>)</span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> inference_endpoint(<span class="va">self</span>, request_data: Dict[<span class="bu">str</span>, Any]) <span class="op">-&gt;</span> Dict[<span class="bu">str</span>, Any]:</span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Handle inference requests"""</span></span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a>            inputs <span class="op">=</span> request_data.get(<span class="st">"inputs"</span>, {})</span>
<span id="cb36-20"><a href="#cb36-20" aria-hidden="true" tabindex="-1"></a>            adapter_name <span class="op">=</span> request_data.get(<span class="st">"adapter_name"</span>)</span>
<span id="cb36-21"><a href="#cb36-21" aria-hidden="true" tabindex="-1"></a>            parameters <span class="op">=</span> request_data.get(<span class="st">"parameters"</span>, {})</span>
<span id="cb36-22"><a href="#cb36-22" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb36-23"><a href="#cb36-23" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Perform inference</span></span>
<span id="cb36-24"><a href="#cb36-24" aria-hidden="true" tabindex="-1"></a>            result <span class="op">=</span> <span class="va">self</span>.model_manager.inference(inputs, adapter_name)</span>
<span id="cb36-25"><a href="#cb36-25" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb36-26"><a href="#cb36-26" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Log request</span></span>
<span id="cb36-27"><a href="#cb36-27" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.request_history.append({</span>
<span id="cb36-28"><a href="#cb36-28" aria-hidden="true" tabindex="-1"></a>                <span class="st">"timestamp"</span>: time.time(),</span>
<span id="cb36-29"><a href="#cb36-29" aria-hidden="true" tabindex="-1"></a>                <span class="st">"adapter"</span>: adapter_name,</span>
<span id="cb36-30"><a href="#cb36-30" aria-hidden="true" tabindex="-1"></a>                <span class="st">"latency"</span>: result[<span class="st">"inference_time"</span>],</span>
<span id="cb36-31"><a href="#cb36-31" aria-hidden="true" tabindex="-1"></a>                <span class="st">"status"</span>: <span class="st">"success"</span></span>
<span id="cb36-32"><a href="#cb36-32" aria-hidden="true" tabindex="-1"></a>            })</span>
<span id="cb36-33"><a href="#cb36-33" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb36-34"><a href="#cb36-34" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> {</span>
<span id="cb36-35"><a href="#cb36-35" aria-hidden="true" tabindex="-1"></a>                <span class="st">"status"</span>: <span class="st">"success"</span>,</span>
<span id="cb36-36"><a href="#cb36-36" aria-hidden="true" tabindex="-1"></a>                <span class="st">"outputs"</span>: result[<span class="st">"outputs"</span>],</span>
<span id="cb36-37"><a href="#cb36-37" aria-hidden="true" tabindex="-1"></a>                <span class="st">"inference_time"</span>: result[<span class="st">"inference_time"</span>],</span>
<span id="cb36-38"><a href="#cb36-38" aria-hidden="true" tabindex="-1"></a>                <span class="st">"adapter_used"</span>: result[<span class="st">"adapter_used"</span>],</span>
<span id="cb36-39"><a href="#cb36-39" aria-hidden="true" tabindex="-1"></a>                <span class="st">"request_id"</span>: result[<span class="st">"request_id"</span>]</span>
<span id="cb36-40"><a href="#cb36-40" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb36-41"><a href="#cb36-41" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb36-42"><a href="#cb36-42" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb36-43"><a href="#cb36-43" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Log error</span></span>
<span id="cb36-44"><a href="#cb36-44" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.request_history.append({</span>
<span id="cb36-45"><a href="#cb36-45" aria-hidden="true" tabindex="-1"></a>                <span class="st">"timestamp"</span>: time.time(),</span>
<span id="cb36-46"><a href="#cb36-46" aria-hidden="true" tabindex="-1"></a>                <span class="st">"adapter"</span>: request_data.get(<span class="st">"adapter_name"</span>),</span>
<span id="cb36-47"><a href="#cb36-47" aria-hidden="true" tabindex="-1"></a>                <span class="st">"status"</span>: <span class="st">"error"</span>,</span>
<span id="cb36-48"><a href="#cb36-48" aria-hidden="true" tabindex="-1"></a>                <span class="st">"error"</span>: <span class="bu">str</span>(e)</span>
<span id="cb36-49"><a href="#cb36-49" aria-hidden="true" tabindex="-1"></a>            })</span>
<span id="cb36-50"><a href="#cb36-50" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb36-51"><a href="#cb36-51" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> {</span>
<span id="cb36-52"><a href="#cb36-52" aria-hidden="true" tabindex="-1"></a>                <span class="st">"status"</span>: <span class="st">"error"</span>,</span>
<span id="cb36-53"><a href="#cb36-53" aria-hidden="true" tabindex="-1"></a>                <span class="st">"error"</span>: <span class="bu">str</span>(e),</span>
<span id="cb36-54"><a href="#cb36-54" aria-hidden="true" tabindex="-1"></a>                <span class="st">"request_id"</span>: <span class="va">None</span></span>
<span id="cb36-55"><a href="#cb36-55" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb36-56"><a href="#cb36-56" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-57"><a href="#cb36-57" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> load_adapter_endpoint(<span class="va">self</span>, request_data: Dict[<span class="bu">str</span>, Any]) <span class="op">-&gt;</span> Dict[<span class="bu">str</span>, Any]:</span>
<span id="cb36-58"><a href="#cb36-58" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Handle adapter loading requests"""</span></span>
<span id="cb36-59"><a href="#cb36-59" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb36-60"><a href="#cb36-60" aria-hidden="true" tabindex="-1"></a>            adapter_name <span class="op">=</span> request_data[<span class="st">"adapter_name"</span>]</span>
<span id="cb36-61"><a href="#cb36-61" aria-hidden="true" tabindex="-1"></a>            adapter_path <span class="op">=</span> request_data[<span class="st">"adapter_path"</span>]</span>
<span id="cb36-62"><a href="#cb36-62" aria-hidden="true" tabindex="-1"></a>            config <span class="op">=</span> request_data.get(<span class="st">"config"</span>)</span>
<span id="cb36-63"><a href="#cb36-63" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb36-64"><a href="#cb36-64" aria-hidden="true" tabindex="-1"></a>            success <span class="op">=</span> <span class="va">self</span>.model_manager.load_adapter(adapter_name, adapter_path, config)</span>
<span id="cb36-65"><a href="#cb36-65" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb36-66"><a href="#cb36-66" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> success:</span>
<span id="cb36-67"><a href="#cb36-67" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span> {</span>
<span id="cb36-68"><a href="#cb36-68" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"status"</span>: <span class="st">"success"</span>,</span>
<span id="cb36-69"><a href="#cb36-69" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"message"</span>: <span class="ss">f"Adapter '</span><span class="sc">{</span>adapter_name<span class="sc">}</span><span class="ss">' loaded successfully"</span></span>
<span id="cb36-70"><a href="#cb36-70" aria-hidden="true" tabindex="-1"></a>                }</span>
<span id="cb36-71"><a href="#cb36-71" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb36-72"><a href="#cb36-72" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span> {</span>
<span id="cb36-73"><a href="#cb36-73" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"status"</span>: <span class="st">"error"</span>,</span>
<span id="cb36-74"><a href="#cb36-74" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"message"</span>: <span class="ss">f"Failed to load adapter '</span><span class="sc">{</span>adapter_name<span class="sc">}</span><span class="ss">'"</span></span>
<span id="cb36-75"><a href="#cb36-75" aria-hidden="true" tabindex="-1"></a>                }</span>
<span id="cb36-76"><a href="#cb36-76" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb36-77"><a href="#cb36-77" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb36-78"><a href="#cb36-78" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> {</span>
<span id="cb36-79"><a href="#cb36-79" aria-hidden="true" tabindex="-1"></a>                <span class="st">"status"</span>: <span class="st">"error"</span>,</span>
<span id="cb36-80"><a href="#cb36-80" aria-hidden="true" tabindex="-1"></a>                <span class="st">"message"</span>: <span class="bu">str</span>(e)</span>
<span id="cb36-81"><a href="#cb36-81" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb36-82"><a href="#cb36-82" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-83"><a href="#cb36-83" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> unload_adapter_endpoint(<span class="va">self</span>, adapter_name: <span class="bu">str</span>) <span class="op">-&gt;</span> Dict[<span class="bu">str</span>, Any]:</span>
<span id="cb36-84"><a href="#cb36-84" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Handle adapter unloading requests"""</span></span>
<span id="cb36-85"><a href="#cb36-85" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb36-86"><a href="#cb36-86" aria-hidden="true" tabindex="-1"></a>            success <span class="op">=</span> <span class="va">self</span>.model_manager.unload_adapter(adapter_name)</span>
<span id="cb36-87"><a href="#cb36-87" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb36-88"><a href="#cb36-88" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> success:</span>
<span id="cb36-89"><a href="#cb36-89" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span> {</span>
<span id="cb36-90"><a href="#cb36-90" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"status"</span>: <span class="st">"success"</span>, </span>
<span id="cb36-91"><a href="#cb36-91" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"message"</span>: <span class="ss">f"Adapter '</span><span class="sc">{</span>adapter_name<span class="sc">}</span><span class="ss">' unloaded successfully"</span></span>
<span id="cb36-92"><a href="#cb36-92" aria-hidden="true" tabindex="-1"></a>                }</span>
<span id="cb36-93"><a href="#cb36-93" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb36-94"><a href="#cb36-94" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span> {</span>
<span id="cb36-95"><a href="#cb36-95" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"status"</span>: <span class="st">"error"</span>,</span>
<span id="cb36-96"><a href="#cb36-96" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"message"</span>: <span class="ss">f"Adapter '</span><span class="sc">{</span>adapter_name<span class="sc">}</span><span class="ss">' not found"</span></span>
<span id="cb36-97"><a href="#cb36-97" aria-hidden="true" tabindex="-1"></a>                }</span>
<span id="cb36-98"><a href="#cb36-98" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb36-99"><a href="#cb36-99" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb36-100"><a href="#cb36-100" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> {</span>
<span id="cb36-101"><a href="#cb36-101" aria-hidden="true" tabindex="-1"></a>                <span class="st">"status"</span>: <span class="st">"error"</span>,</span>
<span id="cb36-102"><a href="#cb36-102" aria-hidden="true" tabindex="-1"></a>                <span class="st">"message"</span>: <span class="bu">str</span>(e)</span>
<span id="cb36-103"><a href="#cb36-103" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb36-104"><a href="#cb36-104" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-105"><a href="#cb36-105" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> health_endpoint(<span class="va">self</span>) <span class="op">-&gt;</span> Dict[<span class="bu">str</span>, Any]:</span>
<span id="cb36-106"><a href="#cb36-106" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Handle health check requests"""</span></span>
<span id="cb36-107"><a href="#cb36-107" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.model_manager.health_check()</span>
<span id="cb36-108"><a href="#cb36-108" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-109"><a href="#cb36-109" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> list_adapters_endpoint(<span class="va">self</span>) <span class="op">-&gt;</span> Dict[<span class="bu">str</span>, Any]:</span>
<span id="cb36-110"><a href="#cb36-110" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Handle adapter listing requests"""</span></span>
<span id="cb36-111"><a href="#cb36-111" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {</span>
<span id="cb36-112"><a href="#cb36-112" aria-hidden="true" tabindex="-1"></a>            <span class="st">"active_adapters"</span>: <span class="bu">list</span>(<span class="va">self</span>.model_manager.active_adapters.keys()),</span>
<span id="cb36-113"><a href="#cb36-113" aria-hidden="true" tabindex="-1"></a>            <span class="st">"adapter_configs"</span>: <span class="va">self</span>.model_manager.adapter_configs,</span>
<span id="cb36-114"><a href="#cb36-114" aria-hidden="true" tabindex="-1"></a>            <span class="st">"total_adapters"</span>: <span class="bu">len</span>(<span class="va">self</span>.model_manager.active_adapters)</span>
<span id="cb36-115"><a href="#cb36-115" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb36-116"><a href="#cb36-116" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-117"><a href="#cb36-117" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_metrics_endpoint(<span class="va">self</span>) <span class="op">-&gt;</span> Dict[<span class="bu">str</span>, Any]:</span>
<span id="cb36-118"><a href="#cb36-118" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Get detailed metrics"""</span></span>
<span id="cb36-119"><a href="#cb36-119" aria-hidden="true" tabindex="-1"></a>        recent_requests <span class="op">=</span> [req <span class="cf">for</span> req <span class="kw">in</span> <span class="va">self</span>.request_history </span>
<span id="cb36-120"><a href="#cb36-120" aria-hidden="true" tabindex="-1"></a>                          <span class="cf">if</span> time.time() <span class="op">-</span> req[<span class="st">"timestamp"</span>] <span class="op">&lt;</span> <span class="dv">3600</span>]  <span class="co"># Last hour</span></span>
<span id="cb36-121"><a href="#cb36-121" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb36-122"><a href="#cb36-122" aria-hidden="true" tabindex="-1"></a>        success_requests <span class="op">=</span> [req <span class="cf">for</span> req <span class="kw">in</span> recent_requests <span class="cf">if</span> req[<span class="st">"status"</span>] <span class="op">==</span> <span class="st">"success"</span>]</span>
<span id="cb36-123"><a href="#cb36-123" aria-hidden="true" tabindex="-1"></a>        error_requests <span class="op">=</span> [req <span class="cf">for</span> req <span class="kw">in</span> recent_requests <span class="cf">if</span> req[<span class="st">"status"</span>] <span class="op">==</span> <span class="st">"error"</span>]</span>
<span id="cb36-124"><a href="#cb36-124" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb36-125"><a href="#cb36-125" aria-hidden="true" tabindex="-1"></a>        metrics <span class="op">=</span> {</span>
<span id="cb36-126"><a href="#cb36-126" aria-hidden="true" tabindex="-1"></a>            <span class="st">"total_requests_last_hour"</span>: <span class="bu">len</span>(recent_requests),</span>
<span id="cb36-127"><a href="#cb36-127" aria-hidden="true" tabindex="-1"></a>            <span class="st">"successful_requests"</span>: <span class="bu">len</span>(success_requests),</span>
<span id="cb36-128"><a href="#cb36-128" aria-hidden="true" tabindex="-1"></a>            <span class="st">"failed_requests"</span>: <span class="bu">len</span>(error_requests),</span>
<span id="cb36-129"><a href="#cb36-129" aria-hidden="true" tabindex="-1"></a>            <span class="st">"success_rate"</span>: <span class="bu">len</span>(success_requests) <span class="op">/</span> <span class="bu">len</span>(recent_requests) <span class="cf">if</span> recent_requests <span class="cf">else</span> <span class="dv">0</span>,</span>
<span id="cb36-130"><a href="#cb36-130" aria-hidden="true" tabindex="-1"></a>            <span class="st">"average_latency"</span>: np.mean([req[<span class="st">"latency"</span>] <span class="cf">for</span> req <span class="kw">in</span> success_requests]) <span class="cf">if</span> success_requests <span class="cf">else</span> <span class="dv">0</span>,</span>
<span id="cb36-131"><a href="#cb36-131" aria-hidden="true" tabindex="-1"></a>            <span class="st">"adapter_usage"</span>: {}</span>
<span id="cb36-132"><a href="#cb36-132" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb36-133"><a href="#cb36-133" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb36-134"><a href="#cb36-134" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Adapter usage statistics</span></span>
<span id="cb36-135"><a href="#cb36-135" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> req <span class="kw">in</span> success_requests:</span>
<span id="cb36-136"><a href="#cb36-136" aria-hidden="true" tabindex="-1"></a>            adapter <span class="op">=</span> req.get(<span class="st">"adapter"</span>, <span class="st">"base_model"</span>)</span>
<span id="cb36-137"><a href="#cb36-137" aria-hidden="true" tabindex="-1"></a>            metrics[<span class="st">"adapter_usage"</span>][adapter] <span class="op">=</span> metrics[<span class="st">"adapter_usage"</span>].get(adapter, <span class="dv">0</span>) <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb36-138"><a href="#cb36-138" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb36-139"><a href="#cb36-139" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> metrics</span>
<span id="cb36-140"><a href="#cb36-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-141"><a href="#cb36-141" aria-hidden="true" tabindex="-1"></a><span class="co"># API server demonstration</span></span>
<span id="cb36-142"><a href="#cb36-142" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">API Server Demo:"</span>)</span>
<span id="cb36-143"><a href="#cb36-143" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">20</span>)</span>
<span id="cb36-144"><a href="#cb36-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-145"><a href="#cb36-145" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize API server</span></span>
<span id="cb36-146"><a href="#cb36-146" aria-hidden="true" tabindex="-1"></a>api_server <span class="op">=</span> LoRAAPIServer(manager)</span>
<span id="cb36-147"><a href="#cb36-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-148"><a href="#cb36-148" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate API requests</span></span>
<span id="cb36-149"><a href="#cb36-149" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Simulating API requests..."</span>)</span>
<span id="cb36-150"><a href="#cb36-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-151"><a href="#cb36-151" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Inference request</span></span>
<span id="cb36-152"><a href="#cb36-152" aria-hidden="true" tabindex="-1"></a>inference_request <span class="op">=</span> {</span>
<span id="cb36-153"><a href="#cb36-153" aria-hidden="true" tabindex="-1"></a>    <span class="st">"inputs"</span>: {<span class="st">"image"</span>: <span class="st">"test.jpg"</span>, <span class="st">"text"</span>: <span class="st">"Describe this image"</span>},</span>
<span id="cb36-154"><a href="#cb36-154" aria-hidden="true" tabindex="-1"></a>    <span class="st">"adapter_name"</span>: <span class="st">"medical_adapter"</span></span>
<span id="cb36-155"><a href="#cb36-155" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb36-156"><a href="#cb36-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-157"><a href="#cb36-157" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> api_server.inference_endpoint(inference_request)</span>
<span id="cb36-158"><a href="#cb36-158" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Inference response: </span><span class="sc">{</span>response[<span class="st">'status'</span>]<span class="sc">}</span><span class="ss"> (took </span><span class="sc">{</span>response<span class="sc">.</span>get(<span class="st">'inference_time'</span>, <span class="dv">0</span>)<span class="sc">:.3f}</span><span class="ss">s)"</span>)</span>
<span id="cb36-159"><a href="#cb36-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-160"><a href="#cb36-160" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Load new adapter</span></span>
<span id="cb36-161"><a href="#cb36-161" aria-hidden="true" tabindex="-1"></a>load_request <span class="op">=</span> {</span>
<span id="cb36-162"><a href="#cb36-162" aria-hidden="true" tabindex="-1"></a>    <span class="st">"adapter_name"</span>: <span class="st">"custom_adapter"</span>,</span>
<span id="cb36-163"><a href="#cb36-163" aria-hidden="true" tabindex="-1"></a>    <span class="st">"adapter_path"</span>: <span class="st">"adapters/custom"</span>,</span>
<span id="cb36-164"><a href="#cb36-164" aria-hidden="true" tabindex="-1"></a>    <span class="st">"config"</span>: {<span class="st">"rank"</span>: <span class="dv">20</span>, <span class="st">"alpha"</span>: <span class="dv">20</span>}</span>
<span id="cb36-165"><a href="#cb36-165" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb36-166"><a href="#cb36-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-167"><a href="#cb36-167" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> api_server.load_adapter_endpoint(load_request)</span>
<span id="cb36-168"><a href="#cb36-168" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Load adapter response: </span><span class="sc">{</span>response[<span class="st">'status'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb36-169"><a href="#cb36-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-170"><a href="#cb36-170" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Health check</span></span>
<span id="cb36-171"><a href="#cb36-171" aria-hidden="true" tabindex="-1"></a>health_response <span class="op">=</span> api_server.health_endpoint()</span>
<span id="cb36-172"><a href="#cb36-172" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Health status: </span><span class="sc">{</span>health_response[<span class="st">'status'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb36-173"><a href="#cb36-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-174"><a href="#cb36-174" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. List adapters</span></span>
<span id="cb36-175"><a href="#cb36-175" aria-hidden="true" tabindex="-1"></a>adapters_response <span class="op">=</span> api_server.list_adapters_endpoint()</span>
<span id="cb36-176"><a href="#cb36-176" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Active adapters: </span><span class="sc">{</span>adapters_response[<span class="st">'total_adapters'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb36-177"><a href="#cb36-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-178"><a href="#cb36-178" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Get metrics</span></span>
<span id="cb36-179"><a href="#cb36-179" aria-hidden="true" tabindex="-1"></a>metrics_response <span class="op">=</span> api_server.get_metrics_endpoint()</span>
<span id="cb36-180"><a href="#cb36-180" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Success rate: </span><span class="sc">{</span>metrics_response[<span class="st">'success_rate'</span>]<span class="sc">:.1%}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
API Server Demo:
====================
LoRA API Server initialized
Available endpoints:
  POST /inference - Perform inference
  POST /load_adapter - Load new adapter
  DELETE /adapter/{name} - Unload adapter
  GET /health - Health check
  GET /adapters - List adapters

Simulating API requests...</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>INFO:__main__:Loading adapter 'custom_adapter' from adapters/custom
INFO:__main__:Adapter 'custom_adapter' loaded successfully</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Inference response: success (took 0.013s)
Load adapter response: success
Health status: healthy
Active adapters: 4
Success rate: 100.0%</code></pre>
</div>
</div>
</section>
</section>
<section id="monitoring-and-observability" class="level2">
<h2 class="anchored" data-anchor-id="monitoring-and-observability">Monitoring and Observability</h2>
<section id="performance-monitoring" class="level3">
<h3 class="anchored" data-anchor-id="performance-monitoring">Performance Monitoring</h3>
<div id="monitoring-system" class="cell" data-execution_count="25">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> defaultdict, deque</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LoRAMonitor:</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Comprehensive monitoring for LoRA-adapted VLMs"""</span></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, model, adapter_name: <span class="bu">str</span> <span class="op">=</span> <span class="st">"default"</span>, window_size: <span class="bu">int</span> <span class="op">=</span> <span class="dv">1000</span>):</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> model</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.adapter_name <span class="op">=</span> adapter_name</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.window_size <span class="op">=</span> window_size</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Metrics storage</span></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.metrics <span class="op">=</span> {</span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>            <span class="st">'inference_times'</span>: deque(maxlen<span class="op">=</span>window_size),</span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a>            <span class="st">'memory_usage'</span>: deque(maxlen<span class="op">=</span>window_size),</span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a>            <span class="st">'accuracy_scores'</span>: deque(maxlen<span class="op">=</span>window_size),</span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a>            <span class="st">'request_counts'</span>: defaultdict(<span class="bu">int</span>),</span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a>            <span class="st">'error_counts'</span>: defaultdict(<span class="bu">int</span>),</span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a>            <span class="st">'timestamps'</span>: deque(maxlen<span class="op">=</span>window_size)</span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb40-22"><a href="#cb40-22" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-23"><a href="#cb40-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># LoRA-specific metrics</span></span>
<span id="cb40-24"><a href="#cb40-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lora_metrics <span class="op">=</span> {</span>
<span id="cb40-25"><a href="#cb40-25" aria-hidden="true" tabindex="-1"></a>            <span class="st">'weight_norms'</span>: {},</span>
<span id="cb40-26"><a href="#cb40-26" aria-hidden="true" tabindex="-1"></a>            <span class="st">'rank_utilization'</span>: {},</span>
<span id="cb40-27"><a href="#cb40-27" aria-hidden="true" tabindex="-1"></a>            <span class="st">'adaptation_strength'</span>: {}</span>
<span id="cb40-28"><a href="#cb40-28" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb40-29"><a href="#cb40-29" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-30"><a href="#cb40-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Performance thresholds</span></span>
<span id="cb40-31"><a href="#cb40-31" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.thresholds <span class="op">=</span> {</span>
<span id="cb40-32"><a href="#cb40-32" aria-hidden="true" tabindex="-1"></a>            <span class="st">'max_inference_time'</span>: <span class="fl">2.0</span>,  <span class="co"># seconds</span></span>
<span id="cb40-33"><a href="#cb40-33" aria-hidden="true" tabindex="-1"></a>            <span class="st">'max_memory_usage'</span>: <span class="fl">4.0</span>,    <span class="co"># GB</span></span>
<span id="cb40-34"><a href="#cb40-34" aria-hidden="true" tabindex="-1"></a>            <span class="st">'min_accuracy'</span>: <span class="fl">0.8</span>,        <span class="co"># minimum acceptable accuracy</span></span>
<span id="cb40-35"><a href="#cb40-35" aria-hidden="true" tabindex="-1"></a>            <span class="st">'max_error_rate'</span>: <span class="fl">0.02</span>      <span class="co"># maximum error rate</span></span>
<span id="cb40-36"><a href="#cb40-36" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb40-37"><a href="#cb40-37" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-38"><a href="#cb40-38" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"LoRA Monitor initialized for adapter: </span><span class="sc">{</span>adapter_name<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb40-39"><a href="#cb40-39" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb40-40"><a href="#cb40-40" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> log_inference(<span class="va">self</span>, inference_time: <span class="bu">float</span>, memory_usage: <span class="bu">float</span>, </span>
<span id="cb40-41"><a href="#cb40-41" aria-hidden="true" tabindex="-1"></a>                     accuracy: Optional[<span class="bu">float</span>] <span class="op">=</span> <span class="va">None</span>):</span>
<span id="cb40-42"><a href="#cb40-42" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Log inference metrics"""</span></span>
<span id="cb40-43"><a href="#cb40-43" aria-hidden="true" tabindex="-1"></a>        current_time <span class="op">=</span> time.time()</span>
<span id="cb40-44"><a href="#cb40-44" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-45"><a href="#cb40-45" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.metrics[<span class="st">'inference_times'</span>].append(inference_time)</span>
<span id="cb40-46"><a href="#cb40-46" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.metrics[<span class="st">'memory_usage'</span>].append(memory_usage)</span>
<span id="cb40-47"><a href="#cb40-47" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.metrics[<span class="st">'timestamps'</span>].append(current_time)</span>
<span id="cb40-48"><a href="#cb40-48" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-49"><a href="#cb40-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> accuracy <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb40-50"><a href="#cb40-50" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.metrics[<span class="st">'accuracy_scores'</span>].append(accuracy)</span>
<span id="cb40-51"><a href="#cb40-51" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-52"><a href="#cb40-52" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check thresholds and alert if necessary</span></span>
<span id="cb40-53"><a href="#cb40-53" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.check_thresholds(inference_time, memory_usage, accuracy)</span>
<span id="cb40-54"><a href="#cb40-54" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb40-55"><a href="#cb40-55" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> check_thresholds(<span class="va">self</span>, inference_time: <span class="bu">float</span>, memory_usage: <span class="bu">float</span>, </span>
<span id="cb40-56"><a href="#cb40-56" aria-hidden="true" tabindex="-1"></a>                        accuracy: Optional[<span class="bu">float</span>] <span class="op">=</span> <span class="va">None</span>):</span>
<span id="cb40-57"><a href="#cb40-57" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Check if metrics exceed defined thresholds"""</span></span>
<span id="cb40-58"><a href="#cb40-58" aria-hidden="true" tabindex="-1"></a>        alerts <span class="op">=</span> []</span>
<span id="cb40-59"><a href="#cb40-59" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-60"><a href="#cb40-60" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> inference_time <span class="op">&gt;</span> <span class="va">self</span>.thresholds[<span class="st">'max_inference_time'</span>]:</span>
<span id="cb40-61"><a href="#cb40-61" aria-hidden="true" tabindex="-1"></a>            alerts.append(<span class="ss">f"HIGH_LATENCY: </span><span class="sc">{</span>inference_time<span class="sc">:.3f}</span><span class="ss">s &gt; </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>thresholds[<span class="st">'max_inference_time'</span>]<span class="sc">}</span><span class="ss">s"</span>)</span>
<span id="cb40-62"><a href="#cb40-62" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-63"><a href="#cb40-63" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> memory_usage <span class="op">&gt;</span> <span class="va">self</span>.thresholds[<span class="st">'max_memory_usage'</span>]:</span>
<span id="cb40-64"><a href="#cb40-64" aria-hidden="true" tabindex="-1"></a>            alerts.append(<span class="ss">f"HIGH_MEMORY: </span><span class="sc">{</span>memory_usage<span class="sc">:.2f}</span><span class="ss">GB &gt; </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>thresholds[<span class="st">'max_memory_usage'</span>]<span class="sc">}</span><span class="ss">GB"</span>)</span>
<span id="cb40-65"><a href="#cb40-65" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-66"><a href="#cb40-66" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> accuracy <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> accuracy <span class="op">&lt;</span> <span class="va">self</span>.thresholds[<span class="st">'min_accuracy'</span>]:</span>
<span id="cb40-67"><a href="#cb40-67" aria-hidden="true" tabindex="-1"></a>            alerts.append(<span class="ss">f"LOW_ACCURACY: </span><span class="sc">{</span>accuracy<span class="sc">:.3f}</span><span class="ss"> &lt; </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>thresholds[<span class="st">'min_accuracy'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb40-68"><a href="#cb40-68" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-69"><a href="#cb40-69" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> alert <span class="kw">in</span> alerts:</span>
<span id="cb40-70"><a href="#cb40-70" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"🚨 ALERT [</span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>adapter_name<span class="sc">}</span><span class="ss">]: </span><span class="sc">{</span>alert<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb40-71"><a href="#cb40-71" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb40-72"><a href="#cb40-72" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> compute_performance_stats(<span class="va">self</span>) <span class="op">-&gt;</span> Dict[<span class="bu">str</span>, Any]:</span>
<span id="cb40-73"><a href="#cb40-73" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Compute performance statistics from collected metrics"""</span></span>
<span id="cb40-74"><a href="#cb40-74" aria-hidden="true" tabindex="-1"></a>        stats <span class="op">=</span> {}</span>
<span id="cb40-75"><a href="#cb40-75" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-76"><a href="#cb40-76" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Inference time statistics</span></span>
<span id="cb40-77"><a href="#cb40-77" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.metrics[<span class="st">'inference_times'</span>]:</span>
<span id="cb40-78"><a href="#cb40-78" aria-hidden="true" tabindex="-1"></a>            times <span class="op">=</span> <span class="bu">list</span>(<span class="va">self</span>.metrics[<span class="st">'inference_times'</span>])</span>
<span id="cb40-79"><a href="#cb40-79" aria-hidden="true" tabindex="-1"></a>            stats[<span class="st">'inference_time'</span>] <span class="op">=</span> {</span>
<span id="cb40-80"><a href="#cb40-80" aria-hidden="true" tabindex="-1"></a>                <span class="st">'mean'</span>: np.mean(times),</span>
<span id="cb40-81"><a href="#cb40-81" aria-hidden="true" tabindex="-1"></a>                <span class="st">'std'</span>: np.std(times),</span>
<span id="cb40-82"><a href="#cb40-82" aria-hidden="true" tabindex="-1"></a>                <span class="st">'p50'</span>: np.percentile(times, <span class="dv">50</span>),</span>
<span id="cb40-83"><a href="#cb40-83" aria-hidden="true" tabindex="-1"></a>                <span class="st">'p95'</span>: np.percentile(times, <span class="dv">95</span>),</span>
<span id="cb40-84"><a href="#cb40-84" aria-hidden="true" tabindex="-1"></a>                <span class="st">'p99'</span>: np.percentile(times, <span class="dv">99</span>),</span>
<span id="cb40-85"><a href="#cb40-85" aria-hidden="true" tabindex="-1"></a>                <span class="st">'min'</span>: np.<span class="bu">min</span>(times),</span>
<span id="cb40-86"><a href="#cb40-86" aria-hidden="true" tabindex="-1"></a>                <span class="st">'max'</span>: np.<span class="bu">max</span>(times)</span>
<span id="cb40-87"><a href="#cb40-87" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb40-88"><a href="#cb40-88" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-89"><a href="#cb40-89" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Memory usage statistics</span></span>
<span id="cb40-90"><a href="#cb40-90" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.metrics[<span class="st">'memory_usage'</span>]:</span>
<span id="cb40-91"><a href="#cb40-91" aria-hidden="true" tabindex="-1"></a>            memory <span class="op">=</span> <span class="bu">list</span>(<span class="va">self</span>.metrics[<span class="st">'memory_usage'</span>])</span>
<span id="cb40-92"><a href="#cb40-92" aria-hidden="true" tabindex="-1"></a>            stats[<span class="st">'memory_usage'</span>] <span class="op">=</span> {</span>
<span id="cb40-93"><a href="#cb40-93" aria-hidden="true" tabindex="-1"></a>                <span class="st">'mean'</span>: np.mean(memory),</span>
<span id="cb40-94"><a href="#cb40-94" aria-hidden="true" tabindex="-1"></a>                <span class="st">'max'</span>: np.<span class="bu">max</span>(memory),</span>
<span id="cb40-95"><a href="#cb40-95" aria-hidden="true" tabindex="-1"></a>                <span class="st">'min'</span>: np.<span class="bu">min</span>(memory),</span>
<span id="cb40-96"><a href="#cb40-96" aria-hidden="true" tabindex="-1"></a>                <span class="st">'current'</span>: memory[<span class="op">-</span><span class="dv">1</span>] <span class="cf">if</span> memory <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb40-97"><a href="#cb40-97" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb40-98"><a href="#cb40-98" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-99"><a href="#cb40-99" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Accuracy statistics</span></span>
<span id="cb40-100"><a href="#cb40-100" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.metrics[<span class="st">'accuracy_scores'</span>]:</span>
<span id="cb40-101"><a href="#cb40-101" aria-hidden="true" tabindex="-1"></a>            accuracy <span class="op">=</span> <span class="bu">list</span>(<span class="va">self</span>.metrics[<span class="st">'accuracy_scores'</span>])</span>
<span id="cb40-102"><a href="#cb40-102" aria-hidden="true" tabindex="-1"></a>            stats[<span class="st">'accuracy'</span>] <span class="op">=</span> {</span>
<span id="cb40-103"><a href="#cb40-103" aria-hidden="true" tabindex="-1"></a>                <span class="st">'mean'</span>: np.mean(accuracy),</span>
<span id="cb40-104"><a href="#cb40-104" aria-hidden="true" tabindex="-1"></a>                <span class="st">'std'</span>: np.std(accuracy),</span>
<span id="cb40-105"><a href="#cb40-105" aria-hidden="true" tabindex="-1"></a>                <span class="st">'min'</span>: np.<span class="bu">min</span>(accuracy),</span>
<span id="cb40-106"><a href="#cb40-106" aria-hidden="true" tabindex="-1"></a>                <span class="st">'max'</span>: np.<span class="bu">max</span>(accuracy),</span>
<span id="cb40-107"><a href="#cb40-107" aria-hidden="true" tabindex="-1"></a>                <span class="st">'recent'</span>: np.mean(accuracy[<span class="op">-</span><span class="dv">10</span>:]) <span class="cf">if</span> <span class="bu">len</span>(accuracy) <span class="op">&gt;=</span> <span class="dv">10</span> <span class="cf">else</span> np.mean(accuracy)</span>
<span id="cb40-108"><a href="#cb40-108" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb40-109"><a href="#cb40-109" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-110"><a href="#cb40-110" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Throughput calculation</span></span>
<span id="cb40-111"><a href="#cb40-111" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(<span class="va">self</span>.metrics[<span class="st">'timestamps'</span>]) <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb40-112"><a href="#cb40-112" aria-hidden="true" tabindex="-1"></a>            time_span <span class="op">=</span> <span class="va">self</span>.metrics[<span class="st">'timestamps'</span>][<span class="op">-</span><span class="dv">1</span>] <span class="op">-</span> <span class="va">self</span>.metrics[<span class="st">'timestamps'</span>][<span class="dv">0</span>]</span>
<span id="cb40-113"><a href="#cb40-113" aria-hidden="true" tabindex="-1"></a>            stats[<span class="st">'throughput'</span>] <span class="op">=</span> {</span>
<span id="cb40-114"><a href="#cb40-114" aria-hidden="true" tabindex="-1"></a>                <span class="st">'requests_per_second'</span>: <span class="bu">len</span>(<span class="va">self</span>.metrics[<span class="st">'timestamps'</span>]) <span class="op">/</span> time_span <span class="cf">if</span> time_span <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="dv">0</span>,</span>
<span id="cb40-115"><a href="#cb40-115" aria-hidden="true" tabindex="-1"></a>                <span class="st">'time_span_minutes'</span>: time_span <span class="op">/</span> <span class="dv">60</span></span>
<span id="cb40-116"><a href="#cb40-116" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb40-117"><a href="#cb40-117" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-118"><a href="#cb40-118" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> stats</span>
<span id="cb40-119"><a href="#cb40-119" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb40-120"><a href="#cb40-120" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> analyze_trends(<span class="va">self</span>, window_minutes: <span class="bu">int</span> <span class="op">=</span> <span class="dv">30</span>) <span class="op">-&gt;</span> Dict[<span class="bu">str</span>, Any]:</span>
<span id="cb40-121"><a href="#cb40-121" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Analyze performance trends over time"""</span></span>
<span id="cb40-122"><a href="#cb40-122" aria-hidden="true" tabindex="-1"></a>        current_time <span class="op">=</span> time.time()</span>
<span id="cb40-123"><a href="#cb40-123" aria-hidden="true" tabindex="-1"></a>        cutoff_time <span class="op">=</span> current_time <span class="op">-</span> (window_minutes <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb40-124"><a href="#cb40-124" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-125"><a href="#cb40-125" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Filter recent metrics</span></span>
<span id="cb40-126"><a href="#cb40-126" aria-hidden="true" tabindex="-1"></a>        recent_indices <span class="op">=</span> [i <span class="cf">for</span> i, t <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="va">self</span>.metrics[<span class="st">'timestamps'</span>]) </span>
<span id="cb40-127"><a href="#cb40-127" aria-hidden="true" tabindex="-1"></a>                         <span class="cf">if</span> t <span class="op">&gt;=</span> cutoff_time]</span>
<span id="cb40-128"><a href="#cb40-128" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-129"><a href="#cb40-129" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(recent_indices) <span class="op">&lt;</span> <span class="dv">2</span>:</span>
<span id="cb40-130"><a href="#cb40-130" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> {<span class="st">"error"</span>: <span class="st">"Insufficient data for trend analysis"</span>}</span>
<span id="cb40-131"><a href="#cb40-131" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-132"><a href="#cb40-132" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Extract recent data</span></span>
<span id="cb40-133"><a href="#cb40-133" aria-hidden="true" tabindex="-1"></a>        recent_times <span class="op">=</span> [<span class="va">self</span>.metrics[<span class="st">'inference_times'</span>][i] <span class="cf">for</span> i <span class="kw">in</span> recent_indices]</span>
<span id="cb40-134"><a href="#cb40-134" aria-hidden="true" tabindex="-1"></a>        recent_memory <span class="op">=</span> [<span class="va">self</span>.metrics[<span class="st">'memory_usage'</span>][i] <span class="cf">for</span> i <span class="kw">in</span> recent_indices]</span>
<span id="cb40-135"><a href="#cb40-135" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-136"><a href="#cb40-136" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate trends (simple linear regression slope)</span></span>
<span id="cb40-137"><a href="#cb40-137" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> np.arange(<span class="bu">len</span>(recent_times))</span>
<span id="cb40-138"><a href="#cb40-138" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-139"><a href="#cb40-139" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Inference time trend</span></span>
<span id="cb40-140"><a href="#cb40-140" aria-hidden="true" tabindex="-1"></a>        time_slope <span class="op">=</span> np.polyfit(x, recent_times, <span class="dv">1</span>)[<span class="dv">0</span>] <span class="cf">if</span> <span class="bu">len</span>(recent_times) <span class="op">&gt;</span> <span class="dv">1</span> <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb40-141"><a href="#cb40-141" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-142"><a href="#cb40-142" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Memory usage trend  </span></span>
<span id="cb40-143"><a href="#cb40-143" aria-hidden="true" tabindex="-1"></a>        memory_slope <span class="op">=</span> np.polyfit(x, recent_memory, <span class="dv">1</span>)[<span class="dv">0</span>] <span class="cf">if</span> <span class="bu">len</span>(recent_memory) <span class="op">&gt;</span> <span class="dv">1</span> <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb40-144"><a href="#cb40-144" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-145"><a href="#cb40-145" aria-hidden="true" tabindex="-1"></a>        trends <span class="op">=</span> {</span>
<span id="cb40-146"><a href="#cb40-146" aria-hidden="true" tabindex="-1"></a>            <span class="st">'window_minutes'</span>: window_minutes,</span>
<span id="cb40-147"><a href="#cb40-147" aria-hidden="true" tabindex="-1"></a>            <span class="st">'data_points'</span>: <span class="bu">len</span>(recent_indices),</span>
<span id="cb40-148"><a href="#cb40-148" aria-hidden="true" tabindex="-1"></a>            <span class="st">'inference_time_trend'</span>: {</span>
<span id="cb40-149"><a href="#cb40-149" aria-hidden="true" tabindex="-1"></a>                <span class="st">'slope'</span>: time_slope,</span>
<span id="cb40-150"><a href="#cb40-150" aria-hidden="true" tabindex="-1"></a>                <span class="st">'direction'</span>: <span class="st">'increasing'</span> <span class="cf">if</span> time_slope <span class="op">&gt;</span> <span class="fl">0.001</span> <span class="cf">else</span> <span class="st">'decreasing'</span> <span class="cf">if</span> time_slope <span class="op">&lt;</span> <span class="op">-</span><span class="fl">0.001</span> <span class="cf">else</span> <span class="st">'stable'</span>,</span>
<span id="cb40-151"><a href="#cb40-151" aria-hidden="true" tabindex="-1"></a>                <span class="st">'severity'</span>: <span class="st">'high'</span> <span class="cf">if</span> <span class="bu">abs</span>(time_slope) <span class="op">&gt;</span> <span class="fl">0.01</span> <span class="cf">else</span> <span class="st">'medium'</span> <span class="cf">if</span> <span class="bu">abs</span>(time_slope) <span class="op">&gt;</span> <span class="fl">0.005</span> <span class="cf">else</span> <span class="st">'low'</span></span>
<span id="cb40-152"><a href="#cb40-152" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb40-153"><a href="#cb40-153" aria-hidden="true" tabindex="-1"></a>            <span class="st">'memory_usage_trend'</span>: {</span>
<span id="cb40-154"><a href="#cb40-154" aria-hidden="true" tabindex="-1"></a>                <span class="st">'slope'</span>: memory_slope,</span>
<span id="cb40-155"><a href="#cb40-155" aria-hidden="true" tabindex="-1"></a>                <span class="st">'direction'</span>: <span class="st">'increasing'</span> <span class="cf">if</span> memory_slope <span class="op">&gt;</span> <span class="fl">0.01</span> <span class="cf">else</span> <span class="st">'decreasing'</span> <span class="cf">if</span> memory_slope <span class="op">&lt;</span> <span class="op">-</span><span class="fl">0.01</span> <span class="cf">else</span> <span class="st">'stable'</span>,</span>
<span id="cb40-156"><a href="#cb40-156" aria-hidden="true" tabindex="-1"></a>                <span class="st">'severity'</span>: <span class="st">'high'</span> <span class="cf">if</span> <span class="bu">abs</span>(memory_slope) <span class="op">&gt;</span> <span class="fl">0.1</span> <span class="cf">else</span> <span class="st">'medium'</span> <span class="cf">if</span> <span class="bu">abs</span>(memory_slope) <span class="op">&gt;</span> <span class="fl">0.05</span> <span class="cf">else</span> <span class="st">'low'</span></span>
<span id="cb40-157"><a href="#cb40-157" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb40-158"><a href="#cb40-158" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb40-159"><a href="#cb40-159" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-160"><a href="#cb40-160" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> trends</span>
<span id="cb40-161"><a href="#cb40-161" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb40-162"><a href="#cb40-162" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> generate_monitoring_report(<span class="va">self</span>) <span class="op">-&gt;</span> Dict[<span class="bu">str</span>, Any]:</span>
<span id="cb40-163"><a href="#cb40-163" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Generate comprehensive monitoring report"""</span></span>
<span id="cb40-164"><a href="#cb40-164" aria-hidden="true" tabindex="-1"></a>        report <span class="op">=</span> {</span>
<span id="cb40-165"><a href="#cb40-165" aria-hidden="true" tabindex="-1"></a>            <span class="st">'adapter_name'</span>: <span class="va">self</span>.adapter_name,</span>
<span id="cb40-166"><a href="#cb40-166" aria-hidden="true" tabindex="-1"></a>            <span class="st">'report_timestamp'</span>: time.time(),</span>
<span id="cb40-167"><a href="#cb40-167" aria-hidden="true" tabindex="-1"></a>            <span class="st">'performance_stats'</span>: <span class="va">self</span>.compute_performance_stats(),</span>
<span id="cb40-168"><a href="#cb40-168" aria-hidden="true" tabindex="-1"></a>            <span class="st">'trends'</span>: <span class="va">self</span>.analyze_trends(),</span>
<span id="cb40-169"><a href="#cb40-169" aria-hidden="true" tabindex="-1"></a>            <span class="st">'thresholds'</span>: <span class="va">self</span>.thresholds,</span>
<span id="cb40-170"><a href="#cb40-170" aria-hidden="true" tabindex="-1"></a>            <span class="st">'health_status'</span>: <span class="va">self</span>._compute_health_status()</span>
<span id="cb40-171"><a href="#cb40-171" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb40-172"><a href="#cb40-172" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-173"><a href="#cb40-173" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> report</span>
<span id="cb40-174"><a href="#cb40-174" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb40-175"><a href="#cb40-175" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _compute_health_status(<span class="va">self</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb40-176"><a href="#cb40-176" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Compute overall health status"""</span></span>
<span id="cb40-177"><a href="#cb40-177" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> <span class="va">self</span>.metrics[<span class="st">'inference_times'</span>]:</span>
<span id="cb40-178"><a href="#cb40-178" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="st">'unknown'</span></span>
<span id="cb40-179"><a href="#cb40-179" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-180"><a href="#cb40-180" aria-hidden="true" tabindex="-1"></a>        recent_times <span class="op">=</span> <span class="bu">list</span>(<span class="va">self</span>.metrics[<span class="st">'inference_times'</span>])[<span class="op">-</span><span class="dv">10</span>:]</span>
<span id="cb40-181"><a href="#cb40-181" aria-hidden="true" tabindex="-1"></a>        recent_memory <span class="op">=</span> <span class="bu">list</span>(<span class="va">self</span>.metrics[<span class="st">'memory_usage'</span>])[<span class="op">-</span><span class="dv">10</span>:]</span>
<span id="cb40-182"><a href="#cb40-182" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-183"><a href="#cb40-183" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check for threshold violations</span></span>
<span id="cb40-184"><a href="#cb40-184" aria-hidden="true" tabindex="-1"></a>        high_latency <span class="op">=</span> <span class="bu">any</span>(t <span class="op">&gt;</span> <span class="va">self</span>.thresholds[<span class="st">'max_inference_time'</span>] <span class="cf">for</span> t <span class="kw">in</span> recent_times)</span>
<span id="cb40-185"><a href="#cb40-185" aria-hidden="true" tabindex="-1"></a>        high_memory <span class="op">=</span> <span class="bu">any</span>(m <span class="op">&gt;</span> <span class="va">self</span>.thresholds[<span class="st">'max_memory_usage'</span>] <span class="cf">for</span> m <span class="kw">in</span> recent_memory)</span>
<span id="cb40-186"><a href="#cb40-186" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-187"><a href="#cb40-187" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> high_latency <span class="kw">or</span> high_memory:</span>
<span id="cb40-188"><a href="#cb40-188" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="st">'degraded'</span></span>
<span id="cb40-189"><a href="#cb40-189" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-190"><a href="#cb40-190" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check for accuracy issues</span></span>
<span id="cb40-191"><a href="#cb40-191" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.metrics[<span class="st">'accuracy_scores'</span>]:</span>
<span id="cb40-192"><a href="#cb40-192" aria-hidden="true" tabindex="-1"></a>            recent_accuracy <span class="op">=</span> <span class="bu">list</span>(<span class="va">self</span>.metrics[<span class="st">'accuracy_scores'</span>])[<span class="op">-</span><span class="dv">10</span>:]</span>
<span id="cb40-193"><a href="#cb40-193" aria-hidden="true" tabindex="-1"></a>            low_accuracy <span class="op">=</span> <span class="bu">any</span>(a <span class="op">&lt;</span> <span class="va">self</span>.thresholds[<span class="st">'min_accuracy'</span>] <span class="cf">for</span> a <span class="kw">in</span> recent_accuracy)</span>
<span id="cb40-194"><a href="#cb40-194" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> low_accuracy:</span>
<span id="cb40-195"><a href="#cb40-195" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span> <span class="st">'degraded'</span></span>
<span id="cb40-196"><a href="#cb40-196" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-197"><a href="#cb40-197" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">'healthy'</span></span>
<span id="cb40-198"><a href="#cb40-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-199"><a href="#cb40-199" aria-hidden="true" tabindex="-1"></a><span class="co"># Monitoring demonstration</span></span>
<span id="cb40-200"><a href="#cb40-200" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"LoRA Monitoring System Demo:"</span>)</span>
<span id="cb40-201"><a href="#cb40-201" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">30</span>)</span>
<span id="cb40-202"><a href="#cb40-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-203"><a href="#cb40-203" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize monitor</span></span>
<span id="cb40-204"><a href="#cb40-204" aria-hidden="true" tabindex="-1"></a>monitor <span class="op">=</span> LoRAMonitor(<span class="va">None</span>, <span class="st">"production_adapter"</span>)</span>
<span id="cb40-205"><a href="#cb40-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-206"><a href="#cb40-206" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate monitoring data</span></span>
<span id="cb40-207"><a href="#cb40-207" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Simulating monitoring data..."</span>)</span>
<span id="cb40-208"><a href="#cb40-208" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)  <span class="co"># For reproducible results</span></span>
<span id="cb40-209"><a href="#cb40-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-210"><a href="#cb40-210" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb40-211"><a href="#cb40-211" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Simulate varying performance</span></span>
<span id="cb40-212"><a href="#cb40-212" aria-hidden="true" tabindex="-1"></a>    base_latency <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb40-213"><a href="#cb40-213" aria-hidden="true" tabindex="-1"></a>    latency_noise <span class="op">=</span> np.random.normal(<span class="dv">0</span>, <span class="fl">0.02</span>)</span>
<span id="cb40-214"><a href="#cb40-214" aria-hidden="true" tabindex="-1"></a>    memory_base <span class="op">=</span> <span class="fl">2.0</span></span>
<span id="cb40-215"><a href="#cb40-215" aria-hidden="true" tabindex="-1"></a>    memory_noise <span class="op">=</span> np.random.normal(<span class="dv">0</span>, <span class="fl">0.1</span>)</span>
<span id="cb40-216"><a href="#cb40-216" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb40-217"><a href="#cb40-217" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add some performance degradation over time</span></span>
<span id="cb40-218"><a href="#cb40-218" aria-hidden="true" tabindex="-1"></a>    degradation_factor <span class="op">=</span> <span class="dv">1</span> <span class="op">+</span> (i <span class="op">/</span> <span class="dv">1000</span>)</span>
<span id="cb40-219"><a href="#cb40-219" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb40-220"><a href="#cb40-220" aria-hidden="true" tabindex="-1"></a>    inference_time <span class="op">=</span> base_latency <span class="op">*</span> degradation_factor <span class="op">+</span> latency_noise</span>
<span id="cb40-221"><a href="#cb40-221" aria-hidden="true" tabindex="-1"></a>    memory_usage <span class="op">=</span> memory_base <span class="op">+</span> memory_noise</span>
<span id="cb40-222"><a href="#cb40-222" aria-hidden="true" tabindex="-1"></a>    accuracy <span class="op">=</span> <span class="fl">0.92</span> <span class="op">+</span> np.random.normal(<span class="dv">0</span>, <span class="fl">0.03</span>)</span>
<span id="cb40-223"><a href="#cb40-223" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb40-224"><a href="#cb40-224" aria-hidden="true" tabindex="-1"></a>    monitor.log_inference(inference_time, memory_usage, accuracy)</span>
<span id="cb40-225"><a href="#cb40-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-226"><a href="#cb40-226" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate performance report</span></span>
<span id="cb40-227"><a href="#cb40-227" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Generating performance report..."</span>)</span>
<span id="cb40-228"><a href="#cb40-228" aria-hidden="true" tabindex="-1"></a>report <span class="op">=</span> monitor.generate_monitoring_report()</span>
<span id="cb40-229"><a href="#cb40-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-230"><a href="#cb40-230" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Health Status: </span><span class="sc">{</span>report[<span class="st">'health_status'</span>]<span class="sc">.</span>upper()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb40-231"><a href="#cb40-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-232"><a href="#cb40-232" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">'performance_stats'</span> <span class="kw">in</span> report:</span>
<span id="cb40-233"><a href="#cb40-233" aria-hidden="true" tabindex="-1"></a>    perf <span class="op">=</span> report[<span class="st">'performance_stats'</span>]</span>
<span id="cb40-234"><a href="#cb40-234" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb40-235"><a href="#cb40-235" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">'inference_time'</span> <span class="kw">in</span> perf:</span>
<span id="cb40-236"><a href="#cb40-236" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Inference Time - Mean: </span><span class="sc">{</span>perf[<span class="st">'inference_time'</span>][<span class="st">'mean'</span>]<span class="sc">:.3f}</span><span class="ss">s, P95: </span><span class="sc">{</span>perf[<span class="st">'inference_time'</span>][<span class="st">'p95'</span>]<span class="sc">:.3f}</span><span class="ss">s"</span>)</span>
<span id="cb40-237"><a href="#cb40-237" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb40-238"><a href="#cb40-238" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">'memory_usage'</span> <span class="kw">in</span> perf:</span>
<span id="cb40-239"><a href="#cb40-239" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Memory Usage - Mean: </span><span class="sc">{</span>perf[<span class="st">'memory_usage'</span>][<span class="st">'mean'</span>]<span class="sc">:.2f}</span><span class="ss">GB, Max: </span><span class="sc">{</span>perf[<span class="st">'memory_usage'</span>][<span class="st">'max'</span>]<span class="sc">:.2f}</span><span class="ss">GB"</span>)</span>
<span id="cb40-240"><a href="#cb40-240" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb40-241"><a href="#cb40-241" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">'accuracy'</span> <span class="kw">in</span> perf:</span>
<span id="cb40-242"><a href="#cb40-242" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Accuracy - Mean: </span><span class="sc">{</span>perf[<span class="st">'accuracy'</span>][<span class="st">'mean'</span>]<span class="sc">:.3f}</span><span class="ss">, Recent: </span><span class="sc">{</span>perf[<span class="st">'accuracy'</span>][<span class="st">'recent'</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb40-243"><a href="#cb40-243" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb40-244"><a href="#cb40-244" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">'throughput'</span> <span class="kw">in</span> perf:</span>
<span id="cb40-245"><a href="#cb40-245" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Throughput: </span><span class="sc">{</span>perf[<span class="st">'throughput'</span>][<span class="st">'requests_per_second'</span>]<span class="sc">:.1f}</span><span class="ss"> req/s"</span>)</span>
<span id="cb40-246"><a href="#cb40-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-247"><a href="#cb40-247" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">'trends'</span> <span class="kw">in</span> report <span class="kw">and</span> <span class="st">'error'</span> <span class="kw">not</span> <span class="kw">in</span> report[<span class="st">'trends'</span>]:</span>
<span id="cb40-248"><a href="#cb40-248" aria-hidden="true" tabindex="-1"></a>    trends <span class="op">=</span> report[<span class="st">'trends'</span>]</span>
<span id="cb40-249"><a href="#cb40-249" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Trend Analysis (</span><span class="sc">{</span>trends[<span class="st">'window_minutes'</span>]<span class="sc">}</span><span class="ss"> min window):"</span>)</span>
<span id="cb40-250"><a href="#cb40-250" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Latency trend: </span><span class="sc">{</span>trends[<span class="st">'inference_time_trend'</span>][<span class="st">'direction'</span>]<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>trends[<span class="st">'inference_time_trend'</span>][<span class="st">'severity'</span>]<span class="sc">}</span><span class="ss"> severity)"</span>)</span>
<span id="cb40-251"><a href="#cb40-251" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Memory trend: </span><span class="sc">{</span>trends[<span class="st">'memory_usage_trend'</span>][<span class="st">'direction'</span>]<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>trends[<span class="st">'memory_usage_trend'</span>][<span class="st">'severity'</span>]<span class="sc">}</span><span class="ss"> severity)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>LoRA Monitoring System Demo:
==============================
LoRA Monitor initialized for adapter: production_adapter

Simulating monitoring data...

Generating performance report...
Health Status: HEALTHY
Inference Time - Mean: 0.102s, P95: 0.131s
Memory Usage - Mean: 1.99GB, Max: 2.19GB
Accuracy - Mean: 0.917, Recent: 0.926
Throughput: 562239.1 req/s

Trend Analysis (30 min window):
Latency trend: stable (low severity)
Memory trend: stable (low severity)</code></pre>
</div>
</div>
</section>
<section id="visualization-and-dashboards" class="level3">
<h3 class="anchored" data-anchor-id="visualization-and-dashboards">Visualization and Dashboards</h3>
<div id="cell-fig-monitoring-dashboard" class="cell" data-execution_count="26">
<div class="cell-output cell-output-display">
<div id="fig-monitoring-dashboard" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-monitoring-dashboard-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-monitoring-dashboard-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-monitoring-dashboard-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: LoRA Monitoring Dashboard
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="future-directions" class="level2">
<h2 class="anchored" data-anchor-id="future-directions">Future Directions</h2>
<section id="emerging-techniques" class="level3">
<h3 class="anchored" data-anchor-id="emerging-techniques">Emerging Techniques</h3>
<div id="future-directions" class="cell" data-execution_count="27">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> EmergingLoRATechniques:</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Showcase of emerging LoRA techniques and future directions"""</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.techniques <span class="op">=</span> {</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>            <span class="st">"dynamic_lora"</span>: {</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>                <span class="st">"description"</span>: <span class="st">"Adaptive rank and module selection during training"</span>,</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>                <span class="st">"key_features"</span>: [</span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Runtime rank adjustment"</span>,</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Automatic module importance scoring"</span>,</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Dynamic resource allocation"</span></span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>                ],</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>                <span class="st">"potential_impact"</span>: <span class="st">"30-50</span><span class="sc">% e</span><span class="st">fficiency improvement"</span>,</span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a>                <span class="st">"maturity"</span>: <span class="st">"Research phase"</span></span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a>            <span class="st">"hierarchical_lora"</span>: {</span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a>                <span class="st">"description"</span>: <span class="st">"Multi-level adaptation for different abstraction levels"</span>,</span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a>                <span class="st">"key_features"</span>: [</span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Coarse-to-fine adaptation hierarchy"</span>,</span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Layer-specific rank allocation"</span>,</span>
<span id="cb42-22"><a href="#cb42-22" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Compositional parameter sharing"</span></span>
<span id="cb42-23"><a href="#cb42-23" aria-hidden="true" tabindex="-1"></a>                ],</span>
<span id="cb42-24"><a href="#cb42-24" aria-hidden="true" tabindex="-1"></a>                <span class="st">"potential_impact"</span>: <span class="st">"Better transfer learning"</span>,</span>
<span id="cb42-25"><a href="#cb42-25" aria-hidden="true" tabindex="-1"></a>                <span class="st">"maturity"</span>: <span class="st">"Early development"</span></span>
<span id="cb42-26"><a href="#cb42-26" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb42-27"><a href="#cb42-27" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb42-28"><a href="#cb42-28" aria-hidden="true" tabindex="-1"></a>            <span class="st">"conditional_lora"</span>: {</span>
<span id="cb42-29"><a href="#cb42-29" aria-hidden="true" tabindex="-1"></a>                <span class="st">"description"</span>: <span class="st">"Task-conditional parameter generation"</span>,</span>
<span id="cb42-30"><a href="#cb42-30" aria-hidden="true" tabindex="-1"></a>                <span class="st">"key_features"</span>: [</span>
<span id="cb42-31"><a href="#cb42-31" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Dynamic adapter generation"</span>,</span>
<span id="cb42-32"><a href="#cb42-32" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Task-aware parameter synthesis"</span>,</span>
<span id="cb42-33"><a href="#cb42-33" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Meta-learning integration"</span></span>
<span id="cb42-34"><a href="#cb42-34" aria-hidden="true" tabindex="-1"></a>                ],</span>
<span id="cb42-35"><a href="#cb42-35" aria-hidden="true" tabindex="-1"></a>                <span class="st">"potential_impact"</span>: <span class="st">"Unlimited task adaptation"</span>,</span>
<span id="cb42-36"><a href="#cb42-36" aria-hidden="true" tabindex="-1"></a>                <span class="st">"maturity"</span>: <span class="st">"Conceptual"</span></span>
<span id="cb42-37"><a href="#cb42-37" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb42-38"><a href="#cb42-38" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb42-39"><a href="#cb42-39" aria-hidden="true" tabindex="-1"></a>            <span class="st">"federated_lora"</span>: {</span>
<span id="cb42-40"><a href="#cb42-40" aria-hidden="true" tabindex="-1"></a>                <span class="st">"description"</span>: <span class="st">"Distributed learning with privacy preservation"</span>,</span>
<span id="cb42-41"><a href="#cb42-41" aria-hidden="true" tabindex="-1"></a>                <span class="st">"key_features"</span>: [</span>
<span id="cb42-42"><a href="#cb42-42" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Decentralized adapter training"</span>,</span>
<span id="cb42-43"><a href="#cb42-43" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Privacy-preserving aggregation"</span>,</span>
<span id="cb42-44"><a href="#cb42-44" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Personalized adaptations"</span></span>
<span id="cb42-45"><a href="#cb42-45" aria-hidden="true" tabindex="-1"></a>                ],</span>
<span id="cb42-46"><a href="#cb42-46" aria-hidden="true" tabindex="-1"></a>                <span class="st">"potential_impact"</span>: <span class="st">"Privacy-safe collaboration"</span>,</span>
<span id="cb42-47"><a href="#cb42-47" aria-hidden="true" tabindex="-1"></a>                <span class="st">"maturity"</span>: <span class="st">"Active research"</span></span>
<span id="cb42-48"><a href="#cb42-48" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb42-49"><a href="#cb42-49" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb42-50"><a href="#cb42-50" aria-hidden="true" tabindex="-1"></a>            <span class="st">"neural_architecture_lora"</span>: {</span>
<span id="cb42-51"><a href="#cb42-51" aria-hidden="true" tabindex="-1"></a>                <span class="st">"description"</span>: <span class="st">"Architecture search for optimal LoRA configurations"</span>,</span>
<span id="cb42-52"><a href="#cb42-52" aria-hidden="true" tabindex="-1"></a>                <span class="st">"key_features"</span>: [</span>
<span id="cb42-53"><a href="#cb42-53" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Automated hyperparameter optimization"</span>,</span>
<span id="cb42-54"><a href="#cb42-54" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Architecture-aware adaptation"</span>,</span>
<span id="cb42-55"><a href="#cb42-55" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Performance-efficiency trade-off optimization"</span></span>
<span id="cb42-56"><a href="#cb42-56" aria-hidden="true" tabindex="-1"></a>                ],</span>
<span id="cb42-57"><a href="#cb42-57" aria-hidden="true" tabindex="-1"></a>                <span class="st">"potential_impact"</span>: <span class="st">"Optimal configurations automatically"</span>,</span>
<span id="cb42-58"><a href="#cb42-58" aria-hidden="true" tabindex="-1"></a>                <span class="st">"maturity"</span>: <span class="st">"Research phase"</span></span>
<span id="cb42-59"><a href="#cb42-59" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb42-60"><a href="#cb42-60" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb42-61"><a href="#cb42-61" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb42-62"><a href="#cb42-62" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_research_roadmap(<span class="va">self</span>):</span>
<span id="cb42-63"><a href="#cb42-63" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Generate research roadmap for LoRA development"""</span></span>
<span id="cb42-64"><a href="#cb42-64" aria-hidden="true" tabindex="-1"></a>        roadmap <span class="op">=</span> {</span>
<span id="cb42-65"><a href="#cb42-65" aria-hidden="true" tabindex="-1"></a>            <span class="st">"short_term"</span>: {</span>
<span id="cb42-66"><a href="#cb42-66" aria-hidden="true" tabindex="-1"></a>                <span class="st">"timeframe"</span>: <span class="st">"6-12 months"</span>,</span>
<span id="cb42-67"><a href="#cb42-67" aria-hidden="true" tabindex="-1"></a>                <span class="st">"focus_areas"</span>: [</span>
<span id="cb42-68"><a href="#cb42-68" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Improved rank selection algorithms"</span>,</span>
<span id="cb42-69"><a href="#cb42-69" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Better initialization strategies"</span>, </span>
<span id="cb42-70"><a href="#cb42-70" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Enhanced debugging tools"</span>,</span>
<span id="cb42-71"><a href="#cb42-71" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Standardized evaluation protocols"</span></span>
<span id="cb42-72"><a href="#cb42-72" aria-hidden="true" tabindex="-1"></a>                ],</span>
<span id="cb42-73"><a href="#cb42-73" aria-hidden="true" tabindex="-1"></a>                <span class="st">"expected_outcomes"</span>: [</span>
<span id="cb42-74"><a href="#cb42-74" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"More stable training"</span>,</span>
<span id="cb42-75"><a href="#cb42-75" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Better out-of-box performance"</span>,</span>
<span id="cb42-76"><a href="#cb42-76" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Easier troubleshooting"</span></span>
<span id="cb42-77"><a href="#cb42-77" aria-hidden="true" tabindex="-1"></a>                ]</span>
<span id="cb42-78"><a href="#cb42-78" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb42-79"><a href="#cb42-79" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb42-80"><a href="#cb42-80" aria-hidden="true" tabindex="-1"></a>            <span class="st">"medium_term"</span>: {</span>
<span id="cb42-81"><a href="#cb42-81" aria-hidden="true" tabindex="-1"></a>                <span class="st">"timeframe"</span>: <span class="st">"1-2 years"</span>, </span>
<span id="cb42-82"><a href="#cb42-82" aria-hidden="true" tabindex="-1"></a>                <span class="st">"focus_areas"</span>: [</span>
<span id="cb42-83"><a href="#cb42-83" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Dynamic and adaptive LoRA"</span>,</span>
<span id="cb42-84"><a href="#cb42-84" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Multi-modal LoRA extensions"</span>,</span>
<span id="cb42-85"><a href="#cb42-85" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Automated hyperparameter optimization"</span>,</span>
<span id="cb42-86"><a href="#cb42-86" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Large-scale deployment frameworks"</span></span>
<span id="cb42-87"><a href="#cb42-87" aria-hidden="true" tabindex="-1"></a>                ],</span>
<span id="cb42-88"><a href="#cb42-88" aria-hidden="true" tabindex="-1"></a>                <span class="st">"expected_outcomes"</span>: [</span>
<span id="cb42-89"><a href="#cb42-89" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Self-optimizing systems"</span>,</span>
<span id="cb42-90"><a href="#cb42-90" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Audio-visual-text models"</span>,</span>
<span id="cb42-91"><a href="#cb42-91" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Production-ready pipelines"</span></span>
<span id="cb42-92"><a href="#cb42-92" aria-hidden="true" tabindex="-1"></a>                ]</span>
<span id="cb42-93"><a href="#cb42-93" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb42-94"><a href="#cb42-94" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb42-95"><a href="#cb42-95" aria-hidden="true" tabindex="-1"></a>            <span class="st">"long_term"</span>: {</span>
<span id="cb42-96"><a href="#cb42-96" aria-hidden="true" tabindex="-1"></a>                <span class="st">"timeframe"</span>: <span class="st">"2-5 years"</span>,</span>
<span id="cb42-97"><a href="#cb42-97" aria-hidden="true" tabindex="-1"></a>                <span class="st">"focus_areas"</span>: [</span>
<span id="cb42-98"><a href="#cb42-98" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Theoretical understanding of adaptation"</span>,</span>
<span id="cb42-99"><a href="#cb42-99" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Novel mathematical frameworks"</span>,</span>
<span id="cb42-100"><a href="#cb42-100" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Integration with emerging architectures"</span>,</span>
<span id="cb42-101"><a href="#cb42-101" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Quantum-inspired adaptations"</span></span>
<span id="cb42-102"><a href="#cb42-102" aria-hidden="true" tabindex="-1"></a>                ],</span>
<span id="cb42-103"><a href="#cb42-103" aria-hidden="true" tabindex="-1"></a>                <span class="st">"expected_outcomes"</span>: [</span>
<span id="cb42-104"><a href="#cb42-104" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Principled design guidelines"</span>,</span>
<span id="cb42-105"><a href="#cb42-105" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Next-generation efficiency"</span>,</span>
<span id="cb42-106"><a href="#cb42-106" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Revolutionary capabilities"</span></span>
<span id="cb42-107"><a href="#cb42-107" aria-hidden="true" tabindex="-1"></a>                ]</span>
<span id="cb42-108"><a href="#cb42-108" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb42-109"><a href="#cb42-109" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb42-110"><a href="#cb42-110" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb42-111"><a href="#cb42-111" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> roadmap</span>
<span id="cb42-112"><a href="#cb42-112" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb42-113"><a href="#cb42-113" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict_impact(<span class="va">self</span>, technique_name: <span class="bu">str</span>) <span class="op">-&gt;</span> Dict[<span class="bu">str</span>, Any]:</span>
<span id="cb42-114"><a href="#cb42-114" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Predict potential impact of emerging techniques"""</span></span>
<span id="cb42-115"><a href="#cb42-115" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> technique_name <span class="kw">not</span> <span class="kw">in</span> <span class="va">self</span>.techniques:</span>
<span id="cb42-116"><a href="#cb42-116" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> {<span class="st">"error"</span>: <span class="ss">f"Unknown technique: </span><span class="sc">{</span>technique_name<span class="sc">}</span><span class="ss">"</span>}</span>
<span id="cb42-117"><a href="#cb42-117" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb42-118"><a href="#cb42-118" aria-hidden="true" tabindex="-1"></a>        technique <span class="op">=</span> <span class="va">self</span>.techniques[technique_name]</span>
<span id="cb42-119"><a href="#cb42-119" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb42-120"><a href="#cb42-120" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Simulate impact prediction</span></span>
<span id="cb42-121"><a href="#cb42-121" aria-hidden="true" tabindex="-1"></a>        impact_factors <span class="op">=</span> {</span>
<span id="cb42-122"><a href="#cb42-122" aria-hidden="true" tabindex="-1"></a>            <span class="st">"efficiency_gain"</span>: np.random.uniform(<span class="fl">1.2</span>, <span class="fl">2.5</span>),</span>
<span id="cb42-123"><a href="#cb42-123" aria-hidden="true" tabindex="-1"></a>            <span class="st">"performance_improvement"</span>: np.random.uniform(<span class="fl">0.02</span>, <span class="fl">0.15</span>),</span>
<span id="cb42-124"><a href="#cb42-124" aria-hidden="true" tabindex="-1"></a>            <span class="st">"adoption_timeline"</span>: np.random.choice([<span class="st">"6 months"</span>, <span class="st">"1 year"</span>, <span class="st">"2 years"</span>, <span class="st">"3+ years"</span>]),</span>
<span id="cb42-125"><a href="#cb42-125" aria-hidden="true" tabindex="-1"></a>            <span class="st">"implementation_complexity"</span>: np.random.choice([<span class="st">"low"</span>, <span class="st">"medium"</span>, <span class="st">"high"</span>, <span class="st">"very high"</span>]),</span>
<span id="cb42-126"><a href="#cb42-126" aria-hidden="true" tabindex="-1"></a>            <span class="st">"research_interest"</span>: np.random.uniform(<span class="fl">0.6</span>, <span class="fl">0.95</span>)</span>
<span id="cb42-127"><a href="#cb42-127" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb42-128"><a href="#cb42-128" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb42-129"><a href="#cb42-129" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {</span>
<span id="cb42-130"><a href="#cb42-130" aria-hidden="true" tabindex="-1"></a>            <span class="st">"technique"</span>: technique_name,</span>
<span id="cb42-131"><a href="#cb42-131" aria-hidden="true" tabindex="-1"></a>            <span class="st">"description"</span>: technique[<span class="st">"description"</span>],</span>
<span id="cb42-132"><a href="#cb42-132" aria-hidden="true" tabindex="-1"></a>            <span class="st">"predicted_impact"</span>: impact_factors,</span>
<span id="cb42-133"><a href="#cb42-133" aria-hidden="true" tabindex="-1"></a>            <span class="st">"key_benefits"</span>: technique[<span class="st">"key_features"</span>],</span>
<span id="cb42-134"><a href="#cb42-134" aria-hidden="true" tabindex="-1"></a>            <span class="st">"current_maturity"</span>: technique[<span class="st">"maturity"</span>]</span>
<span id="cb42-135"><a href="#cb42-135" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb42-136"><a href="#cb42-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-137"><a href="#cb42-137" aria-hidden="true" tabindex="-1"></a><span class="co"># Future directions demonstration</span></span>
<span id="cb42-138"><a href="#cb42-138" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Future Directions in LoRA Research:"</span>)</span>
<span id="cb42-139"><a href="#cb42-139" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">40</span>)</span>
<span id="cb42-140"><a href="#cb42-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-141"><a href="#cb42-141" aria-hidden="true" tabindex="-1"></a>future_tech <span class="op">=</span> EmergingLoRATechniques()</span>
<span id="cb42-142"><a href="#cb42-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-143"><a href="#cb42-143" aria-hidden="true" tabindex="-1"></a><span class="co"># Show emerging techniques</span></span>
<span id="cb42-144"><a href="#cb42-144" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Emerging Techniques:"</span>)</span>
<span id="cb42-145"><a href="#cb42-145" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, info <span class="kw">in</span> future_tech.techniques.items():</span>
<span id="cb42-146"><a href="#cb42-146" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span>name<span class="sc">.</span>replace(<span class="st">'_'</span>, <span class="st">' '</span>)<span class="sc">.</span>title()<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb42-147"><a href="#cb42-147" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  • </span><span class="sc">{</span>info[<span class="st">'description'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb42-148"><a href="#cb42-148" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  • Potential impact: </span><span class="sc">{</span>info[<span class="st">'potential_impact'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb42-149"><a href="#cb42-149" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  • Maturity: </span><span class="sc">{</span>info[<span class="st">'maturity'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb42-150"><a href="#cb42-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-151"><a href="#cb42-151" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">40</span>)</span>
<span id="cb42-152"><a href="#cb42-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-153"><a href="#cb42-153" aria-hidden="true" tabindex="-1"></a><span class="co"># Research roadmap</span></span>
<span id="cb42-154"><a href="#cb42-154" aria-hidden="true" tabindex="-1"></a>roadmap <span class="op">=</span> future_tech.get_research_roadmap()</span>
<span id="cb42-155"><a href="#cb42-155" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Research Roadmap:"</span>)</span>
<span id="cb42-156"><a href="#cb42-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-157"><a href="#cb42-157" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> term, details <span class="kw">in</span> roadmap.items():</span>
<span id="cb42-158"><a href="#cb42-158" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span>term<span class="sc">.</span>replace(<span class="st">'_'</span>, <span class="st">' '</span>)<span class="sc">.</span>title()<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>details[<span class="st">'timeframe'</span>]<span class="sc">}</span><span class="ss">):"</span>)</span>
<span id="cb42-159"><a href="#cb42-159" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"  Focus Areas:"</span>)</span>
<span id="cb42-160"><a href="#cb42-160" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> area <span class="kw">in</span> details[<span class="st">'focus_areas'</span>]:</span>
<span id="cb42-161"><a href="#cb42-161" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"    • </span><span class="sc">{</span>area<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb42-162"><a href="#cb42-162" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"  Expected Outcomes:"</span>)</span>
<span id="cb42-163"><a href="#cb42-163" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> outcome <span class="kw">in</span> details[<span class="st">'expected_outcomes'</span>]:</span>
<span id="cb42-164"><a href="#cb42-164" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"    ✓ </span><span class="sc">{</span>outcome<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb42-165"><a href="#cb42-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-166"><a href="#cb42-166" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">40</span>)</span>
<span id="cb42-167"><a href="#cb42-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-168"><a href="#cb42-168" aria-hidden="true" tabindex="-1"></a><span class="co"># Impact prediction example</span></span>
<span id="cb42-169"><a href="#cb42-169" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Impact Prediction Example:"</span>)</span>
<span id="cb42-170"><a href="#cb42-170" aria-hidden="true" tabindex="-1"></a>prediction <span class="op">=</span> future_tech.predict_impact(<span class="st">"dynamic_lora"</span>)</span>
<span id="cb42-171"><a href="#cb42-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-172"><a href="#cb42-172" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Technique: </span><span class="sc">{</span>prediction[<span class="st">'technique'</span>]<span class="sc">.</span>replace(<span class="st">'_'</span>, <span class="st">' '</span>)<span class="sc">.</span>title()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb42-173"><a href="#cb42-173" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Description: </span><span class="sc">{</span>prediction[<span class="st">'description'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb42-174"><a href="#cb42-174" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Predicted Impact:"</span>)</span>
<span id="cb42-175"><a href="#cb42-175" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> factor, value <span class="kw">in</span> prediction[<span class="st">'predicted_impact'</span>].items():</span>
<span id="cb42-176"><a href="#cb42-176" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(value, <span class="bu">float</span>):</span>
<span id="cb42-177"><a href="#cb42-177" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">'gain'</span> <span class="kw">in</span> factor <span class="kw">or</span> <span class="st">'improvement'</span> <span class="kw">in</span> factor:</span>
<span id="cb42-178"><a href="#cb42-178" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"  • </span><span class="sc">{</span>factor<span class="sc">.</span>replace(<span class="st">'_'</span>, <span class="st">' '</span>)<span class="sc">.</span>title()<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>value<span class="sc">:.1f}</span><span class="ss">x"</span> <span class="cf">if</span> <span class="st">'gain'</span> <span class="kw">in</span> factor <span class="cf">else</span> <span class="ss">f"  • </span><span class="sc">{</span>factor<span class="sc">.</span>replace(<span class="st">'_'</span>, <span class="st">' '</span>)<span class="sc">.</span>title()<span class="sc">}</span><span class="ss">: +</span><span class="sc">{</span>value<span class="sc">:.1%}</span><span class="ss">"</span>)</span>
<span id="cb42-179"><a href="#cb42-179" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb42-180"><a href="#cb42-180" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"  • </span><span class="sc">{</span>factor<span class="sc">.</span>replace(<span class="st">'_'</span>, <span class="st">' '</span>)<span class="sc">.</span>title()<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>value<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb42-181"><a href="#cb42-181" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb42-182"><a href="#cb42-182" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  • </span><span class="sc">{</span>factor<span class="sc">.</span>replace(<span class="st">'_'</span>, <span class="st">' '</span>)<span class="sc">.</span>title()<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>value<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Future Directions in LoRA Research:
========================================

Emerging Techniques:

Dynamic Lora:
  • Adaptive rank and module selection during training
  • Potential impact: 30-50% efficiency improvement
  • Maturity: Research phase

Hierarchical Lora:
  • Multi-level adaptation for different abstraction levels
  • Potential impact: Better transfer learning
  • Maturity: Early development

Conditional Lora:
  • Task-conditional parameter generation
  • Potential impact: Unlimited task adaptation
  • Maturity: Conceptual

Federated Lora:
  • Distributed learning with privacy preservation
  • Potential impact: Privacy-safe collaboration
  • Maturity: Active research

Neural Architecture Lora:
  • Architecture search for optimal LoRA configurations
  • Potential impact: Optimal configurations automatically
  • Maturity: Research phase

========================================

Research Roadmap:

Short Term (6-12 months):
  Focus Areas:
    • Improved rank selection algorithms
    • Better initialization strategies
    • Enhanced debugging tools
    • Standardized evaluation protocols
  Expected Outcomes:
    ✓ More stable training
    ✓ Better out-of-box performance
    ✓ Easier troubleshooting

Medium Term (1-2 years):
  Focus Areas:
    • Dynamic and adaptive LoRA
    • Multi-modal LoRA extensions
    • Automated hyperparameter optimization
    • Large-scale deployment frameworks
  Expected Outcomes:
    ✓ Self-optimizing systems
    ✓ Audio-visual-text models
    ✓ Production-ready pipelines

Long Term (2-5 years):
  Focus Areas:
    • Theoretical understanding of adaptation
    • Novel mathematical frameworks
    • Integration with emerging architectures
    • Quantum-inspired adaptations
  Expected Outcomes:
    ✓ Principled design guidelines
    ✓ Next-generation efficiency
    ✓ Revolutionary capabilities

========================================

Impact Prediction Example:
Technique: Dynamic Lora
Description: Adaptive rank and module selection during training
Predicted Impact:
  • Efficiency Gain: 1.8x
  • Performance Improvement: +3.0%
  • Adoption Timeline: 6 months
  • Implementation Complexity: medium
  • Research Interest: 0.94</code></pre>
</div>
</div>
</section>
<section id="research-opportunities" class="level3">
<h3 class="anchored" data-anchor-id="research-opportunities">Research Opportunities</h3>
<div id="research-opportunities" class="cell" data-execution_count="28">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LoRAResearchOpportunities:</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Identify key research opportunities in LoRA for VLMs"""</span></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.research_areas <span class="op">=</span> {</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>            <span class="st">"theoretical_analysis"</span>: {</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>                <span class="st">"priority"</span>: <span class="st">"high"</span>,</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>                <span class="st">"description"</span>: <span class="st">"Better understanding of LoRA's approximation capabilities"</span>,</span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>                <span class="st">"open_questions"</span>: [</span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"What is the theoretical limit of low-rank approximation?"</span>,</span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"How does rank relate to task complexity?"</span>,</span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Can we predict optimal rank analytically?"</span>,</span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"What are the convergence guarantees?"</span></span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a>                ],</span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a>                <span class="st">"potential_methods"</span>: [</span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Matrix perturbation theory"</span>,</span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Information theory analysis"</span>, </span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Optimization theory"</span>,</span>
<span id="cb44-19"><a href="#cb44-19" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Statistical learning theory"</span></span>
<span id="cb44-20"><a href="#cb44-20" aria-hidden="true" tabindex="-1"></a>                ]</span>
<span id="cb44-21"><a href="#cb44-21" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb44-22"><a href="#cb44-22" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb44-23"><a href="#cb44-23" aria-hidden="true" tabindex="-1"></a>            <span class="st">"architecture_specific"</span>: {</span>
<span id="cb44-24"><a href="#cb44-24" aria-hidden="true" tabindex="-1"></a>                <span class="st">"priority"</span>: <span class="st">"high"</span>,</span>
<span id="cb44-25"><a href="#cb44-25" aria-hidden="true" tabindex="-1"></a>                <span class="st">"description"</span>: <span class="st">"Optimized LoRA for different VLM architectures"</span>,</span>
<span id="cb44-26"><a href="#cb44-26" aria-hidden="true" tabindex="-1"></a>                <span class="st">"open_questions"</span>: [</span>
<span id="cb44-27"><a href="#cb44-27" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"How should LoRA differ for Transformers vs CNNs?"</span>,</span>
<span id="cb44-28"><a href="#cb44-28" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"What's optimal for diffusion models?"</span>,</span>
<span id="cb44-29"><a href="#cb44-29" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"How to handle multi-scale architectures?"</span>,</span>
<span id="cb44-30"><a href="#cb44-30" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"What about retrieval-augmented models?"</span></span>
<span id="cb44-31"><a href="#cb44-31" aria-hidden="true" tabindex="-1"></a>                ],</span>
<span id="cb44-32"><a href="#cb44-32" aria-hidden="true" tabindex="-1"></a>                <span class="st">"potential_methods"</span>: [</span>
<span id="cb44-33"><a href="#cb44-33" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Architecture-aware rank selection"</span>,</span>
<span id="cb44-34"><a href="#cb44-34" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Layer-type specific adaptations"</span>,</span>
<span id="cb44-35"><a href="#cb44-35" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Scale-dependent parameters"</span>,</span>
<span id="cb44-36"><a href="#cb44-36" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Retrieval-aware fine-tuning"</span></span>
<span id="cb44-37"><a href="#cb44-37" aria-hidden="true" tabindex="-1"></a>                ]</span>
<span id="cb44-38"><a href="#cb44-38" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb44-39"><a href="#cb44-39" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb44-40"><a href="#cb44-40" aria-hidden="true" tabindex="-1"></a>            <span class="st">"multimodal_extensions"</span>: {</span>
<span id="cb44-41"><a href="#cb44-41" aria-hidden="true" tabindex="-1"></a>                <span class="st">"priority"</span>: <span class="st">"medium"</span>,</span>
<span id="cb44-42"><a href="#cb44-42" aria-hidden="true" tabindex="-1"></a>                <span class="st">"description"</span>: <span class="st">"LoRA for audio-visual-text models"</span>,</span>
<span id="cb44-43"><a href="#cb44-43" aria-hidden="true" tabindex="-1"></a>                <span class="st">"open_questions"</span>: [</span>
<span id="cb44-44"><a href="#cb44-44" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"How to balance modality-specific adaptations?"</span>,</span>
<span id="cb44-45"><a href="#cb44-45" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Can we share parameters across modalities?"</span>,</span>
<span id="cb44-46"><a href="#cb44-46" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"How to handle temporal dynamics?"</span>,</span>
<span id="cb44-47"><a href="#cb44-47" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"What about cross-modal attention?"</span></span>
<span id="cb44-48"><a href="#cb44-48" aria-hidden="true" tabindex="-1"></a>                ],</span>
<span id="cb44-49"><a href="#cb44-49" aria-hidden="true" tabindex="-1"></a>                <span class="st">"potential_methods"</span>: [</span>
<span id="cb44-50"><a href="#cb44-50" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Modality-aware parameter sharing"</span>,</span>
<span id="cb44-51"><a href="#cb44-51" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Temporal LoRA for sequences"</span>,</span>
<span id="cb44-52"><a href="#cb44-52" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Cross-modal adaptation matrices"</span>,</span>
<span id="cb44-53"><a href="#cb44-53" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Hierarchical multimodal LoRA"</span></span>
<span id="cb44-54"><a href="#cb44-54" aria-hidden="true" tabindex="-1"></a>                ]</span>
<span id="cb44-55"><a href="#cb44-55" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb44-56"><a href="#cb44-56" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb44-57"><a href="#cb44-57" aria-hidden="true" tabindex="-1"></a>            <span class="st">"continual_learning"</span>: {</span>
<span id="cb44-58"><a href="#cb44-58" aria-hidden="true" tabindex="-1"></a>                <span class="st">"priority"</span>: <span class="st">"medium"</span>, </span>
<span id="cb44-59"><a href="#cb44-59" aria-hidden="true" tabindex="-1"></a>                <span class="st">"description"</span>: <span class="st">"LoRA for lifelong learning in VLMs"</span>,</span>
<span id="cb44-60"><a href="#cb44-60" aria-hidden="true" tabindex="-1"></a>                <span class="st">"open_questions"</span>: [</span>
<span id="cb44-61"><a href="#cb44-61" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"How to prevent catastrophic forgetting?"</span>,</span>
<span id="cb44-62"><a href="#cb44-62" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Can we grow adapters over time?"</span>,</span>
<span id="cb44-63"><a href="#cb44-63" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"How to balance old vs new knowledge?"</span>,</span>
<span id="cb44-64"><a href="#cb44-64" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"What about task interference?"</span></span>
<span id="cb44-65"><a href="#cb44-65" aria-hidden="true" tabindex="-1"></a>                ],</span>
<span id="cb44-66"><a href="#cb44-66" aria-hidden="true" tabindex="-1"></a>                <span class="st">"potential_methods"</span>: [</span>
<span id="cb44-67"><a href="#cb44-67" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Progressive adapter growth"</span>,</span>
<span id="cb44-68"><a href="#cb44-68" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Memory-based parameter selection"</span>,</span>
<span id="cb44-69"><a href="#cb44-69" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Task-specific adapter routing"</span>,</span>
<span id="cb44-70"><a href="#cb44-70" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Elastic weight consolidation for LoRA"</span></span>
<span id="cb44-71"><a href="#cb44-71" aria-hidden="true" tabindex="-1"></a>                ]</span>
<span id="cb44-72"><a href="#cb44-72" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb44-73"><a href="#cb44-73" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb44-74"><a href="#cb44-74" aria-hidden="true" tabindex="-1"></a>            <span class="st">"efficiency_optimization"</span>: {</span>
<span id="cb44-75"><a href="#cb44-75" aria-hidden="true" tabindex="-1"></a>                <span class="st">"priority"</span>: <span class="st">"high"</span>,</span>
<span id="cb44-76"><a href="#cb44-76" aria-hidden="true" tabindex="-1"></a>                <span class="st">"description"</span>: <span class="st">"Hardware-aware LoRA optimization"</span>,</span>
<span id="cb44-77"><a href="#cb44-77" aria-hidden="true" tabindex="-1"></a>                <span class="st">"open_questions"</span>: [</span>
<span id="cb44-78"><a href="#cb44-78" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"How to optimize for different hardware?"</span>,</span>
<span id="cb44-79"><a href="#cb44-79" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Can we quantize LoRA parameters?"</span>,</span>
<span id="cb44-80"><a href="#cb44-80" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"What about sparsity in adaptations?"</span>,</span>
<span id="cb44-81"><a href="#cb44-81" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"How to minimize memory bandwidth?"</span></span>
<span id="cb44-82"><a href="#cb44-82" aria-hidden="true" tabindex="-1"></a>                ],</span>
<span id="cb44-83"><a href="#cb44-83" aria-hidden="true" tabindex="-1"></a>                <span class="st">"potential_methods"</span>: [</span>
<span id="cb44-84"><a href="#cb44-84" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Hardware-aware rank selection"</span>,</span>
<span id="cb44-85"><a href="#cb44-85" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Quantized LoRA parameters"</span>,</span>
<span id="cb44-86"><a href="#cb44-86" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Sparse adaptation matrices"</span>,</span>
<span id="cb44-87"><a href="#cb44-87" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Memory-efficient implementations"</span></span>
<span id="cb44-88"><a href="#cb44-88" aria-hidden="true" tabindex="-1"></a>                ]</span>
<span id="cb44-89"><a href="#cb44-89" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb44-90"><a href="#cb44-90" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb44-91"><a href="#cb44-91" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb44-92"><a href="#cb44-92" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> generate_research_proposals(<span class="va">self</span>, area: <span class="bu">str</span>) <span class="op">-&gt;</span> Dict[<span class="bu">str</span>, Any]:</span>
<span id="cb44-93"><a href="#cb44-93" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Generate specific research proposals for an area"""</span></span>
<span id="cb44-94"><a href="#cb44-94" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> area <span class="kw">not</span> <span class="kw">in</span> <span class="va">self</span>.research_areas:</span>
<span id="cb44-95"><a href="#cb44-95" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> {<span class="st">"error"</span>: <span class="ss">f"Unknown research area: </span><span class="sc">{</span>area<span class="sc">}</span><span class="ss">"</span>}</span>
<span id="cb44-96"><a href="#cb44-96" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb44-97"><a href="#cb44-97" aria-hidden="true" tabindex="-1"></a>        area_info <span class="op">=</span> <span class="va">self</span>.research_areas[area]</span>
<span id="cb44-98"><a href="#cb44-98" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb44-99"><a href="#cb44-99" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Generate specific research proposals</span></span>
<span id="cb44-100"><a href="#cb44-100" aria-hidden="true" tabindex="-1"></a>        proposals <span class="op">=</span> []</span>
<span id="cb44-101"><a href="#cb44-101" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb44-102"><a href="#cb44-102" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, question <span class="kw">in</span> <span class="bu">enumerate</span>(area_info[<span class="st">"open_questions"</span>][:<span class="dv">3</span>]):  <span class="co"># Top 3 questions</span></span>
<span id="cb44-103"><a href="#cb44-103" aria-hidden="true" tabindex="-1"></a>            proposal <span class="op">=</span> {</span>
<span id="cb44-104"><a href="#cb44-104" aria-hidden="true" tabindex="-1"></a>                <span class="st">"title"</span>: <span class="ss">f"Investigation of </span><span class="sc">{</span>question<span class="sc">.</span>replace(<span class="st">'?'</span>, <span class="st">''</span>)<span class="sc">}</span><span class="ss">"</span>,</span>
<span id="cb44-105"><a href="#cb44-105" aria-hidden="true" tabindex="-1"></a>                <span class="st">"objective"</span>: question,</span>
<span id="cb44-106"><a href="#cb44-106" aria-hidden="true" tabindex="-1"></a>                <span class="st">"methodology"</span>: area_info[<span class="st">"potential_methods"</span>][i] <span class="cf">if</span> i <span class="op">&lt;</span> <span class="bu">len</span>(area_info[<span class="st">"potential_methods"</span>]) <span class="cf">else</span> <span class="st">"To be determined"</span>,</span>
<span id="cb44-107"><a href="#cb44-107" aria-hidden="true" tabindex="-1"></a>                <span class="st">"expected_timeline"</span>: <span class="st">"12-18 months"</span>,</span>
<span id="cb44-108"><a href="#cb44-108" aria-hidden="true" tabindex="-1"></a>                <span class="st">"required_resources"</span>: [<span class="st">"GPU cluster"</span>, <span class="st">"Research team"</span>, <span class="st">"Datasets"</span>],</span>
<span id="cb44-109"><a href="#cb44-109" aria-hidden="true" tabindex="-1"></a>                <span class="st">"success_metrics"</span>: [</span>
<span id="cb44-110"><a href="#cb44-110" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Theoretical insights published"</span>,</span>
<span id="cb44-111"><a href="#cb44-111" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Empirical validation completed"</span>, </span>
<span id="cb44-112"><a href="#cb44-112" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"Performance improvements demonstrated"</span></span>
<span id="cb44-113"><a href="#cb44-113" aria-hidden="true" tabindex="-1"></a>                ]</span>
<span id="cb44-114"><a href="#cb44-114" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb44-115"><a href="#cb44-115" aria-hidden="true" tabindex="-1"></a>            proposals.append(proposal)</span>
<span id="cb44-116"><a href="#cb44-116" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb44-117"><a href="#cb44-117" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {</span>
<span id="cb44-118"><a href="#cb44-118" aria-hidden="true" tabindex="-1"></a>            <span class="st">"research_area"</span>: area,</span>
<span id="cb44-119"><a href="#cb44-119" aria-hidden="true" tabindex="-1"></a>            <span class="st">"priority"</span>: area_info[<span class="st">"priority"</span>],</span>
<span id="cb44-120"><a href="#cb44-120" aria-hidden="true" tabindex="-1"></a>            <span class="st">"description"</span>: area_info[<span class="st">"description"</span>],</span>
<span id="cb44-121"><a href="#cb44-121" aria-hidden="true" tabindex="-1"></a>            <span class="st">"proposals"</span>: proposals</span>
<span id="cb44-122"><a href="#cb44-122" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb44-123"><a href="#cb44-123" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb44-124"><a href="#cb44-124" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> assess_research_impact(<span class="va">self</span>) <span class="op">-&gt;</span> Dict[<span class="bu">str</span>, Any]:</span>
<span id="cb44-125"><a href="#cb44-125" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Assess potential impact of different research areas"""</span></span>
<span id="cb44-126"><a href="#cb44-126" aria-hidden="true" tabindex="-1"></a>        impact_assessment <span class="op">=</span> {}</span>
<span id="cb44-127"><a href="#cb44-127" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb44-128"><a href="#cb44-128" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> area, info <span class="kw">in</span> <span class="va">self</span>.research_areas.items():</span>
<span id="cb44-129"><a href="#cb44-129" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Simulate impact scoring</span></span>
<span id="cb44-130"><a href="#cb44-130" aria-hidden="true" tabindex="-1"></a>            scores <span class="op">=</span> {</span>
<span id="cb44-131"><a href="#cb44-131" aria-hidden="true" tabindex="-1"></a>                <span class="st">"scientific_impact"</span>: np.random.uniform(<span class="fl">0.6</span>, <span class="fl">0.95</span>),</span>
<span id="cb44-132"><a href="#cb44-132" aria-hidden="true" tabindex="-1"></a>                <span class="st">"practical_impact"</span>: np.random.uniform(<span class="fl">0.5</span>, <span class="fl">0.9</span>),</span>
<span id="cb44-133"><a href="#cb44-133" aria-hidden="true" tabindex="-1"></a>                <span class="st">"timeline_feasibility"</span>: np.random.uniform(<span class="fl">0.4</span>, <span class="fl">0.8</span>),</span>
<span id="cb44-134"><a href="#cb44-134" aria-hidden="true" tabindex="-1"></a>                <span class="st">"resource_requirements"</span>: np.random.uniform(<span class="fl">0.3</span>, <span class="fl">0.9</span>),</span>
<span id="cb44-135"><a href="#cb44-135" aria-hidden="true" tabindex="-1"></a>                <span class="st">"collaboration_potential"</span>: np.random.uniform(<span class="fl">0.5</span>, <span class="fl">0.95</span>)</span>
<span id="cb44-136"><a href="#cb44-136" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb44-137"><a href="#cb44-137" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb44-138"><a href="#cb44-138" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Compute overall impact score</span></span>
<span id="cb44-139"><a href="#cb44-139" aria-hidden="true" tabindex="-1"></a>            weights <span class="op">=</span> {<span class="st">"scientific_impact"</span>: <span class="fl">0.3</span>, <span class="st">"practical_impact"</span>: <span class="fl">0.3</span>, </span>
<span id="cb44-140"><a href="#cb44-140" aria-hidden="true" tabindex="-1"></a>                      <span class="st">"timeline_feasibility"</span>: <span class="fl">0.2</span>, <span class="st">"resource_requirements"</span>: <span class="fl">0.1</span>,</span>
<span id="cb44-141"><a href="#cb44-141" aria-hidden="true" tabindex="-1"></a>                      <span class="st">"collaboration_potential"</span>: <span class="fl">0.1</span>}</span>
<span id="cb44-142"><a href="#cb44-142" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb44-143"><a href="#cb44-143" aria-hidden="true" tabindex="-1"></a>            overall_score <span class="op">=</span> <span class="bu">sum</span>(scores[metric] <span class="op">*</span> weight <span class="cf">for</span> metric, weight <span class="kw">in</span> weights.items())</span>
<span id="cb44-144"><a href="#cb44-144" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb44-145"><a href="#cb44-145" aria-hidden="true" tabindex="-1"></a>            impact_assessment[area] <span class="op">=</span> {</span>
<span id="cb44-146"><a href="#cb44-146" aria-hidden="true" tabindex="-1"></a>                <span class="st">"priority"</span>: info[<span class="st">"priority"</span>],</span>
<span id="cb44-147"><a href="#cb44-147" aria-hidden="true" tabindex="-1"></a>                <span class="st">"scores"</span>: scores,</span>
<span id="cb44-148"><a href="#cb44-148" aria-hidden="true" tabindex="-1"></a>                <span class="st">"overall_impact"</span>: overall_score,</span>
<span id="cb44-149"><a href="#cb44-149" aria-hidden="true" tabindex="-1"></a>                <span class="st">"recommendation"</span>: <span class="st">"high priority"</span> <span class="cf">if</span> overall_score <span class="op">&gt;</span> <span class="fl">0.75</span> <span class="cf">else</span> <span class="st">"medium priority"</span> <span class="cf">if</span> overall_score <span class="op">&gt;</span> <span class="fl">0.6</span> <span class="cf">else</span> <span class="st">"low priority"</span></span>
<span id="cb44-150"><a href="#cb44-150" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb44-151"><a href="#cb44-151" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb44-152"><a href="#cb44-152" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> impact_assessment</span>
<span id="cb44-153"><a href="#cb44-153" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb44-154"><a href="#cb44-154" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> create_collaboration_map(<span class="va">self</span>) <span class="op">-&gt;</span> Dict[<span class="bu">str</span>, Any]:</span>
<span id="cb44-155"><a href="#cb44-155" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Create collaboration opportunities map"""</span></span>
<span id="cb44-156"><a href="#cb44-156" aria-hidden="true" tabindex="-1"></a>        collaborations <span class="op">=</span> {</span>
<span id="cb44-157"><a href="#cb44-157" aria-hidden="true" tabindex="-1"></a>            <span class="st">"academic_institutions"</span>: [</span>
<span id="cb44-158"><a href="#cb44-158" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Computer Vision labs for VLM architectures"</span>,</span>
<span id="cb44-159"><a href="#cb44-159" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Machine Learning theory groups for theoretical analysis"</span>,</span>
<span id="cb44-160"><a href="#cb44-160" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Systems labs for efficiency optimization"</span>,</span>
<span id="cb44-161"><a href="#cb44-161" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Cognitive Science for multimodal understanding"</span></span>
<span id="cb44-162"><a href="#cb44-162" aria-hidden="true" tabindex="-1"></a>            ],</span>
<span id="cb44-163"><a href="#cb44-163" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb44-164"><a href="#cb44-164" aria-hidden="true" tabindex="-1"></a>            <span class="st">"industry_partners"</span>: [</span>
<span id="cb44-165"><a href="#cb44-165" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Cloud providers for large-scale deployment"</span>,</span>
<span id="cb44-166"><a href="#cb44-166" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Hardware manufacturers for optimization"</span>,</span>
<span id="cb44-167"><a href="#cb44-167" aria-hidden="true" tabindex="-1"></a>                <span class="st">"AI companies for real-world applications"</span>,</span>
<span id="cb44-168"><a href="#cb44-168" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Research labs for cutting-edge techniques"</span></span>
<span id="cb44-169"><a href="#cb44-169" aria-hidden="true" tabindex="-1"></a>            ],</span>
<span id="cb44-170"><a href="#cb44-170" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb44-171"><a href="#cb44-171" aria-hidden="true" tabindex="-1"></a>            <span class="st">"interdisciplinary_opportunities"</span>: [</span>
<span id="cb44-172"><a href="#cb44-172" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Neuroscience: Brain-inspired adaptation mechanisms"</span>,</span>
<span id="cb44-173"><a href="#cb44-173" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Mathematics: Advanced matrix theory applications"</span>,</span>
<span id="cb44-174"><a href="#cb44-174" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Psychology: Human-like learning patterns"</span>,</span>
<span id="cb44-175"><a href="#cb44-175" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Engineering: Hardware-software co-design"</span></span>
<span id="cb44-176"><a href="#cb44-176" aria-hidden="true" tabindex="-1"></a>            ],</span>
<span id="cb44-177"><a href="#cb44-177" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb44-178"><a href="#cb44-178" aria-hidden="true" tabindex="-1"></a>            <span class="st">"funding_opportunities"</span>: [</span>
<span id="cb44-179"><a href="#cb44-179" aria-hidden="true" tabindex="-1"></a>                <span class="st">"NSF: Theoretical foundations of adaptation"</span>,</span>
<span id="cb44-180"><a href="#cb44-180" aria-hidden="true" tabindex="-1"></a>                <span class="st">"DARPA: Efficient AI systems"</span>,</span>
<span id="cb44-181"><a href="#cb44-181" aria-hidden="true" tabindex="-1"></a>                <span class="st">"NIH: Medical imaging applications"</span>,</span>
<span id="cb44-182"><a href="#cb44-182" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Industry grants: Practical deployments"</span></span>
<span id="cb44-183"><a href="#cb44-183" aria-hidden="true" tabindex="-1"></a>            ]</span>
<span id="cb44-184"><a href="#cb44-184" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb44-185"><a href="#cb44-185" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb44-186"><a href="#cb44-186" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> collaborations</span>
<span id="cb44-187"><a href="#cb44-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-188"><a href="#cb44-188" aria-hidden="true" tabindex="-1"></a><span class="co"># Research opportunities demonstration</span></span>
<span id="cb44-189"><a href="#cb44-189" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"LoRA Research Opportunities:"</span>)</span>
<span id="cb44-190"><a href="#cb44-190" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">35</span>)</span>
<span id="cb44-191"><a href="#cb44-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-192"><a href="#cb44-192" aria-hidden="true" tabindex="-1"></a>research_ops <span class="op">=</span> LoRAResearchOpportunities()</span>
<span id="cb44-193"><a href="#cb44-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-194"><a href="#cb44-194" aria-hidden="true" tabindex="-1"></a><span class="co"># Show high-priority research areas</span></span>
<span id="cb44-195"><a href="#cb44-195" aria-hidden="true" tabindex="-1"></a>high_priority_areas <span class="op">=</span> [area <span class="cf">for</span> area, info <span class="kw">in</span> research_ops.research_areas.items() </span>
<span id="cb44-196"><a href="#cb44-196" aria-hidden="true" tabindex="-1"></a>                      <span class="cf">if</span> info[<span class="st">"priority"</span>] <span class="op">==</span> <span class="st">"high"</span>]</span>
<span id="cb44-197"><a href="#cb44-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-198"><a href="#cb44-198" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"High-Priority Research Areas:"</span>)</span>
<span id="cb44-199"><a href="#cb44-199" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> area <span class="kw">in</span> high_priority_areas:</span>
<span id="cb44-200"><a href="#cb44-200" aria-hidden="true" tabindex="-1"></a>    info <span class="op">=</span> research_ops.research_areas[area]</span>
<span id="cb44-201"><a href="#cb44-201" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span>area<span class="sc">.</span>replace(<span class="st">'_'</span>, <span class="st">' '</span>)<span class="sc">.</span>title()<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb44-202"><a href="#cb44-202" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  • </span><span class="sc">{</span>info[<span class="st">'description'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb44-203"><a href="#cb44-203" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  • Key questions: </span><span class="sc">{</span><span class="bu">len</span>(info[<span class="st">'open_questions'</span>])<span class="sc">}</span><span class="ss"> identified"</span>)</span>
<span id="cb44-204"><a href="#cb44-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-205"><a href="#cb44-205" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">35</span>)</span>
<span id="cb44-206"><a href="#cb44-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-207"><a href="#cb44-207" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate detailed proposal for one area</span></span>
<span id="cb44-208"><a href="#cb44-208" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Detailed Research Proposal Example:"</span>)</span>
<span id="cb44-209"><a href="#cb44-209" aria-hidden="true" tabindex="-1"></a>proposal_details <span class="op">=</span> research_ops.generate_research_proposals(<span class="st">"theoretical_analysis"</span>)</span>
<span id="cb44-210"><a href="#cb44-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-211"><a href="#cb44-211" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Area: </span><span class="sc">{</span>proposal_details[<span class="st">'research_area'</span>]<span class="sc">.</span>replace(<span class="st">'_'</span>, <span class="st">' '</span>)<span class="sc">.</span>title()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb44-212"><a href="#cb44-212" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Priority: </span><span class="sc">{</span>proposal_details[<span class="st">'priority'</span>]<span class="sc">.</span>upper()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb44-213"><a href="#cb44-213" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Description: </span><span class="sc">{</span>proposal_details[<span class="st">'description'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb44-214"><a href="#cb44-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-215"><a href="#cb44-215" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">'proposals'</span> <span class="kw">in</span> proposal_details:</span>
<span id="cb44-216"><a href="#cb44-216" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, proposal <span class="kw">in</span> <span class="bu">enumerate</span>(proposal_details[<span class="st">'proposals'</span>][:<span class="dv">1</span>], <span class="dv">1</span>):  <span class="co"># Show first proposal</span></span>
<span id="cb44-217"><a href="#cb44-217" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Proposal </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>proposal[<span class="st">'title'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb44-218"><a href="#cb44-218" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Objective: </span><span class="sc">{</span>proposal[<span class="st">'objective'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb44-219"><a href="#cb44-219" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Methodology: </span><span class="sc">{</span>proposal[<span class="st">'methodology'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb44-220"><a href="#cb44-220" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Timeline: </span><span class="sc">{</span>proposal[<span class="st">'expected_timeline'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb44-221"><a href="#cb44-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-222"><a href="#cb44-222" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">35</span>)</span>
<span id="cb44-223"><a href="#cb44-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-224"><a href="#cb44-224" aria-hidden="true" tabindex="-1"></a><span class="co"># Impact assessment</span></span>
<span id="cb44-225"><a href="#cb44-225" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Research Impact Assessment:"</span>)</span>
<span id="cb44-226"><a href="#cb44-226" aria-hidden="true" tabindex="-1"></a>impact_assessment <span class="op">=</span> research_ops.assess_research_impact()</span>
<span id="cb44-227"><a href="#cb44-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-228"><a href="#cb44-228" aria-hidden="true" tabindex="-1"></a><span class="co"># Sort by overall impact</span></span>
<span id="cb44-229"><a href="#cb44-229" aria-hidden="true" tabindex="-1"></a>sorted_areas <span class="op">=</span> <span class="bu">sorted</span>(impact_assessment.items(), </span>
<span id="cb44-230"><a href="#cb44-230" aria-hidden="true" tabindex="-1"></a>                     key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="dv">1</span>][<span class="st">'overall_impact'</span>], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb44-231"><a href="#cb44-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-232"><a href="#cb44-232" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> area, assessment <span class="kw">in</span> sorted_areas:</span>
<span id="cb44-233"><a href="#cb44-233" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span>area<span class="sc">.</span>replace(<span class="st">'_'</span>, <span class="st">' '</span>)<span class="sc">.</span>title()<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb44-234"><a href="#cb44-234" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Overall Impact: </span><span class="sc">{</span>assessment[<span class="st">'overall_impact'</span>]<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb44-235"><a href="#cb44-235" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Recommendation: </span><span class="sc">{</span>assessment[<span class="st">'recommendation'</span>]<span class="sc">.</span>upper()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb44-236"><a href="#cb44-236" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Scientific Impact: </span><span class="sc">{</span>assessment[<span class="st">'scores'</span>][<span class="st">'scientific_impact'</span>]<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb44-237"><a href="#cb44-237" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Practical Impact: </span><span class="sc">{</span>assessment[<span class="st">'scores'</span>][<span class="st">'practical_impact'</span>]<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb44-238"><a href="#cb44-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-239"><a href="#cb44-239" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">35</span>)</span>
<span id="cb44-240"><a href="#cb44-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-241"><a href="#cb44-241" aria-hidden="true" tabindex="-1"></a><span class="co"># Collaboration opportunities</span></span>
<span id="cb44-242"><a href="#cb44-242" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Collaboration Opportunities:"</span>)</span>
<span id="cb44-243"><a href="#cb44-243" aria-hidden="true" tabindex="-1"></a>collab_map <span class="op">=</span> research_ops.create_collaboration_map()</span>
<span id="cb44-244"><a href="#cb44-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-245"><a href="#cb44-245" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> category, opportunities <span class="kw">in</span> collab_map.items():</span>
<span id="cb44-246"><a href="#cb44-246" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span>category<span class="sc">.</span>replace(<span class="st">'_'</span>, <span class="st">' '</span>)<span class="sc">.</span>title()<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb44-247"><a href="#cb44-247" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> opportunity <span class="kw">in</span> opportunities[:<span class="dv">2</span>]:  <span class="co"># Show first 2</span></span>
<span id="cb44-248"><a href="#cb44-248" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  • </span><span class="sc">{</span>opportunity<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>LoRA Research Opportunities:
===================================
High-Priority Research Areas:

Theoretical Analysis:
  • Better understanding of LoRA's approximation capabilities
  • Key questions: 4 identified

Architecture Specific:
  • Optimized LoRA for different VLM architectures
  • Key questions: 4 identified

Efficiency Optimization:
  • Hardware-aware LoRA optimization
  • Key questions: 4 identified

===================================

Detailed Research Proposal Example:
Area: Theoretical Analysis
Priority: HIGH
Description: Better understanding of LoRA's approximation capabilities

Proposal 1: Investigation of What is the theoretical limit of low-rank approximation
  Objective: What is the theoretical limit of low-rank approximation?
  Methodology: Matrix perturbation theory
  Timeline: 12-18 months

===================================

Research Impact Assessment:

Multimodal Extensions:
  Overall Impact: 0.78
  Recommendation: HIGH PRIORITY
  Scientific Impact: 0.93
  Practical Impact: 0.80

Theoretical Analysis:
  Overall Impact: 0.71
  Recommendation: MEDIUM PRIORITY
  Scientific Impact: 0.89
  Practical Impact: 0.78

Architecture Specific:
  Overall Impact: 0.69
  Recommendation: MEDIUM PRIORITY
  Scientific Impact: 0.69
  Practical Impact: 0.72

Efficiency Optimization:
  Overall Impact: 0.63
  Recommendation: MEDIUM PRIORITY
  Scientific Impact: 0.62
  Practical Impact: 0.52

Continual Learning:
  Overall Impact: 0.63
  Recommendation: MEDIUM PRIORITY
  Scientific Impact: 0.69
  Practical Impact: 0.64

===================================

Collaboration Opportunities:

Academic Institutions:
  • Computer Vision labs for VLM architectures
  • Machine Learning theory groups for theoretical analysis

Industry Partners:
  • Cloud providers for large-scale deployment
  • Hardware manufacturers for optimization

Interdisciplinary Opportunities:
  • Neuroscience: Brain-inspired adaptation mechanisms
  • Mathematics: Advanced matrix theory applications

Funding Opportunities:
  • NSF: Theoretical foundations of adaptation
  • DARPA: Efficient AI systems</code></pre>
</div>
</div>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>This comprehensive guide has covered the theoretical foundations, practical implementation, and production deployment of LoRA for Vision-Language Models. Key takeaways include:</p>
<section id="summary-of-key-points" class="level3">
<h3 class="anchored" data-anchor-id="summary-of-key-points">Summary of Key Points</h3>
<div id="key-takeaways" class="cell" data-execution_count="29">
<div class="cell-output cell-output-stdout">
<pre><code>🎯 Key Takeaways from LoRA for VLMs:
=============================================
 1. 🔬 Start with conservative hyperparameters (rank=16, alpha=16) and gradually increase complexity
 2. 🎯 Focus on high-impact modules (attention layers, cross-modal fusion) for maximum efficiency
 3. 📊 Monitor both performance and efficiency metrics throughout development
 4. 🔧 Use appropriate debugging and analysis tools to understand adapter behavior
 5. 🚀 Implement progressive training strategies for stable convergence
 6. ⚡ Apply memory optimization techniques for large-scale deployment
 7. 📈 Establish comprehensive monitoring for production systems
 8. 🔄 Stay updated with emerging techniques and research developments
 9. 🤝 Consider task-specific configurations for optimal performance
10. 🛡️ Implement robust troubleshooting procedures for common issues

=============================================
📚 This guide provides a solid foundation for leveraging LoRA
   in Vision-Language Model applications, from research through
   production deployment and monitoring.</code></pre>
</div>
</div>
</section>
<section id="future-outlook" class="level3">
<h3 class="anchored" data-anchor-id="future-outlook">Future Outlook</h3>
<p>As the field continues to evolve, LoRA and its variants will likely become even more sophisticated, enabling more efficient and capable multimodal AI systems. The techniques and principles outlined in this guide provide a solid foundation for leveraging these advances in your own Vision-Language Model applications.</p>
</section>
<section id="resources-for-further-learning" class="level3">
<h3 class="anchored" data-anchor-id="resources-for-further-learning">Resources for Further Learning</h3>
<ul>
<li><strong>Hugging Face PEFT</strong>: Parameter-Efficient Fine-Tuning library</li>
<li><strong>LoRA Paper</strong>: “LoRA: Low-Rank Adaptation of Large Language Models” (Hu et al., 2021)</li>
<li><strong>CLIP Paper</strong>: “Learning Transferable Visual Representations from Natural Language Supervision” (Radford et al., 2021)</li>
<li><strong>LLaVA Paper</strong>: “Visual Instruction Tuning” (Liu et al., 2023)</li>
<li><strong>AdaLoRA Paper</strong>: “Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning” (Zhang et al., 2023)</li>
</ul>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ol type="1">
<li><p>Hu, E. J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., … &amp; Chen, W. (2021). LoRA: Low-Rank Adaptation of Large Language Models. <em>arXiv preprint arXiv:2106.09685</em>.</p></li>
<li><p>Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., … &amp; Sutskever, I. (2021). Learning Transferable Visual Representations from Natural Language Supervision. <em>International Conference on Machine Learning</em>.</p></li>
<li><p>Li, J., Li, D., Xiong, C., &amp; Hoi, S. (2022). BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation. <em>International Conference on Machine Learning</em>.</p></li>
<li><p>Liu, H., Li, C., Wu, Q., &amp; Lee, Y. J. (2023). Visual Instruction Tuning. <em>arXiv preprint arXiv:2304.08485</em>.</p></li>
<li><p>Zhang, Q., Chen, M., Bukharin, A., He, P., Cheng, Y., Chen, W., &amp; Zhao, T. (2023). AdaLoRA: Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning. <em>International Conference on Learning Representations</em>.</p></li>
</ol>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/theja-vanka\.github\.io\/blogs\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>© 2025 Krishnatheja Vanka</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>